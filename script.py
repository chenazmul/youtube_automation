import os
import shutil
import subprocess
import yt_dlp
import whisper
from glob import glob
import random
import string
import pysubs2
import torch
import requests
import json
import re
from concurrent.futures import as_completed
from openai import AzureOpenAI
from azure.identity import DefaultAzureCredential, get_bearer_token_provider 
from dotenv import load_dotenv
from subtitle_design import apply_design  # `subtitle_design.py` ‡¶•‡ßá‡¶ï‡ßá ‡¶°‡¶ø‡¶ú‡¶æ‡¶á‡¶® ‡¶´‡¶æ‡¶Ç‡¶∂‡¶® ‡¶á‡¶Æ‡¶™‡ßã‡¶∞‡ßç‡¶ü ‡¶ï‡¶∞‡¶æ ‡¶π‡¶ö‡ßç‡¶õ‡ßá
from azure_prompt import generate_output_from_azure  # Azure AI ‡¶è‡¶∞ ‡¶´‡¶æ‡¶Ç‡¶∂‡¶®‡¶ü‡¶ø ‡¶á‡¶Æ‡¶™‡ßã‡¶∞‡ßç‡¶ü ‡¶ï‡¶∞‡¶æ ‡¶π‡¶ö‡ßç‡¶õ‡ßá
from metadata_updater import set_file_properties
from metadata_updater import process_video_metadata
from ai_voice_generator import transcribe_and_generate_ai_voice  # AI ‡¶≠‡¶Ø‡¶º‡ßá‡¶∏ ‡¶´‡¶æ‡¶Ç‡¶∂‡¶® ‡¶á‡¶Æ‡¶™‡ßã‡¶∞‡ßç‡¶ü ‡¶ï‡¶∞‡¶æ ‡¶π‡¶ö‡ßç‡¶õ‡ßá
import time
from face_footage_handler import FaceFootageHandler

load_dotenv()  # ‡¶è‡¶ü‡¶ø ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ .env ‡¶´‡¶æ‡¶á‡¶≤ ‡¶•‡ßá‡¶ï‡ßá ‡¶™‡¶∞‡¶ø‡¶¨‡ßá‡¶∂ ‡¶≠‡ßá‡¶∞‡¶ø‡¶Ø‡¶º‡ßá‡¶¨‡¶≤‡¶ó‡ßÅ‡¶≤‡ßã ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡¶¨‡ßá


# Azure OpenAI API ‡¶ï‡¶®‡¶´‡¶ø‡¶ó‡¶æ‡¶∞‡ßá‡¶∂‡¶®
endpoint = os.getenv("ENDPOINT_URL", "https://et1.openai.azure.com/")  
deployment = os.getenv("DEPLOYMENT_NAME", "gpt-4o")  

# Initialize Azure OpenAI Service client with Entra ID authentication
token_provider = get_bearer_token_provider(  
    DefaultAzureCredential(),  
    "https://cognitiveservices.azure.com/.default"  
)  

client = AzureOpenAI(  
    azure_endpoint=endpoint,  
    azure_ad_token_provider=token_provider,  
    api_version="2024-05-01-preview",  
)


# ‡¶´‡¶æ‡¶á‡¶≤ ‡¶®‡¶æ‡¶Æ ‡¶∏‡ßá‡¶®‡¶ø‡¶ü‡¶æ‡¶á‡¶ú ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶´‡¶æ‡¶Ç‡¶∂‡¶®
def sanitize_filename(filename):
    """
    ‡¶´‡¶æ‡¶á‡¶≤ ‡¶®‡¶æ‡¶Æ ‡¶•‡ßá‡¶ï‡ßá ‡¶¨‡¶ø‡¶∂‡ßá‡¶∑ ‡¶Ö‡¶ï‡ßç‡¶∑‡¶∞‡¶ó‡ßÅ‡¶≤‡ßã ‡¶∞‡¶ø‡¶Æ‡ßÅ‡¶≠ ‡¶ï‡¶∞‡ßá ‡¶∂‡ßÅ‡¶ß‡ßÅ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ ‡¶∏‡ßá‡¶´ ‡¶ï‡ßç‡¶Ø‡¶æ‡¶∞‡ßá‡¶ï‡ßç‡¶ü‡¶æ‡¶∞ ‡¶∞‡¶æ‡¶ñ‡ßá‡•§
    
    Args:
        filename (str): ‡¶Ö‡¶∞‡¶ø‡¶ú‡¶ø‡¶®‡¶æ‡¶≤ ‡¶´‡¶æ‡¶á‡¶≤‡¶®‡¶æ‡¶Æ
        
    Returns:
        tuple: (sanitized_name, original_name) - ‡¶∏‡ßá‡¶®‡¶ø‡¶ü‡¶æ‡¶á‡¶ú ‡¶ï‡¶∞‡¶æ ‡¶®‡¶æ‡¶Æ ‡¶è‡¶¨‡¶Ç ‡¶Ö‡¶∞‡¶ø‡¶ú‡¶ø‡¶®‡¶æ‡¶≤ ‡¶®‡¶æ‡¶Æ
    """
    # ‡¶Ö‡¶∞‡¶ø‡¶ú‡¶ø‡¶®‡¶æ‡¶≤ ‡¶®‡¶æ‡¶Æ ‡¶∏‡¶Ç‡¶∞‡¶ï‡ßç‡¶∑‡¶£ ‡¶ï‡¶∞‡ßÅ‡¶®
    original_name = filename
    
    # ‡¶è‡¶ï‡ßç‡¶∏‡¶ü‡ßá‡¶®‡¶∂‡¶® ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®
    base_name, extension = os.path.splitext(filename)
    
    # ‡¶¨‡¶ø‡¶∂‡ßá‡¶∑ ‡¶ï‡ßç‡¶Ø‡¶æ‡¶∞‡ßá‡¶ï‡ßç‡¶ü‡¶æ‡¶∞ ‡¶∞‡¶ø‡¶Æ‡ßÅ‡¶≠ ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶è‡¶¨‡¶Ç ‡¶∏‡ßç‡¶™‡ßá‡¶∏ ‡¶Ü‡¶®‡ßç‡¶°‡¶æ‡¶∞‡¶∏‡ßç‡¶ï‡ßã‡¶∞ ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶∏‡ßç‡¶•‡¶æ‡¶™‡¶® ‡¶ï‡¶∞‡ßÅ‡¶®
    sanitized_base = re.sub(r'[^\w\s-]', '', base_name)
    sanitized_base = re.sub(r'[\s]+', '_', sanitized_base)
    
    # ‡¶ñ‡ßÅ‡¶¨ ‡¶≤‡¶Æ‡ßç‡¶¨‡¶æ ‡¶®‡¶æ‡¶Æ ‡¶π‡¶≤‡ßá ‡¶∏‡ßá‡¶ü‡¶ø ‡¶∂‡¶∞‡ßç‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®
    if len(sanitized_base) > 50:
        sanitized_base = sanitized_base[:50]
    
    # ‡¶∏‡ßá‡¶®‡¶ø‡¶ü‡¶æ‡¶á‡¶ú ‡¶ï‡¶∞‡¶æ ‡¶®‡¶æ‡¶Æ ‡¶´‡¶ø‡¶∞‡¶ø‡¶Ø‡¶º‡ßá ‡¶¶‡¶ø‡¶®
    sanitized_name = sanitized_base + extension
    
    return sanitized_name, original_name


# ‡¶´‡¶æ‡¶á‡¶≤ ‡¶®‡¶æ‡¶Æ ‡¶Æ‡ßç‡¶Ø‡¶æ‡¶™‡¶ø‡¶Ç ‡¶è‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶°‡¶ø‡¶ï‡¶∂‡¶®‡¶æ‡¶∞‡¶ø
filename_mapping = {}

def map_filename(original_path, sanitized_path):
    """
    ‡¶Ö‡¶∞‡¶ø‡¶ú‡¶ø‡¶®‡¶æ‡¶≤ ‡¶´‡¶æ‡¶á‡¶≤ ‡¶™‡¶æ‡¶• ‡¶è‡¶¨‡¶Ç ‡¶∏‡ßá‡¶®‡¶ø‡¶ü‡¶æ‡¶á‡¶ú ‡¶ï‡¶∞‡¶æ ‡¶´‡¶æ‡¶á‡¶≤ ‡¶™‡¶æ‡¶•‡ßá‡¶∞ ‡¶Æ‡ßç‡¶Ø‡¶æ‡¶™‡¶ø‡¶Ç ‡¶∞‡¶æ‡¶ñ‡ßá‡•§
    
    Args:
        original_path (str): ‡¶Ö‡¶∞‡¶ø‡¶ú‡¶ø‡¶®‡¶æ‡¶≤ ‡¶´‡¶æ‡¶á‡¶≤ ‡¶™‡¶æ‡¶•
        sanitized_path (str): ‡¶∏‡ßá‡¶®‡¶ø‡¶ü‡¶æ‡¶á‡¶ú ‡¶ï‡¶∞‡¶æ ‡¶´‡¶æ‡¶á‡¶≤ ‡¶™‡¶æ‡¶•
    """
    filename_mapping[sanitized_path] = original_path
    
def get_original_filename(sanitized_path):
    """
    ‡¶∏‡ßá‡¶®‡¶ø‡¶ü‡¶æ‡¶á‡¶ú ‡¶ï‡¶∞‡¶æ ‡¶´‡¶æ‡¶á‡¶≤ ‡¶™‡¶æ‡¶• ‡¶•‡ßá‡¶ï‡ßá ‡¶Ö‡¶∞‡¶ø‡¶ú‡¶ø‡¶®‡¶æ‡¶≤ ‡¶´‡¶æ‡¶á‡¶≤ ‡¶™‡¶æ‡¶• ‡¶™‡¶æ‡¶Ø‡¶º‡•§
    
    Args:
        sanitized_path (str): ‡¶∏‡ßá‡¶®‡¶ø‡¶ü‡¶æ‡¶á‡¶ú ‡¶ï‡¶∞‡¶æ ‡¶´‡¶æ‡¶á‡¶≤ ‡¶™‡¶æ‡¶•
        
    Returns:
        str: ‡¶Ö‡¶∞‡¶ø‡¶ú‡¶ø‡¶®‡¶æ‡¶≤ ‡¶´‡¶æ‡¶á‡¶≤ ‡¶™‡¶æ‡¶•, ‡¶Ø‡¶¶‡¶ø ‡¶™‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ ‡¶Ø‡¶æ‡¶Ø‡¶º; ‡¶Ö‡¶®‡ßç‡¶Ø‡¶•‡¶æ‡¶Ø‡¶º ‡¶∏‡ßá‡¶®‡¶ø‡¶ü‡¶æ‡¶á‡¶ú ‡¶ï‡¶∞‡¶æ ‡¶™‡¶æ‡¶•
    """
    return filename_mapping.get(sanitized_path, sanitized_path)

def get_original_basename(sanitized_path):
    """
    ‡¶∏‡ßá‡¶®‡¶ø‡¶ü‡¶æ‡¶á‡¶ú ‡¶ï‡¶∞‡¶æ ‡¶´‡¶æ‡¶á‡¶≤ ‡¶™‡¶æ‡¶• ‡¶•‡ßá‡¶ï‡ßá ‡¶Ö‡¶∞‡¶ø‡¶ú‡¶ø‡¶®‡¶æ‡¶≤ ‡¶´‡¶æ‡¶á‡¶≤ ‡¶®‡¶æ‡¶Æ (‡¶¨‡ßá‡¶∏‡¶®‡¶æ‡¶Æ) ‡¶™‡¶æ‡¶Ø‡¶º‡•§
    
    Args:
        sanitized_path (str): ‡¶∏‡ßá‡¶®‡¶ø‡¶ü‡¶æ‡¶á‡¶ú ‡¶ï‡¶∞‡¶æ ‡¶´‡¶æ‡¶á‡¶≤ ‡¶™‡¶æ‡¶•
        
    Returns:
        str: ‡¶Ö‡¶∞‡¶ø‡¶ú‡¶ø‡¶®‡¶æ‡¶≤ ‡¶´‡¶æ‡¶á‡¶≤‡ßá‡¶∞ ‡¶¨‡ßá‡¶∏‡¶®‡¶æ‡¶Æ, ‡¶Ø‡¶¶‡¶ø ‡¶™‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ ‡¶Ø‡¶æ‡¶Ø‡¶º; ‡¶Ö‡¶®‡ßç‡¶Ø‡¶•‡¶æ‡¶Ø‡¶º ‡¶∏‡ßá‡¶®‡¶ø‡¶ü‡¶æ‡¶á‡¶ú ‡¶ï‡¶∞‡¶æ ‡¶¨‡ßá‡¶∏‡¶®‡¶æ‡¶Æ
    """
    original_path = get_original_filename(sanitized_path)
    return os.path.splitext(os.path.basename(original_path))[0]


# üîπ ‡¶ï‡¶®‡¶´‡¶ø‡¶ó‡¶æ‡¶∞‡ßá‡¶∂‡¶®
BASE_PATH = "G:/video_project/"
OLD_AUDIO_FOLDER = "G:/video_project/old_audio"
YOUTUBE_URL_FILE = os.path.join(BASE_PATH, "youtube_urls.txt")
YOUTUBE_SHORTS_URL_FILE = os.path.join(BASE_PATH, "youtube_shorts_urls.txt")
# AI ‡¶≠‡¶Ø‡¶º‡ßá‡¶∏ ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì URL ‡¶´‡¶æ‡¶á‡¶≤
YOUTUBE_AI_VOICE_SHORTS_URL_FILE = os.path.join(BASE_PATH, "youtube_ai_voice_shorts_urls.txt")
YOUTUBE_AI_VOICE_LONG_VIDEO_URL_FILE = os.path.join(BASE_PATH, "youtube_ai_voice_long_video_urls.txt")

AUDIO_FOLDER = os.path.join(BASE_PATH, "audio_files")
STOCK_VIDEO = os.path.join(BASE_PATH, "stock_video.mp4")  # ‡¶´‡¶≤‡¶¨‡ßç‡¶Ø‡¶æ‡¶ï ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá
OUTPUT_FOLDER = os.path.join(BASE_PATH, "output_videos")
SHORTS_FOLDER = os.path.join(OUTPUT_FOLDER, "shorts")
TEMP_FOLDER = os.path.join(BASE_PATH, "temp_output")
SHORTS_STOCK_VIDEOS_FOLDER = os.path.join(BASE_PATH, "shorts_stock_videos")
STOCK_VIDEOS_FOLDER = os.path.join(BASE_PATH, "stock_videos")
BACKGROUND_MUSIC_FOLDER = os.path.join(BASE_PATH, "background_music")
# üîπ ‡¶´‡ßá‡¶∏ ‡¶´‡ßÅ‡¶ü‡ßá‡¶ú ‡¶´‡ßã‡¶≤‡ßç‡¶°‡¶æ‡¶∞ ‡¶ï‡¶®‡¶´‡¶ø‡¶ó‡¶æ‡¶∞‡ßá‡¶∂‡¶®
REAL_FOOTAGE_SHORTS_FOLDER = os.path.join(BASE_PATH, "real_footage_shorts")
REAL_FOOTAGE_LONG_FOLDER = os.path.join(BASE_PATH, "real_footage_long")
YOUTUBE_SHORTS_WITH_FACE_URL_FILE = os.path.join(BASE_PATH, "youtube_shorts_with_5_sec_with_face.txt")
YOUTUBE_LONG_WITH_FACE_URL_FILE = os.path.join(BASE_PATH, "youtube_long_with_5_sec_with_face.txt")
YOUTUBE_SHORTS_WITH_FACE_AI_URL_FILE = os.path.join(BASE_PATH, "youtube_shorts_with_5_sec_with_face_ai.txt")
YOUTUBE_LONG_WITH_FACE_AI_URL_FILE = os.path.join(BASE_PATH, "youtube_long_with_5_sec_with_face_ai.txt")

# üîπ Ensure output directories exist
os.makedirs(AUDIO_FOLDER, exist_ok=True)
os.makedirs(OUTPUT_FOLDER, exist_ok=True)
os.makedirs(SHORTS_FOLDER, exist_ok=True)
os.makedirs(TEMP_FOLDER, exist_ok=True)
os.makedirs(SHORTS_STOCK_VIDEOS_FOLDER, exist_ok=True)
# ‡¶´‡ßã‡¶≤‡ßç‡¶°‡¶æ‡¶∞ ‡¶ó‡ßÅ‡¶≤‡¶ø ‡¶®‡¶ø‡¶∂‡ßç‡¶ö‡¶ø‡¶§ ‡¶ï‡¶∞‡ßÅ‡¶®
os.makedirs(REAL_FOOTAGE_SHORTS_FOLDER, exist_ok=True)
os.makedirs(REAL_FOOTAGE_LONG_FOLDER, exist_ok=True)

# FaceFootageHandler ‡¶á‡¶®‡¶ø‡¶∂‡¶ø‡¶Ø‡¶º‡¶æ‡¶≤‡¶æ‡¶á‡¶ú ‡¶ï‡¶∞‡ßÅ‡¶®
face_handler = FaceFootageHandler(BASE_PATH)

def transcribe_audio(audio_file):
    """‡¶∏‡ßç‡¶™‡¶ø‡¶ö ‡¶ü‡ßÅ ‡¶ü‡ßá‡¶ï‡ßç‡¶∏‡¶ü ‡¶™‡ßç‡¶∞‡¶∏‡ßá‡¶∏ ‡¶ï‡¶∞‡¶æ Whisper ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá"""
    result = model.transcribe(audio_file, task='transcribe')
    if result and 'text' in result:
        return result['text']
    else:
        print(f"‚ùå Transcription failed for {audio_file}")
        return None


# Azure OpenAI API ‡¶ï‡¶≤
def generate_output_from_azure(transcribe, video_title, output_file_path):
    """Azure OpenAI API ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶∏‡ßç‡¶™‡¶ø‡¶ö ‡¶ü‡ßá‡¶ï‡ßç‡¶∏‡¶ü ‡¶™‡ßç‡¶∞‡¶∏‡ßá‡¶∏ ‡¶ï‡¶∞‡¶æ ‡¶è‡¶¨‡¶Ç ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü ‡¶∏‡ßá‡¶≠ ‡¶ï‡¶∞‡¶æ"""
    
    # ‡¶™‡ßç‡¶∞‡¶Æ‡ßç‡¶™‡¶ü ‡¶§‡ßà‡¶∞‡¶ø
    prompt = f"""
    Here is my transcribe: {transcribe}
    Topic: "{video_title}"
    
    Write 1 Youtube relevent Video Title, Must engaging. 
    Write 2 paragraphs based on transcribe and title.
    Write 10 hashtags.
    Write 10 normal tags with comma separation.

    And After this, write this also:

    üé§ Speakers in this video: 
    Tony Robbins

    üîä Our speeches are created by, remixed or licensed to Tony Robbins Motivation.
    For licensing information, message geniusteam01@gmail.com

    üé• The video footage in this video:
    All video footage used is licensed through either CC-BY, from various stock footage websites, or filmed by us. All Creative Commons footage is listed at the video's end and licensed under CC-BY 3.0. Film and TV shows used in the video are interwoven with the video's narrative, related to the video's topic, and corresponding to FAIR USE.
    """
    
    # API Key ‡¶è‡¶¨‡¶Ç Endpoint ‡¶•‡ßá‡¶ï‡ßá API URL ‡¶∏‡ßá‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®
    api_key = os.getenv("API_KEY")  # ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ Azure OpenAI API Key 
    url = f'{endpoint}/openai/deployments/{deployment}/chat/completions?api-version=2024-02-15-preview'

    headers = {
        'Content-Type': 'application/json',
        'api-key': api_key  # API Key
    }

    payload = {
        "messages": [
            {"role": "system", "content": "You are an AI assistant that helps people find information."},
            {"role": "user", "content": prompt}  # ‡¶è‡¶ñ‡¶æ‡¶®‡ßá prompt ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá‡¶õ‡¶ø
        ],
        "max_tokens": 1500,
        "temperature": 0.7
    }

    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload))

        if response.status_code == 200:
            data = response.json()
            result = data['choices'][0]['message']['content'].strip()  # ‡¶∏‡¶†‡¶ø‡¶ï ‡¶ü‡ßá‡¶ï‡ßç‡¶∏‡¶ü ‡¶Ø‡¶æ‡¶ö‡¶æ‡¶á
            print(f"‚úÖ Response received: {result[:200]}...")  # ‡¶Ü‡¶Ç‡¶∂‡¶ø‡¶ï ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü
        else:
            print(f"‚ùå API Response Error: {response.status_code}, {response.text}")
            return

        # ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü ‡¶´‡¶æ‡¶á‡¶≤ ‡¶∏‡ßá‡¶≠ ‡¶ï‡¶∞‡ßÅ‡¶®
        with open(output_file_path, "w", encoding="utf-8") as file:
            file.write(result)
            print(f"‚úÖ Output saved to: {output_file_path}")

    except Exception as e:
        print(f"‚ùå Error generating output from Azure OpenAI: {e}")
        print("‚ö†Ô∏è Skipping Azure process and continuing with the next steps...")


def process_audio_and_generate_text(audio_file, video_title, is_short=False):
    """‡¶∏‡ßç‡¶™‡¶ø‡¶ö ‡¶ü‡ßÅ ‡¶ü‡ßá‡¶ï‡ßç‡¶∏‡¶ü ‡¶™‡ßç‡¶∞‡¶∏‡ßá‡¶∏ ‡¶è‡¶¨‡¶Ç Azure OpenAI ‡¶è‡¶∞ ‡¶Æ‡¶æ‡¶ß‡ßç‡¶Ø‡¶Æ‡ßá ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶æ"""
    
    # Whisper ‡¶è‡¶∞ ‡¶Æ‡¶æ‡¶ß‡ßç‡¶Ø‡¶Æ‡ßá ‡¶Ö‡¶°‡¶ø‡¶ì ‡¶•‡ßá‡¶ï‡ßá ‡¶ü‡ßç‡¶∞‡¶æ‡¶®‡ßç‡¶∏‡¶ï‡ßç‡¶∞‡¶ø‡¶™‡ßç‡¶ü ‡¶ï‡¶∞‡¶æ
    transcribe = transcribe_audio(audio_file)

    if not transcribe:
        return
    
    # ‡¶∏‡ßá‡¶®‡¶ø‡¶ü‡¶æ‡¶á‡¶ú ‡¶ï‡¶∞‡¶æ ‡¶´‡¶æ‡¶á‡¶≤ ‡¶®‡¶æ‡¶Æ ‡¶•‡ßá‡¶ï‡ßá ‡¶Ö‡¶∞‡¶ø‡¶ú‡¶ø‡¶®‡¶æ‡¶≤ ‡¶´‡¶æ‡¶á‡¶≤ ‡¶®‡¶æ‡¶Æ ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßÅ‡¶®
    original_folder_name = get_original_basename(audio_file)
    sanitized_folder_name = os.path.splitext(os.path.basename(audio_file))[0]
    
    # ‡¶Ø‡¶¶‡¶ø ‡¶Ö‡¶∞‡¶ø‡¶ú‡¶ø‡¶®‡¶æ‡¶≤ ‡¶´‡ßã‡¶≤‡ßç‡¶°‡¶æ‡¶∞ ‡¶®‡¶æ‡¶Æ ‡¶®‡¶æ ‡¶™‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ ‡¶Ø‡¶æ‡¶Ø‡¶º, ‡¶§‡¶æ‡¶π‡¶≤‡ßá ‡¶∏‡ßá‡¶®‡¶ø‡¶ü‡¶æ‡¶á‡¶ú ‡¶ï‡¶∞‡¶æ ‡¶®‡¶æ‡¶Æ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®
    if not original_folder_name:
        original_folder_name = sanitized_folder_name
    
    # ‡¶Ö‡¶∞‡¶ø‡¶ú‡¶ø‡¶®‡¶æ‡¶≤ ‡¶´‡¶æ‡¶á‡¶≤ ‡¶®‡¶æ‡¶Æ ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡¶Ø‡¶º‡ßÄ ‡¶´‡ßã‡¶≤‡ßç‡¶°‡¶æ‡¶∞ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®
    if is_short:
        video_folder = os.path.join(OUTPUT_FOLDER, "shorts", original_folder_name)  # Shorts folder
    else:
        video_folder = os.path.join(OUTPUT_FOLDER, original_folder_name)  # Regular video folder

    os.makedirs(video_folder, exist_ok=True)

    # ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì ‡¶ü‡¶æ‡¶á‡¶ü‡ßá‡¶≤ ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡¶Ø‡¶º‡ßÄ ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü ‡¶´‡¶æ‡¶á‡¶≤ ‡¶®‡¶æ‡¶Æ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶æ (‡¶∏‡ßá‡¶®‡¶ø‡¶ü‡¶æ‡¶á‡¶ú ‡¶ï‡¶∞‡¶æ ‡¶®‡¶æ‡¶Æ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá)
    output_file_path = os.path.join(video_folder, f"{sanitized_folder_name}_output.txt")

    # Azure OpenAI API ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶æ
    generate_output_from_azure(transcribe, video_title, output_file_path)
    
    # Save video to the same folder (‡¶è‡¶ü‡¶ø create_video ‡¶´‡¶æ‡¶Ç‡¶∂‡¶®‡ßá‡¶á ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá)
    print(f"‚úÖ Video and text saved to: {video_folder}")


def get_random_file(folder_path, extensions=(".mp4", ".mov", ".mp3", ".wav")):
    """‡¶´‡ßã‡¶≤‡ßç‡¶°‡¶æ‡¶∞ ‡¶•‡ßá‡¶ï‡ßá ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶è‡¶ï‡ßç‡¶∏‡¶ü‡ßá‡¶®‡¶∂‡¶®‡ßá‡¶∞ ‡¶∞‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶°‡¶Æ ‡¶´‡¶æ‡¶á‡¶≤ ‡¶™‡ßá‡¶§‡ßá ‡¶∏‡¶æ‡¶π‡¶æ‡¶Ø‡ßç‡¶Ø ‡¶ï‡¶∞‡ßá‡•§"""
    if not os.path.isdir(folder_path):
        return None
    file_list = [f for f in glob(os.path.join(folder_path, "*")) if f.lower().endswith(extensions)]
    if file_list:
        return random.choice(file_list)
    return None


# ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì ‡¶´‡¶æ‡¶á‡¶≤‡ßá‡¶∞ ‡¶®‡¶æ‡¶Æ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶§‡ßá ‡¶´‡¶æ‡¶á‡¶≤‡ßá‡¶∞ ‡¶®‡¶æ‡¶Æ‡¶ï‡ßá ‡¶Ö‡¶°‡¶ø‡¶ì ‡¶´‡¶æ‡¶á‡¶≤‡ßá‡¶∞ ‡¶®‡¶æ‡¶Æ ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡¶Ø‡¶º‡ßÄ ‡¶∏‡ßá‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®
def get_output_filename(audio_file, is_short=False, prefix='', suffix=''):
    """
    ‡¶Ö‡¶°‡¶ø‡¶ì ‡¶´‡¶æ‡¶á‡¶≤‡ßá‡¶∞ ‡¶®‡¶æ‡¶Æ ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡¶Ø‡¶º‡ßÄ ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì ‡¶®‡¶æ‡¶Æ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®, ‡¶™‡ßç‡¶∞‡¶ø‡¶´‡¶ø‡¶ï‡ßç‡¶∏ ‡¶ì ‡¶∏‡¶æ‡¶´‡¶ø‡¶ï‡ßç‡¶∏ ‡¶∏‡¶π‡•§
    ‡¶è‡¶ñ‡¶® ‡¶è‡¶ü‡¶ø ‡¶Ö‡¶∞‡¶ø‡¶ú‡¶ø‡¶®‡¶æ‡¶≤ ‡¶´‡¶æ‡¶á‡¶≤‡¶®‡¶æ‡¶Æ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá ‡¶´‡ßã‡¶≤‡ßç‡¶°‡¶æ‡¶∞ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßá‡•§
    """
    # ‡¶∏‡ßá‡¶®‡¶ø‡¶ü‡¶æ‡¶á‡¶ú ‡¶ï‡¶∞‡¶æ ‡¶´‡¶æ‡¶á‡¶≤ ‡¶™‡¶æ‡¶• ‡¶•‡ßá‡¶ï‡ßá ‡¶Ö‡¶∞‡¶ø‡¶ú‡¶ø‡¶®‡¶æ‡¶≤ ‡¶´‡¶æ‡¶á‡¶≤‡¶®‡¶æ‡¶Æ ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßÅ‡¶®
    original_audio_filename = get_original_basename(audio_file)
    # ‡¶Ø‡¶¶‡¶ø ‡¶Ö‡¶∞‡¶ø‡¶ú‡¶ø‡¶®‡¶æ‡¶≤ ‡¶®‡¶æ‡¶Æ ‡¶®‡¶æ ‡¶™‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ ‡¶Ø‡¶æ‡¶Ø‡¶º, ‡¶§‡¶æ‡¶π‡¶≤‡ßá ‡¶¨‡¶∞‡ßç‡¶§‡¶Æ‡¶æ‡¶® ‡¶´‡¶æ‡¶á‡¶≤‡ßá‡¶∞ ‡¶®‡¶æ‡¶Æ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®
    if not original_audio_filename:
        original_audio_filename = os.path.splitext(os.path.basename(audio_file))[0]
    
    sanitized_audio_filename = os.path.splitext(os.path.basename(audio_file))[0]
    
    if prefix:
        sanitized_audio_filename = prefix + sanitized_audio_filename
    if suffix:
        sanitized_audio_filename = sanitized_audio_filename + suffix

    # ‡¶Ö‡¶∏‡ßç‡¶•‡¶æ‡¶Ø‡¶º‡ßÄ ‡¶´‡¶æ‡¶á‡¶≤ ‡¶™‡¶æ‡¶• ‡¶π‡¶ø‡¶∏‡¶æ‡¶¨‡ßá TEMP_FOLDER ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®
    if is_short:
        output_filename = os.path.join(TEMP_FOLDER, f"{sanitized_audio_filename}_short.mp4")
    else:
        output_filename = os.path.join(TEMP_FOLDER, f"{sanitized_audio_filename}.mp4")
    
    return output_filename


def convert_srt_to_ass(srt_file, ass_file, is_short=False):
    """Convert SRT subtitles to ASS format with premium styling and random color patterns."""
    try:
        # ‡¶´‡¶æ‡¶á‡¶≤‡¶®‡¶æ‡¶Æ ‡¶è‡¶ï‡ßç‡¶∏‡¶ü‡ßç‡¶∞‡¶æ‡¶ï‡ßç‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®
        base_filename = os.path.basename(srt_file)
        
        print(f"\nüé® Creating design for: {base_filename}")
        
        subs = pysubs2.load(srt_file, encoding="utf-8")
        
        # ‡¶°‡¶ø‡¶ú‡¶æ‡¶á‡¶® ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶™‡ßç‡¶≤‡¶æ‡¶á ‡¶ï‡¶∞‡ßÅ‡¶®, ‡¶´‡¶æ‡¶á‡¶≤‡¶®‡¶æ‡¶Æ ‡¶™‡¶æ‡¶∏ ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶Ø‡¶æ‡¶§‡ßá ‡¶è‡¶ï‡¶á ‡¶´‡¶æ‡¶á‡¶≤‡ßá ‡¶∏‡¶¨‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶è‡¶ï‡¶á ‡¶°‡¶ø‡¶ú‡¶æ‡¶á‡¶® ‡¶π‡¶Ø‡¶º
        subs = apply_design(subs, is_short, filename=base_filename)
        
        # ASS ‡¶´‡¶æ‡¶á‡¶≤ ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá ‡¶∏‡¶Ç‡¶∞‡¶ï‡ßç‡¶∑‡¶£ ‡¶ï‡¶∞‡ßÅ‡¶®
        subs.save(ass_file)
        print(f"‚úÖ Converted SRT to ASS with unique design: {ass_file}")
    except Exception as e:
        print(f"‚ùå Error converting subtitle to ASS: {e}")
        # ‡¶´‡¶≤‡¶¨‡ßç‡¶Ø‡¶æ‡¶ï ‡¶°‡¶ø‡¶ú‡¶æ‡¶á‡¶®
        try:
            subs = pysubs2.load(srt_file, encoding="utf-8")
            subs.styles["Default"].fontname = "Arial"
            subs.styles["Default"].fontsize = 24 if is_short else 30
            subs.styles["Default"].primarycolor = pysubs2.Color(255, 255, 255, 0)
            subs.styles["Default"].outlinecolor = pysubs2.Color(0, 0, 0, 0)
            subs.styles["Default"].backcolor = pysubs2.Color(0, 0, 0, 128)
            subs.styles["Default"].borderstyle = 3
            subs.styles["Default"].outline = 2
            subs.styles["Default"].shadow = 0
            subs.styles["Default"].alignment = 2
            subs.save(ass_file)
            print(f"‚úÖ Used fallback subtitle design: {ass_file}")
        except Exception as fallback_error:
            print(f"‚ùå Even fallback design failed: {fallback_error}")
            
def clear_temp_folder():
    """Clear temporary folder."""
    if os.path.exists(TEMP_FOLDER):
        shutil.rmtree(TEMP_FOLDER)
    os.makedirs(TEMP_FOLDER, exist_ok=True)

def shorten_filename(filename, length=10):
    """Shorten filenames to avoid issues with long paths."""
    base_name = os.path.splitext(os.path.basename(filename))[0]
    short_name = "_".join(base_name.split()[:length])
    return f"{short_name}_{''.join(random.choices(string.ascii_letters + string.digits, k=5))}"

def download_youtube_audio(url_file):
    """Download YouTube audio as MP3 and sanitize filenames."""
    if not os.path.isfile(url_file):
        return []
    with open(url_file, "r", encoding="utf-8") as file:
        urls = [line.strip() for line in file.readlines() if line.strip()]
    if not urls:
        return []

    ydl_opts = {
        'format': 'bestaudio/best',
        'postprocessors': [{
            'key': 'FFmpegExtractAudio',
            'preferredcodec': 'mp3',
            'preferredquality': '192',
        }],
        'outtmpl': os.path.join(AUDIO_FOLDER, '%(title)s.%(ext)s'),
        'noplaylist': True,
    }
    
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        ydl.download(urls)
    
    # ‡¶°‡¶æ‡¶â‡¶®‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡¶æ ‡¶´‡¶æ‡¶á‡¶≤‡¶ó‡ßÅ‡¶≤‡ßã ‡¶∏‡¶Ç‡¶ó‡ßç‡¶∞‡¶π ‡¶ï‡¶∞‡ßÅ‡¶®
    downloaded_files = glob(os.path.join(AUDIO_FOLDER, "*.mp3"))
    sanitized_files = []
    
    # ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶´‡¶æ‡¶á‡¶≤‡ßá‡¶∞ ‡¶®‡¶æ‡¶Æ ‡¶∏‡ßá‡¶®‡¶ø‡¶ü‡¶æ‡¶á‡¶ú ‡¶ï‡¶∞‡ßÅ‡¶®
    for file_path in downloaded_files:
        file_dir = os.path.dirname(file_path)
        file_name = os.path.basename(file_path)
        
        # ‡¶´‡¶æ‡¶á‡¶≤ ‡¶®‡¶æ‡¶Æ ‡¶∏‡ßá‡¶®‡¶ø‡¶ü‡¶æ‡¶á‡¶ú ‡¶ï‡¶∞‡ßÅ‡¶®
        sanitized_name, original_name = sanitize_filename(file_name)
        sanitized_path = os.path.join(file_dir, sanitized_name)
        
        # ‡¶Ø‡¶¶‡¶ø ‡¶´‡¶æ‡¶á‡¶≤‡¶®‡¶æ‡¶Æ ‡¶™‡¶∞‡¶ø‡¶¨‡¶∞‡ßç‡¶§‡¶® ‡¶π‡¶Ø‡¶º‡ßá ‡¶•‡¶æ‡¶ï‡ßá, ‡¶§‡¶æ‡¶π‡¶≤‡ßá ‡¶∞‡¶ø‡¶®‡ßá‡¶Æ ‡¶ï‡¶∞‡ßÅ‡¶®
        if sanitized_name != file_name:
            try:
                # ‡¶´‡¶æ‡¶á‡¶≤ ‡¶∞‡¶ø‡¶®‡ßá‡¶Æ ‡¶ï‡¶∞‡ßÅ‡¶®
                os.rename(file_path, sanitized_path)
                print(f"‚úÖ Renamed: {file_name} -> {sanitized_name}")
                
                # ‡¶Æ‡ßç‡¶Ø‡¶æ‡¶™‡¶ø‡¶Ç ‡¶∏‡¶Ç‡¶∞‡¶ï‡ßç‡¶∑‡¶£ ‡¶ï‡¶∞‡ßÅ‡¶®
                map_filename(file_path, sanitized_path)
                sanitized_files.append(sanitized_path)
            except Exception as e:
                print(f"‚ùå Error renaming file {file_name}: {e}")
                sanitized_files.append(file_path)  # ‡¶Ö‡¶∞‡¶ø‡¶ú‡¶ø‡¶®‡¶æ‡¶≤ ‡¶´‡¶æ‡¶á‡¶≤ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®
        else:
            # ‡¶´‡¶æ‡¶á‡¶≤‡¶®‡¶æ‡¶Æ ‡¶™‡¶∞‡¶ø‡¶¨‡¶∞‡ßç‡¶§‡¶® ‡¶®‡¶æ ‡¶π‡¶≤‡ßá‡¶ì ‡¶Æ‡ßç‡¶Ø‡¶æ‡¶™‡¶ø‡¶Ç ‡¶∞‡¶æ‡¶ñ‡ßÅ‡¶®
            map_filename(file_path, file_path)
            sanitized_files.append(file_path)
    
    print(f"‚úÖ YouTube MP3 Download Complete from {url_file}!")
    return sanitized_files

# remove_background_music ‡¶´‡¶æ‡¶Ç‡¶∂‡¶®‡¶ü‡¶ø ‡¶™‡¶∞‡¶ø‡¶¨‡¶∞‡ßç‡¶§‡¶® ‡¶ï‡¶∞‡ßÅ‡¶®
def remove_background_music(input_audio, output_audio, temp_folder):
    """
    Spleeter ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ï‡¶ó‡ßç‡¶∞‡¶æ‡¶â‡¶®‡ßç‡¶° ‡¶Æ‡¶ø‡¶â‡¶ú‡¶ø‡¶ï ‡¶•‡ßá‡¶ï‡ßá ‡¶≠‡¶Ø‡¶º‡ßá‡¶∏ ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ ‡¶ï‡¶∞‡ßá‡•§ 
    ‡¶Ø‡¶¶‡¶ø Spleeter ‡¶á‡¶®‡¶∏‡ßç‡¶ü‡¶≤ ‡¶®‡¶æ ‡¶•‡¶æ‡¶ï‡ßá ‡¶¨‡¶æ ‡¶¨‡ßç‡¶Ø‡¶∞‡ßç‡¶• ‡¶π‡¶Ø‡¶º, ‡¶§‡¶æ‡¶π‡¶≤‡ßá FFmpeg ‡¶´‡¶ø‡¶≤‡ßç‡¶ü‡¶æ‡¶∞ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá‡•§
    """
    try:
        print(f"üîä Processing audio file to separate voice from background: {input_audio}")
        
        # ‡¶Ö‡¶°‡¶ø‡¶ì‡¶∞ ‡¶¶‡ßà‡¶∞‡ßç‡¶ò‡ßç‡¶Ø ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶®
        duration_cmd = f'ffprobe -i "{input_audio}" -show_entries format=duration -v quiet -of csv="p=0"'
        try:
            duration = float(subprocess.check_output(duration_cmd, shell=True).decode().strip())
            print(f"Audio duration: {duration} seconds ({duration/60:.2f} minutes)")
        except:
            print("Could not determine audio duration")

        # Spleeter ‡¶ü‡ßá‡¶Æ‡ßç‡¶™ ‡¶°‡¶ø‡¶∞‡ßá‡¶ï‡ßç‡¶ü‡¶∞‡¶ø
        spleeter_output = os.path.join(temp_folder, "spleeter_output")
        os.makedirs(spleeter_output, exist_ok=True)
        
        # ‡¶™‡ßç‡¶∞‡¶•‡¶Æ‡ßá Spleeter ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®
        try:
            # Spleeter ‡¶ï‡¶Æ‡¶æ‡¶®‡ßç‡¶° ‡¶ö‡¶æ‡¶≤‡¶æ‡¶®
            spleeter_cmd = f'spleeter separate -o "{spleeter_output}" -p spleeter:2stems "{input_audio}"'
            print("Running Spleeter for voice separation...")
            subprocess.run(spleeter_cmd, shell=True, timeout=300)  # 5 ‡¶Æ‡¶ø‡¶®‡¶ø‡¶ü ‡¶ü‡¶æ‡¶á‡¶Æ‡¶Ü‡¶â‡¶ü
            
            # Spleeter ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü ‡¶™‡¶æ‡¶• - ‡¶Ö‡¶°‡¶ø‡¶ì ‡¶®‡¶æ‡¶Æ ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡¶Ø‡¶º‡ßÄ ‡¶´‡ßã‡¶≤‡ßç‡¶°‡¶æ‡¶∞ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßá
            audio_name = os.path.splitext(os.path.basename(input_audio))[0]
            vocals_path = os.path.join(spleeter_output, audio_name, "vocals.wav")
            
            if os.path.exists(vocals_path):
                # ‡¶≠‡¶Ø‡¶º‡ßá‡¶∏ ‡¶ï‡ßã‡¶Ø‡¶º‡¶æ‡¶≤‡¶ø‡¶ü‡¶ø ‡¶â‡¶®‡ßç‡¶®‡¶§ ‡¶ï‡¶∞‡ßÅ‡¶®
                enhance_cmd = (
                    f'ffmpeg -i "{vocals_path}" -af "volume=1.8, ' 
                    f'compand=attacks=0.01:decays=0.1:points=-80/-80|-45/-45|-27/-25|-15/-10|-5/-2|0/0|20/8" '
                    f'-c:a pcm_s16le "{output_audio}" -y'
                )
                subprocess.run(enhance_cmd, shell=True)
                print(f"‚úÖ Successfully separated and enhanced vocals using Spleeter")
                return
            else:
                print(f"‚ö†Ô∏è Spleeter output file not found: {vocals_path}")
                raise FileNotFoundError(f"Spleeter output file not found: {vocals_path}")
                
        except Exception as spleeter_error:
            print(f"‚ö†Ô∏è Spleeter failed or not installed: {spleeter_error}")
            print("Falling back to FFmpeg filters for voice enhancement...")
        
        # ‡¶Ø‡¶¶‡¶ø Spleeter ‡¶¨‡ßç‡¶Ø‡¶∞‡ßç‡¶• ‡¶π‡¶Ø‡¶º, ‡¶§‡¶æ‡¶π‡¶≤‡ßá FFmpeg ‡¶´‡¶ø‡¶≤‡ßç‡¶ü‡¶æ‡¶∞ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®
        # ‡¶â‡¶®‡ßç‡¶®‡¶§ FFmpeg ‡¶Ö‡¶°‡¶ø‡¶ì ‡¶´‡¶ø‡¶≤‡ßç‡¶ü‡¶æ‡¶∞
        audio_filter = (
            "highpass=f=80, " +           # ‡¶®‡¶ø‡¶ö‡ßÅ ‡¶Ü‡¶ì‡¶Ø‡¶º‡¶æ‡¶ú ‡¶¨‡¶æ‡¶¶ ‡¶¶‡¶ø‡¶®
            "lowpass=f=8000, " +          # ‡¶â‡¶ö‡ßç‡¶ö ‡¶Ü‡¶ì‡¶Ø‡¶º‡¶æ‡¶ú ‡¶¨‡¶æ‡¶¶ ‡¶¶‡¶ø‡¶®
            "volume=2.0, " +              # ‡¶≠‡¶≤‡¶ø‡¶â‡¶Æ ‡¶¨‡¶æ‡¶°‡¶º‡¶æ‡¶®
            "compand=attacks=0.01:decays=0.1:" +  # ‡¶°‡¶æ‡¶á‡¶®‡¶æ‡¶Æ‡¶ø‡¶ï ‡¶ï‡¶Æ‡ßç‡¶™‡ßç‡¶∞‡ßá‡¶∂‡¶®
            "points=-80/-80|-45/-45|-27/-25|-15/-10|-5/-2|0/0|20/8"
        )
        
        ffmpeg_cmd = (
            f'ffmpeg -i "{input_audio}" -af "{audio_filter}" '
            f'-c:a pcm_s16le "{output_audio}" -y'
        )
        
        print(f"Running FFmpeg audio enhancement command...")
        subprocess.run(ffmpeg_cmd, shell=True)
        
        # ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü ‡¶´‡¶æ‡¶á‡¶≤ ‡¶Ø‡¶æ‡¶ö‡¶æ‡¶á ‡¶ï‡¶∞‡ßÅ‡¶®
        if os.path.exists(output_audio):
            try:
                out_duration = float(subprocess.check_output(
                    f'ffprobe -i "{output_audio}" -show_entries format=duration -v quiet -of csv="p=0"',
                    shell=True
                ).decode().strip())
                print(f"‚úÖ Enhanced audio duration: {out_duration} seconds ({out_duration/60:.2f} minutes)")
            except:
                print("Could not determine output audio duration")
            
            print(f"‚úÖ Speech enhanced using FFmpeg filters: {output_audio}")
        else:
            print(f"‚ùå Output file not created: {output_audio}")
            # ‡¶™‡ßç‡¶∞‡¶∏‡ßá‡¶∏‡¶ø‡¶Ç ‡¶¨‡ßç‡¶Ø‡¶∞‡ßç‡¶• ‡¶π‡¶≤‡ßá, ‡¶∏‡¶æ‡¶ß‡¶æ‡¶∞‡¶£ ‡¶ï‡¶™‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®
            shutil.copy2(input_audio, output_audio)
            print(f"‚úÖ Copied original file as fallback: {output_audio}")
            
    except Exception as e:
        print(f"‚ùå Error processing audio: {e}")
        # ‡¶∏‡¶¨‡¶ï‡¶ø‡¶õ‡ßÅ ‡¶¨‡ßç‡¶Ø‡¶∞‡ßç‡¶• ‡¶π‡¶≤‡ßá ‡¶∏‡¶æ‡¶ß‡¶æ‡¶∞‡¶£ ‡¶ï‡¶™‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®
        try:
            shutil.copy2(input_audio, output_audio)
            print(f"‚úÖ File copied as fallback: {output_audio}")
        except Exception as copy_error:
            print(f"‚ùå Even fallback copy failed: {copy_error}")
                       
def split_into_chunks(result, words_per_line=5):
    """
    Whisper result ‡¶°‡ßá‡¶ü‡¶æ ‡¶•‡ßá‡¶ï‡ßá (word_timestamps=True) ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶ì‡¶Ø‡¶º‡¶æ‡¶∞‡ßç‡¶° ‡¶®‡¶ø‡¶Ø‡¶º‡ßá 
    ‡¶õ‡ßã‡¶ü ‡¶õ‡ßã‡¶ü ‡¶ö‡¶æ‡¶ô‡ßç‡¶ï (‡¶∏‡¶æ‡¶¨‡¶ü‡¶æ‡¶á‡¶ü‡ßá‡¶≤ ‡¶≤‡¶æ‡¶á‡¶®) ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßá ‡¶∞‡¶ø‡¶ü‡¶æ‡¶∞‡ßç‡¶® ‡¶ï‡¶∞‡¶¨‡ßá‡•§
    """
    all_chunks = []
    current_words = []
    chunk_start_time = None
    chunk_end_time = None

    for seg in result["segments"]:
        for w in seg["words"]:
            if chunk_start_time is None:
                chunk_start_time = w["start"]
            chunk_end_time = w["end"]
            current_words.append(w["word"])

            if (len(current_words) >= words_per_line) or any(punct in w["word"] for punct in [".", "!", "?", ","]):
                text_line = " ".join(current_words).strip()
                all_chunks.append({
                    "start": chunk_start_time,
                    "end": chunk_end_time,
                    "text": text_line
                })
                current_words = []
                chunk_start_time = None
                chunk_end_time = None
    
    if current_words:
        text_line = " ".join(current_words).strip()
        all_chunks.append({
            "start": chunk_start_time,
            "end": chunk_end_time,
            "text": text_line
        })

    return all_chunks

def color_line_dynamically(line, color1="&H00FF00&", color2="&HFFFFFF&", ratio=0.7):
    """
    line: ‡¶Æ‡ßÇ‡¶≤ ‡¶ü‡ßá‡¶ï‡ßç‡¶∏‡¶ü (‡¶è‡¶ï‡¶ü‡¶ø ‡¶∏‡¶æ‡¶¨‡¶ü‡¶æ‡¶á‡¶ü‡ßá‡¶≤ ‡¶≤‡¶æ‡¶á‡¶®)
    color1: ‡¶™‡ßç‡¶∞‡¶•‡¶Æ ‡¶Ö‡¶Ç‡¶∂‡ßá‡¶∞ ‡¶∞‡¶ô (ASS BGR format, ‡¶â‡¶¶‡¶æ‡¶π‡¶∞‡¶£: &H00FF00& = ‡¶∏‡¶¨‡ßÅ‡¶ú)
    color2: ‡¶™‡¶∞‡ßá‡¶∞ ‡¶Ö‡¶Ç‡¶∂‡ßá‡¶∞ ‡¶∞‡¶ô (ASS BGR format, ‡¶â‡¶¶‡¶æ‡¶π‡¶∞‡¶£: &HFFFF00& = ‡¶®‡ßÄ‡¶≤‡¶æ‡¶≠ ‡¶π‡¶≤‡ßÅ‡¶¶ ‡¶®‡¶Ø‡¶º)
    ratio: ‡¶ï‡¶§ ‡¶∂‡¶§‡¶æ‡¶Ç‡¶∂ ‡¶∂‡¶¨‡ßç‡¶¶ color1 ‡¶è ‡¶•‡¶æ‡¶ï‡¶¨‡ßá (‡¶°‡¶ø‡¶´‡¶≤‡ßç‡¶ü 0.7 = 70%)
    """
    words = line.split()
    total_words = len(words)
    if total_words == 0:
        return line

    split_index = int(total_words * ratio)
    if split_index <= 0:
        return f"{{\\c{color2}}}{line}{{\\r}}"
    if split_index >= total_words:
        return f"{{\\c{color1}}}{line}{{\\r}}"

    part1 = words[:split_index]
    part2 = words[split_index:]
    text1 = " ".join(part1)
    text2 = " ".join(part2)
    return f"{{\\c{color1}}}{text1} {{\\c{color2}}}{text2}{{\\r}}"

def generate_subtitles(audio_file, subtitle_file, subtitle_format='srt'):
    """Generate smaller-chunk subtitles from audio file using word timestamps, with dynamic coloring and fade animation."""
    global model
    result = model.transcribe(audio_file, word_timestamps=True, task='transcribe')
    if not result or "segments" not in result or not result["segments"]:
        print(f"‚ùå Transcription failed or empty segments for: {audio_file}")
        with open(subtitle_file, "w", encoding="utf-8") as f:
            f.write("")
        return

    chunks = split_into_chunks(result, words_per_line=5)
    def format_timestamp(seconds):
        hours, remainder = divmod(int(seconds), 3600)
        minutes, secs = divmod(remainder, 60)
        millisecs = int((seconds % 1) * 1000)
        return f"{hours:02}:{minutes:02}:{secs:02},{millisecs:03}"

    fade_tag = r"{\fad(300,300)}"
    with open(subtitle_file, "w", encoding="utf-8") as f:
        for i, chunk in enumerate(chunks, start=1):
            start_ts = format_timestamp(chunk["start"])
            end_ts = format_timestamp(chunk["end"])
            text_line = chunk["text"]
            colored_text = color_line_dynamically(line=text_line, color1="&H00FF00&", color2="&HFFFFFF&", ratio=0.7)
            animated_text = fade_tag + colored_text
            if subtitle_format == 'srt':
                f.write(f"{i}\n{start_ts} --> {end_ts}\n{animated_text}\n\n")
            else:
                f.write(f"{animated_text}\n")
    print(f"‚úÖ Subtitles generated (chunked): {subtitle_file}")

def create_karaoke_line(words, line_start, line_end):
    """
    words: [{'start': float, 'end': float, 'word': string}, ...]
    line_start, line_end: ‡¶™‡ßÅ‡¶∞‡ßã ‡¶≤‡¶æ‡¶á‡¶®‡ßá‡¶∞ ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶ì ‡¶∂‡ßá‡¶∑ ‡¶∏‡¶Æ‡¶Ø‡¶º (‡¶∏‡ßá‡¶ï‡ßá‡¶®‡ßç‡¶°‡ßá)
    ‡¶∞‡¶ø‡¶ü‡¶æ‡¶∞‡ßç‡¶®: \k ‡¶ü‡ßç‡¶Ø‡¶æ‡¶ó‡¶∏‡¶π ‡¶è‡¶ï‡¶ü‡¶ø ‡¶∏‡ßç‡¶ü‡ßç‡¶∞‡¶ø‡¶Ç, ‡¶Ø‡¶æ‡¶§‡ßá ‡¶∂‡¶¨‡ßç‡¶¶‡¶ó‡ßÅ‡¶≤‡ßã‡¶∞ ‡¶â‡¶ö‡ßç‡¶ö‡¶æ‡¶∞‡¶£‡¶ï‡¶æ‡¶≤ ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡¶Ø‡¶º‡ßÄ ‡¶π‡¶æ‡¶á‡¶≤‡¶æ‡¶á‡¶ü ‡¶π‡¶Ø‡¶º‡•§
    """
    karaoke_text = ""
    for w in words:
        w_start = w["start"] - line_start
        w_end = w["end"] - line_start
        duration_sec = max(0, w_end - w_start)
        duration_cs = int(duration_sec * 100)
        karaoke_text += f"{{\\k{duration_cs}}}{w['word']} "
    karaoke_text += "{\\k0}"
    return karaoke_text.strip()

def split_into_chunks_karaoke(result, words_per_line=5):
    """
    Whisper result ‡¶•‡ßá‡¶ï‡ßá word-level ‡¶§‡¶•‡ßç‡¶Ø ‡¶®‡¶ø‡¶Ø‡¶º‡ßá ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶ö‡¶æ‡¶ô‡ßç‡¶ï‡¶ï‡ßá (‡¶™‡ßç‡¶∞‡¶§‡¶ø words_per_line ‡¶ü‡¶ø ‡¶ì‡¶Ø‡¶º‡¶æ‡¶∞‡ßç‡¶° ‡¶¨‡¶æ ‡¶Ø‡¶§‡¶ø ‡¶ö‡¶ø‡¶π‡ßç‡¶®‡ßá)
    ‡¶è‡¶ï‡¶ü‡¶ø ‡¶ï‡¶∞‡ßá "‡¶ï‡ßç‡¶Ø‡¶æ‡¶∞‡¶æ‡¶ì‡¶ï‡ßá ‡¶≤‡¶æ‡¶á‡¶®" ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá ‡¶∞‡¶ø‡¶ü‡¶æ‡¶∞‡ßç‡¶® ‡¶ï‡¶∞‡ßá‡•§
    """
    all_chunks = []
    current_words = []
    chunk_start_time = None
    chunk_end_time = None
    for seg in result["segments"]:
        for w in seg["words"]:
            if chunk_start_time is None:
                chunk_start_time = w["start"]
            chunk_end_time = w["end"]
            current_words.append(w)
            if (len(current_words) >= words_per_line) or any(punct in w["word"] for punct in [".", "!", "?", ","]):
                karaoke_line = create_karaoke_line(current_words, chunk_start_time, chunk_end_time)
                all_chunks.append({
                    "start": chunk_start_time,
                    "end": chunk_end_time,
                    "text": karaoke_line
                })
                current_words = []
                chunk_start_time = None
                chunk_end_time = None
    if current_words:
        karaoke_line = create_karaoke_line(current_words, chunk_start_time, chunk_end_time)
        all_chunks.append({
            "start": chunk_start_time,
            "end": chunk_end_time,
            "text": karaoke_line
        })
    return all_chunks

def generate_subtitles_karaoke_chunked(audio_file, subtitle_file, words_per_line=5):
    """
    Whisper ‡¶•‡ßá‡¶ï‡ßá word-level timestamps ‡¶®‡¶ø‡¶Ø‡¶º‡ßá, ‡¶™‡ßç‡¶∞‡¶§‡¶ø words_per_line ‡¶ì‡¶Ø‡¶º‡¶æ‡¶∞‡ßç‡¶°‡ßá ‡¶ö‡¶æ‡¶ô‡ßç‡¶ï ‡¶ï‡¶∞‡ßá
    ‡¶ï‡ßç‡¶Ø‡¶æ‡¶∞‡¶æ‡¶ì‡¶ï‡ßá ‡¶è‡¶´‡ßá‡¶ï‡ßç‡¶ü ‡¶∏‡¶π .ass ‡¶´‡¶æ‡¶á‡¶≤ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßá‡•§
    """
    global model
    # ‡¶Ö‡¶°‡¶ø‡¶ì ‡¶´‡¶æ‡¶á‡¶≤ ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡¶æ
    audio_tensor = whisper.load_audio(audio_file)  # Ensure this is a numpy array first
    audio_tensor = torch.from_numpy(audio_tensor).float().to(device)  # Convert numpy array to tensor and move it to the device
    
    result = model.transcribe(audio_tensor, word_timestamps=True, task='transcribe')
    if not result or "segments" not in result or not result["segments"]:
        print(f"‚ùå Transcription failed or empty segments for: {audio_file}")
        with open(subtitle_file, "w", encoding="utf-8") as f:
            f.write("")
        return
    chunks = split_into_chunks_karaoke(result, words_per_line=words_per_line)
    subs = pysubs2.SSAFile()
    fade_tag = r"{\fad(300,300)}"
    for chunk in chunks:
        start_ms = chunk["start"] * 1000
        end_ms = chunk["end"] * 1000
        karaoke_line = chunk["text"]
        karaoke_line = fade_tag + karaoke_line
        karaoke_line = karaoke_line.upper()
        event = pysubs2.SSAEvent(
            start=start_ms,
            end=end_ms,
            text=karaoke_line
        )
        subs.append(event)
    subs.styles["Default"].fontname = "Montserrat"
    subs.styles["Default"].fontsize = 24
    subs.styles["Default"].bold = True
    subs.styles["Default"].alignment = 2
    subs.styles["Default"].outline = 4
    subs.styles["Default"].shadow = 3
    subs.styles["Default"].borderstyle = 1
    subs.styles["Default"].marginv = 60
    subs.styles["Default"].secondarycolor = pysubs2.Color(0, 255, 0, 0)
    subs.save(subtitle_file)
    print(f"‚úÖ Karaoke subtitles (chunked) generated: {subtitle_file}")

def generate_subtitles_karaoke(audio_file, subtitle_file):
    """
    Whisper ‡¶•‡ßá‡¶ï‡ßá word-level timestamps ‡¶®‡¶ø‡¶Ø‡¶º‡ßá ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶∏‡ßá‡¶ó‡¶Æ‡ßá‡¶®‡ßç‡¶ü‡¶ï‡ßá ‡¶ï‡ßç‡¶Ø‡¶æ‡¶∞‡¶æ‡¶ì‡¶ï‡ßá ‡¶è‡¶´‡ßá‡¶ï‡ßç‡¶ü ‡¶∏‡¶π .ass ‡¶´‡¶æ‡¶á‡¶≤ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßá‡•§
    """
    global model
    # ‡¶Ö‡¶°‡¶ø‡¶ì ‡¶´‡¶æ‡¶á‡¶≤ ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡¶æ
    audio_tensor = whisper.load_audio(audio_file)  # Ensure this is a numpy array first
    audio_tensor = torch.from_numpy(audio_tensor).float().to(device)  # Convert numpy array to tensor and move it to the device
    
    result = model.transcribe(audio_tensor, word_timestamps=True, task='transcribe')
    if not result or "segments" not in result or not result["segments"]:
        print(f"‚ùå Transcription failed or empty segments for: {audio_file}")
        with open(subtitle_file, "w", encoding="utf-8") as f:
            f.write("")
        return
    subs = pysubs2.SSAFile()
    fade_tag = r"{\fad(300,300)}"
    for seg in result["segments"]:
        seg_start = seg["start"]
        seg_end = seg["end"]
        words = seg["words"]
        if not words:
            continue
        karaoke_line = create_karaoke_line(words, seg_start, seg_end)
        karaoke_line = fade_tag + karaoke_line
        karaoke_line = karaoke_line.upper()
        event = pysubs2.SSAEvent(
            start=seg_start * 1000,
            end=seg_end * 1000,
            text=karaoke_line
        )
        subs.append(event)
    subs.styles["Default"].fontname = "Montserrat"
    subs.styles["Default"].fontsize = 22
    subs.styles["Default"].bold = True
    subs.styles["Default"].alignment = 2
    subs.styles["Default"].outline = 4
    subs.styles["Default"].shadow = 3
    subs.styles["Default"].borderstyle = 1
    subs.styles["Default"].marginv = 60
    subs.styles["Default"].secondarycolor = pysubs2.Color(0, 255, 0, 0)
    karaoke_style = subs.styles["Default"].copy()
    karaoke_style.primarycolor = pysubs2.Color(255, 255, 255, 0)
    karaoke_style.secondarycolor = pysubs2.Color(255, 255, 0, 0)
    subs.styles["Karaoke"] = karaoke_style
    subs.save(subtitle_file)
    print(f"‚úÖ Karaoke subtitles generated: {subtitle_file}")

def clear_audio_and_temp_folders(audio_file, temp_folder):
    """Delete specific audio file and its related temp files."""
    # Delete the specific audio file
    if os.path.isfile(audio_file):
        os.remove(audio_file)
        print(f"‚úÖ Deleted audio file: {audio_file}")

    # Identify temp folder specific to the audio file
    temp_audio_folder = os.path.join(temp_folder, os.path.splitext(os.path.basename(audio_file))[0])

    # Delete the folder and its contents
    if os.path.isdir(temp_audio_folder):
        shutil.rmtree(temp_audio_folder)
        print(f"‚úÖ Deleted temporary folder: {temp_audio_folder}")

def create_video(stock_video, audio_file, output_video, is_short=False, use_karaoke=True, temp_folder=None, use_ai_voice=False, use_face_footage=False):
    """
    ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßá:
      1. ‡¶∏‡ßç‡¶ü‡¶ï ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì ‡¶≤‡ßÅ‡¶™ ‡¶ï‡¶∞‡ßá (‡¶∏‡ßç‡¶ï‡ßá‡¶≤/‡¶™‡ßç‡¶Ø‡¶æ‡¶° ‡¶Ø‡¶¶‡¶ø ‡¶∂‡¶∞‡ßç‡¶ü‡¶∏ ‡¶π‡¶Ø‡¶º)
      2. ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ï‡¶ó‡ßç‡¶∞‡¶æ‡¶â‡¶®‡ßç‡¶° ‡¶Æ‡¶ø‡¶â‡¶ú‡¶ø‡¶ï ‡¶Æ‡¶ø‡¶ï‡ßç‡¶∏ ‡¶ï‡¶∞‡¶æ
      3. ‡¶∏‡¶æ‡¶¨‡¶ü‡¶æ‡¶á‡¶ü‡ßá‡¶≤ ‡¶§‡ßà‡¶∞‡¶ø (karaoke ‡¶¨‡¶æ ‡¶∏‡¶æ‡¶ß‡¶æ‡¶∞‡¶£, use_karaoke ‡¶´‡ßç‡¶≤‡ßç‡¶Ø‡¶æ‡¶ó ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡¶Ø‡¶º‡ßÄ)
      4. ffmpeg ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶∏‡¶¨ ‡¶Æ‡¶æ‡¶∞‡ßç‡¶ú ‡¶ï‡¶∞‡¶æ
      
    ‡¶Ø‡¶¶‡¶ø use_ai_voice=True ‡¶π‡¶Ø‡¶º, ‡¶§‡¶æ‡¶π‡¶≤‡ßá Whisper ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶ü‡ßç‡¶∞‡¶æ‡¶®‡ßç‡¶∏‡¶ï‡ßç‡¶∞‡¶ø‡¶™‡ßç‡¶ü ‡¶ï‡¶∞‡ßá AI ‡¶≠‡¶Ø‡¶º‡ßá‡¶∏ ‡¶ú‡ßá‡¶®‡¶æ‡¶∞‡ßá‡¶ü ‡¶ï‡¶∞‡¶¨‡ßá‡•§
    ‡¶Ø‡¶¶‡¶ø use_face_footage=True ‡¶π‡¶Ø‡¶º, ‡¶§‡¶æ‡¶π‡¶≤‡ßá ‡¶™‡ßç‡¶∞‡¶•‡¶Æ‡ßá ‡¶´‡ßá‡¶∏ ‡¶´‡ßÅ‡¶ü‡ßá‡¶ú ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶¨‡ßá‡•§
    """
    if not temp_folder:
        temp_folder = TEMP_FOLDER
    
    # ‡¶∏‡ßá‡¶®‡¶ø‡¶ü‡¶æ‡¶á‡¶ú ‡¶ï‡¶∞‡¶æ ‡¶Ö‡¶°‡¶ø‡¶ì ‡¶´‡¶æ‡¶á‡¶≤ ‡¶•‡ßá‡¶ï‡ßá ‡¶®‡¶æ‡¶Æ ‡¶®‡¶ø‡¶®
    sanitized_folder_name = os.path.splitext(os.path.basename(audio_file))[0]
    # ‡¶Ö‡¶∞‡¶ø‡¶ú‡¶ø‡¶®‡¶æ‡¶≤ ‡¶´‡¶æ‡¶á‡¶≤ ‡¶®‡¶æ‡¶Æ ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßÅ‡¶®
    original_folder_name = get_original_basename(audio_file)
    
    # ‡¶Ø‡¶¶‡¶ø ‡¶Ö‡¶∞‡¶ø‡¶ú‡¶ø‡¶®‡¶æ‡¶≤ ‡¶´‡ßã‡¶≤‡ßç‡¶°‡¶æ‡¶∞ ‡¶®‡¶æ‡¶Æ ‡¶®‡¶æ ‡¶™‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ ‡¶Ø‡¶æ‡¶Ø‡¶º, ‡¶§‡¶æ‡¶π‡¶≤‡ßá ‡¶∏‡ßá‡¶®‡¶ø‡¶ü‡¶æ‡¶á‡¶ú ‡¶ï‡¶∞‡¶æ ‡¶®‡¶æ‡¶Æ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®
    if not original_folder_name:
        original_folder_name = sanitized_folder_name
    
    # ‡¶´‡ßã‡¶≤‡ßç‡¶°‡¶æ‡¶∞ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶Ö‡¶∞‡¶ø‡¶ú‡¶ø‡¶®‡¶æ‡¶≤ ‡¶®‡¶æ‡¶Æ ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡¶Ø‡¶º‡ßÄ
    if is_short:
        video_folder = os.path.join(OUTPUT_FOLDER, "shorts", original_folder_name)  # Shorts folder
    else:
        video_folder = os.path.join(OUTPUT_FOLDER, original_folder_name)  # Regular video folder
    
    # ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶á‡¶â‡¶®‡¶ø‡¶ï ‡¶ü‡ßá‡¶Æ‡ßç‡¶™ ‡¶´‡ßã‡¶≤‡ßç‡¶°‡¶æ‡¶∞
    video_specific_temp = os.path.join(temp_folder, f"{sanitized_folder_name}_{int(time.time())}")
    os.makedirs(video_specific_temp, exist_ok=True)
    
    # Make sure folder exists
    os.makedirs(video_folder, exist_ok=True)

    # Create video
    try:
        if is_short:
            random_stock = get_random_file(SHORTS_STOCK_VIDEOS_FOLDER, (".mp4", ".mov"))
            used_stock_video = random_stock if random_stock else stock_video
        else:
            random_stock = get_random_file(STOCK_VIDEOS_FOLDER, (".mp4", ".mov"))
            used_stock_video = random_stock if random_stock else stock_video

        print(f"üé¨ Creating video (is_short={is_short}, karaoke={use_karaoke}, ai_voice={use_ai_voice}, face_footage={use_face_footage}): {output_video} ...")
        
        # ‡¶Ø‡¶¶‡¶ø AI ‡¶≠‡¶Ø‡¶º‡ßá‡¶∏ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶§‡ßá ‡¶π‡¶Ø‡¶º
        if use_ai_voice:
            # Whisper ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶ü‡ßç‡¶∞‡¶æ‡¶®‡ßç‡¶∏‡¶ï‡ßç‡¶∞‡¶ø‡¶™‡ßç‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®
            print("üéôÔ∏è Transcribing audio for AI voice generation...")
            transcript = transcribe_audio(audio_file)
            
            if transcript:
                # AI ‡¶≠‡¶Ø‡¶º‡ßá‡¶∏ ‡¶ú‡ßá‡¶®‡¶æ‡¶∞‡ßá‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®
                ai_voice_file = transcribe_and_generate_ai_voice(transcript, sanitized_folder_name, video_specific_temp)
                
                if ai_voice_file and os.path.exists(ai_voice_file):
                    print(f"‚úÖ Using AI voice: {ai_voice_file}")
                    
                    # AI ‡¶≠‡¶Ø‡¶º‡ßá‡¶∏‡ßá‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ï‡¶ó‡ßç‡¶∞‡¶æ‡¶â‡¶®‡ßç‡¶° ‡¶Æ‡¶ø‡¶â‡¶ú‡¶ø‡¶ï ‡¶Æ‡¶ø‡¶ï‡ßç‡¶∏ ‡¶ï‡¶∞‡ßÅ‡¶®
                    bgm_file = get_random_file(BACKGROUND_MUSIC_FOLDER, (".mp3", ".wav"))
                    if bgm_file:
                        mixed_audio = os.path.join(video_specific_temp, "mixed_audio.m4a")
                        
                        # ‡¶â‡¶®‡ßç‡¶®‡¶§ ‡¶Æ‡¶ø‡¶ï‡ßç‡¶∏‡¶ø‡¶Ç ‡¶´‡¶ø‡¶≤‡ßç‡¶ü‡¶æ‡¶∞:
                        # 1. ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ï‡¶ó‡ßç‡¶∞‡¶æ‡¶â‡¶®‡ßç‡¶° ‡¶Æ‡¶ø‡¶â‡¶ú‡¶ø‡¶ï‡ßá‡¶∞ ‡¶≠‡¶≤‡¶ø‡¶â‡¶Æ ‡¶Ü‡¶∞‡ßã ‡¶ï‡¶Æ‡¶ø‡¶Ø‡¶º‡ßá ‡¶¶‡ßá‡¶ì‡¶Ø‡¶º‡¶æ (0.1 ‡¶•‡ßá‡¶ï‡ßá 0.05)
                        # 2. ‡¶∏‡ßç‡¶™‡¶ø‡¶ö ‡¶≠‡¶≤‡¶ø‡¶â‡¶Æ ‡¶¨‡¶æ‡¶°‡¶º‡¶æ‡¶®‡ßã (1.5x)
                        # 3. ‡¶Æ‡¶ø‡¶ï‡ßç‡¶∏‡¶ø‡¶Ç ‡¶è‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶ì‡¶Ø‡¶º‡ßá‡¶ü‡ßá‡¶ú ‡¶™‡¶∞‡¶ø‡¶¨‡¶∞‡ßç‡¶§‡¶® (‡¶∏‡ßç‡¶™‡¶ø‡¶ö‡¶ï‡ßá ‡¶Ö‡¶ó‡ßç‡¶∞‡¶æ‡¶ß‡¶ø‡¶ï‡¶æ‡¶∞ ‡¶¶‡ßá‡¶ì‡¶Ø‡¶º‡¶æ)
                        mix_cmd = (
                            f'ffmpeg -i "{ai_voice_file}" -i "{bgm_file}" -filter_complex '
                            f'"[0:a]volume=1.5[speech];'
                            f'[1:a]aloop=loop=-1:size=2*44100*60,volume=0.05[music];'
                            f'[speech][music]amix=inputs=2:duration=first:weights=10 1:dropout_transition=3" '
                            f'-c:a aac -b:a 192k "{mixed_audio}" -y'
                        )
                        
                        subprocess.run(mix_cmd, shell=True)
                        
                        # ‡¶Ø‡¶æ‡¶ö‡¶æ‡¶á ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶Ø‡ßá ‡¶Æ‡¶ø‡¶ï‡ßç‡¶∏ ‡¶∏‡¶´‡¶≤ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá
                        if os.path.exists(mixed_audio) and os.path.getsize(mixed_audio) > 0:
                            print(f"‚úÖ Mixed audio with enhanced speech volume and reduced background music")
                            final_audio = mixed_audio
                        else:
                            print(f"‚ö†Ô∏è Failed to mix audio, using original AI voice")
                            final_audio = ai_voice_file
                    else:
                        final_audio = ai_voice_file
                        print("‚ö†Ô∏è No background music found, using AI voice without music")
                else:
                    print("‚ùå AI voice generation failed, using original audio")
                    final_audio = audio_file
            else:
                print("‚ùå Transcription failed, using original audio")
                final_audio = audio_file
        else:
            # ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ï‡¶ó‡ßç‡¶∞‡¶æ‡¶â‡¶®‡ßç‡¶° ‡¶Æ‡¶ø‡¶â‡¶ú‡¶ø‡¶ï ‡¶Æ‡¶ø‡¶ï‡ßç‡¶∏ ‡¶ï‡¶∞‡ßÅ‡¶® (‡¶Ø‡¶¶‡¶ø AI ‡¶≠‡¶Ø‡¶º‡ßá‡¶∏ ‡¶®‡¶æ ‡¶π‡¶Ø‡¶º)
            # ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ï‡¶ó‡ßç‡¶∞‡¶æ‡¶â‡¶®‡ßç‡¶° ‡¶Æ‡¶ø‡¶â‡¶ú‡¶ø‡¶ï ‡¶Æ‡¶ø‡¶ï‡ßç‡¶∏‡¶ø‡¶Ç ‡¶Ö‡¶Ç‡¶∂ ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶® (‡¶Ø‡¶¶‡¶ø AI ‡¶≠‡¶Ø‡¶º‡ßá‡¶∏ ‡¶®‡¶æ ‡¶π‡¶Ø‡¶º)
            bgm_file = get_random_file(BACKGROUND_MUSIC_FOLDER, (".mp3", ".wav"))
            if bgm_file:
                mixed_audio = os.path.join(video_specific_temp, "mixed_audio.m4a")
                
                # ‡¶â‡¶®‡ßç‡¶®‡¶§ ‡¶Æ‡¶ø‡¶ï‡ßç‡¶∏‡¶ø‡¶Ç ‡¶´‡¶ø‡¶≤‡ßç‡¶ü‡¶æ‡¶∞:
                # 1. ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ï‡¶ó‡ßç‡¶∞‡¶æ‡¶â‡¶®‡ßç‡¶° ‡¶Æ‡¶ø‡¶â‡¶ú‡¶ø‡¶ï‡ßá‡¶∞ ‡¶≠‡¶≤‡¶ø‡¶â‡¶Æ ‡¶Ü‡¶∞‡ßã ‡¶ï‡¶Æ‡¶ø‡¶Ø‡¶º‡ßá ‡¶¶‡ßá‡¶ì‡¶Ø‡¶º‡¶æ (0.1 ‡¶•‡ßá‡¶ï‡ßá 0.05)
                # 2. ‡¶∏‡ßç‡¶™‡¶ø‡¶ö ‡¶≠‡¶≤‡¶ø‡¶â‡¶Æ ‡¶¨‡¶æ‡¶°‡¶º‡¶æ‡¶®‡ßã (1.5x)
                # 3. ‡¶Æ‡¶ø‡¶ï‡ßç‡¶∏‡¶ø‡¶Ç ‡¶è‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶ì‡¶Ø‡¶º‡ßá‡¶ü‡ßá‡¶ú ‡¶™‡¶∞‡¶ø‡¶¨‡¶∞‡ßç‡¶§‡¶® (‡¶∏‡ßç‡¶™‡¶ø‡¶ö‡¶ï‡ßá ‡¶Ö‡¶ó‡ßç‡¶∞‡¶æ‡¶ß‡¶ø‡¶ï‡¶æ‡¶∞ ‡¶¶‡ßá‡¶ì‡¶Ø‡¶º‡¶æ)
                mix_cmd = (
                    f'ffmpeg -i "{audio_file}" -i "{bgm_file}" -filter_complex '
                    f'"[0:a]volume=1.5[speech];'
                    f'[1:a]aloop=loop=-1:size=2*44100*60,volume=0.05[music];'
                    f'[speech][music]amix=inputs=2:duration=first:weights=10 1:dropout_transition=3" '
                    f'-c:a aac -b:a 192k "{mixed_audio}" -y'
                )
                
                subprocess.run(mix_cmd, shell=True)
                
                # ‡¶Ø‡¶æ‡¶ö‡¶æ‡¶á ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶Ø‡ßá ‡¶Æ‡¶ø‡¶ï‡ßç‡¶∏ ‡¶∏‡¶´‡¶≤ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá
                if os.path.exists(mixed_audio) and os.path.getsize(mixed_audio) > 0:
                    print(f"‚úÖ Mixed audio with enhanced speech volume and reduced background music")
                    final_audio = mixed_audio
                else:
                    print(f"‚ö†Ô∏è Failed to mix audio, using original enhanced audio")
                    final_audio = audio_file
            else:
                final_audio = audio_file

        # ‡¶Ö‡¶°‡¶ø‡¶ì ‡¶°‡¶ø‡¶â‡¶∞‡ßá‡¶∂‡¶® ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶®
        audio_duration = float(
            subprocess.check_output(
                f'ffprobe -i "{final_audio}" -show_entries format=duration -v quiet -of csv="p=0"',
                shell=True
            ).decode().strip()
        )
        short_duration = min(audio_duration, 60) if is_short else audio_duration
        print(f"üìä Final audio duration: {short_duration:.2f}s")
        
        # ‡¶´‡ßá‡¶∏ ‡¶´‡ßÅ‡¶ü‡ßá‡¶ú ‡¶™‡ßç‡¶∞‡¶∏‡ßá‡¶∏‡¶ø‡¶Ç
        # ‡¶è‡¶á ‡¶Ö‡¶Ç‡¶∂‡¶ü‡¶ø create_video ‡¶´‡¶æ‡¶Ç‡¶∂‡¶®‡ßá‡¶∞ ‡¶≠‡¶ø‡¶§‡¶∞‡ßá ‡¶∞‡¶æ‡¶ñ‡ßÅ‡¶®, ‡¶Ø‡ßá‡¶ñ‡¶æ‡¶®‡ßá ‡¶´‡ßá‡¶∏ ‡¶´‡ßÅ‡¶ü‡ßá‡¶ú ‡¶™‡ßç‡¶∞‡¶∏‡ßá‡¶∏ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º

        if use_face_footage:
            print("üé≠ Processing face footage with guaranteed timing method...")
            # ‡¶´‡ßá‡¶∏ ‡¶´‡ßÅ‡¶ü‡ßá‡¶ú ‡¶®‡¶ø‡¶® (‡¶∏‡¶∞‡ßç‡¶¨‡ßã‡¶ö‡ßç‡¶ö 5 ‡¶∏‡ßá‡¶ï‡ßá‡¶®‡ßç‡¶°‡ßá‡¶∞)
            face_footage = face_handler.get_random_face_footage(is_short=is_short, max_duration=5.0)
            
            if not face_footage or not os.path.exists(face_footage):
                print("‚ö†Ô∏è No face footage available or file does not exist, using only stock footage")
                use_face_footage = False
            else:
                try:
                    # ‡¶è‡¶ï‡¶ü‡¶ø ‡¶∏‡¶Æ‡ßç‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶®‡¶§‡ßÅ‡¶® ‡¶™‡¶¶‡ßç‡¶ß‡¶§‡¶ø ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶æ:
                    # 1. ‡¶™‡ßç‡¶∞‡¶•‡¶Æ‡ßá ‡¶è‡¶Æ‡¶® ‡¶è‡¶ï‡¶ü‡¶ø ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶¨‡ßã ‡¶Ø‡ßá‡¶ü‡¶ø ‡¶∏‡ßç‡¶ü‡¶ï ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì‡¶∞ ‡¶≤‡ßÅ‡¶™‡¶ø‡¶Ç ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶™‡ßÅ‡¶∞‡ßã ‡¶Ö‡¶°‡¶ø‡¶ì ‡¶¶‡ßà‡¶∞‡ßç‡¶ò‡ßç‡¶Ø ‡¶ï‡¶≠‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá
                    # 2. ‡¶§‡¶æ‡¶∞‡¶™‡¶∞ ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì‡¶∞ ‡¶∂‡ßÅ‡¶∞‡ßÅ‡¶§‡ßá ‡¶´‡ßá‡¶∏ ‡¶´‡ßÅ‡¶ü‡ßá‡¶ú ‡¶¨‡¶∏‡¶ø‡¶Ø‡¶º‡ßá ‡¶¶‡ßá‡¶¨‡ßã ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì ‡¶è‡¶°‡¶ø‡¶ü‡¶ø‡¶Ç ‡¶™‡¶¶‡ßç‡¶ß‡¶§‡¶ø‡¶§‡ßá
                    # ‡¶è‡¶§‡ßá ‡¶ü‡¶æ‡¶á‡¶Æ‡¶ø‡¶Ç ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶è‡¶°‡¶º‡¶æ‡¶®‡ßã ‡¶Ø‡¶æ‡¶¨‡ßá
                    
                    # ‡¶∏‡ßç‡¶ü‡ßá‡¶™ 1: ‡¶∏‡¶Æ‡ßç‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶Ö‡¶°‡¶ø‡¶ì ‡¶¶‡ßà‡¶∞‡ßç‡¶ò‡ßç‡¶Ø‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶∏‡ßç‡¶ü‡¶ï ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®
                    full_stock_video = os.path.join(video_specific_temp, "full_stock.mp4")
                    
                    if is_short:
                        # ‡¶∂‡¶∞‡ßç‡¶ü‡¶∏ ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì‡¶∞ ‡¶ï‡ßç‡¶∑‡ßá‡¶§‡ßç‡¶∞‡ßá ‡¶∏‡ßç‡¶ï‡ßá‡¶≤ ‡¶ï‡¶∞‡ßÅ‡¶®
                        scale_filter = "scale=1080:1920:force_original_aspect_ratio=decrease,pad=1080:1920:(ow-iw)/2:(oh-ih)/2"
                        stock_cmd = (
                            f'ffmpeg -stream_loop -1 -i "{used_stock_video}" -t {short_duration} '
                            f'-vf "{scale_filter}" -c:v libx264 -an -preset ultrafast -crf 23 '
                            f'"{full_stock_video}" -y'
                        )
                    else:
                        # ‡¶∞‡ßá‡¶ó‡ßÅ‡¶≤‡¶æ‡¶∞ ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì‡¶∞ ‡¶ï‡ßç‡¶∑‡ßá‡¶§‡ßç‡¶∞‡ßá
                        stock_cmd = (
                            f'ffmpeg -stream_loop -1 -i "{used_stock_video}" -t {short_duration} '
                            f'-c:v libx264 -an -preset ultrafast -crf 23 "{full_stock_video}" -y'
                        )
                    
                    subprocess.run(stock_cmd, shell=True)
                    print(f"‚úÖ Created full-length stock video base")
                    
                    # ‡¶∏‡ßç‡¶ü‡ßá‡¶™ 2: ‡¶´‡ßá‡¶∏ ‡¶´‡ßÅ‡¶ü‡ßá‡¶ú ‡¶™‡ßç‡¶∞‡¶∏‡ßá‡¶∏ ‡¶ï‡¶∞‡ßÅ‡¶® (‡¶∏‡ßç‡¶ï‡ßá‡¶≤, ‡¶Ü‡¶ï‡¶æ‡¶∞ ‡¶á‡¶§‡ßç‡¶Ø‡¶æ‡¶¶‡¶ø)
                    face_processed = os.path.join(video_specific_temp, "face_processed.mp4")
                    
                    # ‡¶´‡ßá‡¶∏ ‡¶´‡ßÅ‡¶ü‡ßá‡¶ú‡ßá‡¶∞ ‡¶¶‡ßà‡¶∞‡ßç‡¶ò‡ßç‡¶Ø ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶®
                    face_duration = float(
                        subprocess.check_output(
                            f'ffprobe -i "{face_footage}" -show_entries format=duration -v quiet -of csv="p=0"',
                            shell=True
                        ).decode().strip()
                    )
                    print(f"‚úÖ Face footage duration: {face_duration:.2f}s")
                    
                    # ‡¶´‡ßá‡¶∏ ‡¶´‡ßÅ‡¶ü‡ßá‡¶ú‡ßá‡¶∞ ‡¶¶‡ßà‡¶∞‡ßç‡¶ò‡ßç‡¶Ø ‡¶∏‡ßÄ‡¶Æ‡¶ø‡¶§ ‡¶ï‡¶∞‡ßÅ‡¶® (5 ‡¶∏‡ßá‡¶ï‡ßá‡¶®‡ßç‡¶°‡ßá‡¶∞ ‡¶¨‡ßá‡¶∂‡¶ø ‡¶®‡¶Ø‡¶º)
                    face_duration = min(face_duration, 5.0)
                    
                    if is_short:
                        face_cmd = (
                            f'ffmpeg -i "{face_footage}" -t {face_duration} '
                            f'-vf "{scale_filter}" -c:v libx264 -an -preset ultrafast -crf 23 '
                            f'"{face_processed}" -y'
                        )
                    else:
                        face_cmd = (
                            f'ffmpeg -i "{face_footage}" -t {face_duration} '
                            f'-c:v libx264 -an -preset ultrafast -crf 23 "{face_processed}" -y'
                        )
                    
                    subprocess.run(face_cmd, shell=True)
                    print(f"‚úÖ Processed face footage (limited to {face_duration:.2f}s)")
                    
                    # ‡¶∏‡ßç‡¶ü‡ßá‡¶™ 3: ‡¶è‡¶ï‡¶ü‡¶æ 1-‡¶™‡ßç‡¶Ø‡¶æ‡¶∏ ‡¶ï‡¶Æ‡¶æ‡¶®‡ßç‡¶°‡ßá ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì ‡¶è‡¶°‡¶ø‡¶ü‡¶ø‡¶Ç‡¶Ø‡¶º‡ßá‡¶∞ ‡¶Æ‡¶æ‡¶ß‡ßç‡¶Ø‡¶Æ‡ßá ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®
                    # overlay + enable=, seekable=1 ‡¶ï‡¶Æ‡¶æ‡¶®‡ßç‡¶° ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá ‡¶è‡¶ï‡¶ü‡¶ø ‡¶´‡ßÅ‡¶≤ ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶¨‡ßã
                    # ‡¶è‡¶ü‡¶æ ‡¶è‡¶ï‡¶á FFmpeg ‡¶™‡ßç‡¶∞‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ‡¶Ø‡¶º ‡¶ï‡¶∞‡¶¨‡ßá, ‡¶Ø‡¶æ‡¶§‡ßá ‡¶∏‡¶ø‡¶ô‡ßç‡¶ï‡¶ø‡¶Ç ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶®‡¶æ ‡¶π‡¶Ø‡¶º
                    
                    final_no_audio = os.path.join(video_specific_temp, "final_no_audio.mp4")
                    
                    # ‡¶è‡¶ñ‡¶æ‡¶®‡ßá overlay ‡¶´‡¶ø‡¶≤‡ßç‡¶ü‡¶æ‡¶∞ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá, ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì‡¶∞ ‡¶∂‡ßÅ‡¶∞‡ßÅ‡¶§‡ßá ‡¶´‡ßá‡¶∏ ‡¶´‡ßÅ‡¶ü‡ßá‡¶ú ‡¶™‡ßç‡¶≤‡ßá‡¶∏ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶ö‡ßç‡¶õ‡ßá
                    # ‡¶è‡¶¨‡¶Ç 5 ‡¶∏‡ßá‡¶ï‡ßá‡¶®‡ßç‡¶° ‡¶¨‡¶æ face_duration ‡¶™‡¶∞‡ßç‡¶Ø‡¶®‡ßç‡¶§ ‡¶¶‡ßá‡¶ñ‡¶æ‡¶®‡ßã ‡¶π‡¶ö‡ßç‡¶õ‡ßá ‡¶∂‡ßÅ‡¶ß‡ßÅ
                    concat_cmd = (
                        f'ffmpeg -i "{full_stock_video}" -i "{face_processed}" -filter_complex '
                        f'"[1:v]setpts=PTS-STARTPTS[face];'
                        f'[0:v][face]overlay=0:0:enable=\'between(t,0,{face_duration})\''
                        f'[outv]" -map "[outv]" -an -c:v libx264 -preset fast -crf 22 '
                        f'"{final_no_audio}" -y'
                    )
                    
                    subprocess.run(concat_cmd, shell=True)
                    
                    # ‡¶Ø‡¶æ‡¶ö‡¶æ‡¶á ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶Ø‡ßá ‡¶è‡¶°‡¶ø‡¶ü‡¶ø‡¶Ç ‡¶∏‡¶´‡¶≤ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá
                    if os.path.exists(final_no_audio) and os.path.getsize(final_no_audio) > 1000:  # ‡¶Ö‡¶®‡ßç‡¶§‡¶§ 1KB
                        # ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì‡¶∞ ‡¶¶‡ßà‡¶∞‡ßç‡¶ò‡ßç‡¶Ø ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶®
                        try:
                            video_duration = float(
                                subprocess.check_output(
                                    f'ffprobe -i "{final_no_audio}" -show_entries format=duration -v quiet -of csv="p=0"',
                                    shell=True
                                ).decode().strip()
                            )
                            print(f"‚úÖ Final video duration: {video_duration:.2f}s, Audio duration: {short_duration:.2f}s")
                            
                            # ‡¶Ø‡¶¶‡¶ø ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì ‡¶¶‡ßà‡¶∞‡ßç‡¶ò‡ßç‡¶Ø ‡¶Ö‡¶°‡¶ø‡¶ì ‡¶¶‡ßà‡¶∞‡ßç‡¶ò‡ßç‡¶Ø‡ßá‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá ‡¶Æ‡ßá‡¶≤‡ßá ‡¶®‡¶æ, ‡¶§‡¶æ‡¶π‡¶≤‡ßá ‡¶ü‡ßç‡¶∞‡¶ø‡¶Æ ‡¶ï‡¶∞‡ßÅ‡¶®
                            if abs(video_duration - short_duration) > 0.5:  # ‡¶Ø‡¶¶‡¶ø 0.5 ‡¶∏‡ßá‡¶ï‡ßá‡¶®‡ßç‡¶°‡ßá‡¶∞ ‡¶¨‡ßá‡¶∂‡¶ø ‡¶™‡¶æ‡¶∞‡ßç‡¶•‡¶ï‡ßç‡¶Ø ‡¶π‡¶Ø‡¶º
                                print(f"‚ö†Ô∏è Video duration mismatch, trimming to match audio")
                                trimmed_video = os.path.join(video_specific_temp, "trimmed_video.mp4")
                                trim_cmd = (
                                    f'ffmpeg -i "{final_no_audio}" -t {short_duration} '
                                    f'-c:v copy "{trimmed_video}" -y'
                                )
                                subprocess.run(trim_cmd, shell=True)
                                final_no_audio = trimmed_video
                        except Exception as e:
                            print(f"‚ö†Ô∏è Could not check video duration: {e}")
                        
                        used_video = final_no_audio
                        print(f"‚úÖ Successfully created face+stock combined video")
                    else:
                        print(f"‚ö†Ô∏è Video editing failed, falling back to stock footage only")
                        use_face_footage = False
                
                except Exception as e:
                    print(f"‚ùå Error processing face footage: {e}")
                    use_face_footage = False
        
        # ‡¶Ø‡¶¶‡¶ø ‡¶´‡ßá‡¶∏ ‡¶´‡ßÅ‡¶ü‡ßá‡¶ú ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶®‡¶æ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º ‡¶¨‡¶æ ‡¶§‡ßç‡¶∞‡ßÅ‡¶ü‡¶ø ‡¶π‡¶Ø‡¶º, ‡¶§‡¶æ‡¶π‡¶≤‡ßá ‡¶∏‡ßç‡¶ü‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶°‡¶æ‡¶∞‡ßç‡¶° ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì ‡¶™‡ßç‡¶∞‡¶∏‡ßá‡¶∏‡¶ø‡¶Ç
        if not use_face_footage:
            print("üé¨ Using only stock footage...")
            # ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì ‡¶≤‡ßÅ‡¶™ ‡¶ï‡¶∞‡ßá ‡¶ì ‡¶Ö‡¶®‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶Ø ‡¶™‡ßç‡¶∞‡¶∏‡ßá‡¶∏‡¶ø‡¶Ç ‡¶è‡¶ï‡¶∏‡¶æ‡¶•‡ßá ‡¶ï‡¶∞‡ßÅ‡¶®
            stock_only_video = os.path.join(video_specific_temp, "stock_only.mp4")
            
            if is_short:
                scale_filter = (
                    "scale=1080:1920:force_original_aspect_ratio=decrease,"
                    "pad=1080:1920:(ow-iw)/2:(oh-ih)/2"
                )
                stock_cmd = (
                    f'ffmpeg -stream_loop -1 -i "{used_stock_video}" -t {short_duration} '
                    f'-vf "{scale_filter}" -c:v libx264 -an -preset ultrafast -crf 22 "{stock_only_video}" -y'
                )
            else:
                stock_cmd = (
                    f'ffmpeg -stream_loop -1 -i "{used_stock_video}" -t {short_duration} '
                    f'-c:v libx264 -an -preset ultrafast -crf 22 "{stock_only_video}" -y'
                )
            
            subprocess.run(stock_cmd, shell=True)
            used_video = stock_only_video
        
        # ‡¶∏‡¶æ‡¶¨‡¶ü‡¶æ‡¶á‡¶ü‡ßá‡¶≤ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶® - ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ ‡¶á‡¶â‡¶®‡¶ø‡¶ï ‡¶´‡¶æ‡¶á‡¶≤‡¶®‡¶æ‡¶Æ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®
        unique_subtitle_id = f"{sanitized_folder_name}_{int(time.time())}"
        temp_subtitle_ass = os.path.join(video_specific_temp, f"subtitles_{unique_subtitle_id}.ass")
        
        if use_ai_voice:
            # AI ‡¶≠‡¶Ø‡¶º‡ßá‡¶∏‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶∏‡¶æ‡¶¨‡¶ü‡¶æ‡¶á‡¶ü‡ßá‡¶≤ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®
            if use_karaoke:
                generate_subtitles_karaoke_chunked(final_audio, temp_subtitle_ass, words_per_line=5)
            else:
                # ‡¶á‡¶â‡¶®‡¶ø‡¶ï ‡¶®‡¶æ‡¶Æ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®
                temp_subtitle_srt = os.path.join(video_specific_temp, f"subtitles_{unique_subtitle_id}.srt")
                generate_subtitles(final_audio, temp_subtitle_srt, subtitle_format='srt')
                convert_srt_to_ass(temp_subtitle_srt, temp_subtitle_ass, is_short=is_short)
        else:
            # ‡¶®‡¶∞‡¶Æ‡¶æ‡¶≤ ‡¶Ö‡¶°‡¶ø‡¶ì‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶∏‡¶æ‡¶¨‡¶ü‡¶æ‡¶á‡¶ü‡ßá‡¶≤ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®
            if use_karaoke:
                generate_subtitles_karaoke_chunked(final_audio, temp_subtitle_ass, words_per_line=5)
            else:
                # ‡¶á‡¶â‡¶®‡¶ø‡¶ï ‡¶®‡¶æ‡¶Æ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®
                temp_subtitle_srt = os.path.join(video_specific_temp, f"subtitles_{unique_subtitle_id}.srt")
                generate_subtitles(final_audio, temp_subtitle_srt, subtitle_format='srt')
                convert_srt_to_ass(temp_subtitle_srt, temp_subtitle_ass, is_short=is_short)

        # ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì, ‡¶Ö‡¶°‡¶ø‡¶ì ‡¶è‡¶¨‡¶Ç ‡¶∏‡¶æ‡¶¨‡¶ü‡¶æ‡¶á‡¶ü‡ßá‡¶≤ ‡¶è‡¶ï‡¶§‡ßç‡¶∞‡¶ø‡¶§ ‡¶ï‡¶∞‡ßÅ‡¶®
        subtitle_path = os.path.abspath(temp_subtitle_ass).replace("\\", "/").replace(":", "\\:")
        merge_cmd = (
            f'ffmpeg -i "{used_video}" -i "{final_audio}" '
            f'-map 0:v -map 1:a '
            f'-vf "drawbox=x=0:y=0:w=iw:h=ih:color=black@0.5:t=fill,ass=\'{subtitle_path}\'" '
            f'-c:v libx264 -c:a aac -preset fast -crf 18 -r 30 "{output_video}" -y'
        )
        subprocess.run(merge_cmd, shell=True)

        # ‡¶´‡¶æ‡¶á‡¶®‡¶æ‡¶≤ ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì ‡¶´‡¶æ‡¶á‡¶≤ ‡¶®‡¶æ‡¶Æ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®
        final_video_path = os.path.join(video_folder, f"{sanitized_folder_name}.mp4")
        
        # ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì ‡¶•‡ßá‡¶ï‡ßá ‡¶´‡¶æ‡¶á‡¶®‡¶æ‡¶≤ ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì ‡¶™‡¶æ‡¶•‡ßá ‡¶Æ‡ßÅ‡¶≠ ‡¶ï‡¶∞‡ßÅ‡¶®
        os.rename(output_video, final_video_path)
        print(f"‚úÖ Final Video Created: {final_video_path}")
        
        # ‡¶ü‡ßá‡¶ï‡ßç‡¶∏‡¶ü ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü ‡¶´‡¶æ‡¶á‡¶≤ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®
        # Whisper ‡¶è‡¶∞ ‡¶Æ‡¶æ‡¶ß‡ßç‡¶Ø‡¶Æ‡ßá ‡¶Ö‡¶°‡¶ø‡¶ì ‡¶•‡ßá‡¶ï‡ßá ‡¶ü‡ßç‡¶∞‡¶æ‡¶®‡ßç‡¶∏‡¶ï‡ßç‡¶∞‡¶ø‡¶™‡ßç‡¶ü ‡¶ï‡¶∞‡¶æ
        transcribe = transcribe_audio(audio_file)
        if transcribe:
            # ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì ‡¶ü‡¶æ‡¶á‡¶ü‡ßá‡¶≤ ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡¶Ø‡¶º‡ßÄ ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü ‡¶´‡¶æ‡¶á‡¶≤ ‡¶®‡¶æ‡¶Æ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶æ
            output_text_path = os.path.join(video_folder, f"{sanitized_folder_name}_output.txt")
            # Azure OpenAI API ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶æ
            generate_output_from_azure(transcribe, original_folder_name, output_text_path)
        
        # ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì ‡¶§‡ßà‡¶∞‡¶ø ‡¶∂‡ßá‡¶∑‡ßá ‡¶Æ‡ßá‡¶ü‡¶æ‡¶°‡ßá‡¶ü‡¶æ ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡¶§‡ßá ‡¶ï‡¶≤ ‡¶ï‡¶∞‡ßÅ‡¶®
        if process_video_metadata(final_video_path):
            print("Metadata update was successful.")
        else:
            print("‚ùå Failed to update metadata.")
        
        print(f"‚úÖ Video and text saved to: {video_folder}")

        # AI ‡¶≠‡¶Ø‡¶º‡ßá‡¶∏ ‡¶´‡¶æ‡¶á‡¶≤ ‡¶°‡¶ø‡¶≤‡¶ø‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶® (‡¶ê‡¶ö‡ßç‡¶õ‡¶ø‡¶ï)
        if use_ai_voice and final_audio != audio_file and os.path.exists(final_audio):
            os.remove(final_audio)
            print(f"üóëÔ∏è Deleted AI voice file: {final_audio}")
            
        # ‡¶∏‡¶¨‡¶∂‡ßá‡¶∑‡ßá ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì-‡¶∏‡ßç‡¶™‡ßá‡¶∏‡¶ø‡¶´‡¶ø‡¶ï ‡¶ü‡ßá‡¶Æ‡ßç‡¶™ ‡¶´‡ßã‡¶≤‡ßç‡¶°‡¶æ‡¶∞ ‡¶°‡¶ø‡¶≤‡¶ø‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®
        try:
            shutil.rmtree(video_specific_temp)
            print(f"üóëÔ∏è Cleaned up temporary folder: {video_specific_temp}")
        except Exception as e:
            print(f"‚ö†Ô∏è Could not clean up temp folder: {e}")

        return True  # Return True if video creation is successful

    except Exception as e:
        print(f"‚ùå Error creating video for {audio_file}: {e}")
        print(f"‚ö†Ô∏è Full error message: {e}")  # ‡¶§‡ßç‡¶∞‡ßÅ‡¶ü‡¶ø‡¶∞ ‡¶¨‡¶ø‡¶∏‡ßç‡¶§‡¶æ‡¶∞‡¶ø‡¶§ ‡¶¨‡¶æ‡¶∞‡ßç‡¶§‡¶æ ‡¶¶‡ßá‡¶ñ‡¶æ‡¶ì
        print("‚ö†Ô∏è Skipping this audio and moving to the next one...")
        return False

def process_audio_in_parallel(audio_file, is_short=False, prefix='', suffix='', use_ai_voice=False, use_face_footage=False):
    """‡¶è‡¶ï‡¶ü‡¶ø ‡¶Ö‡¶°‡¶ø‡¶ì ‡¶´‡¶æ‡¶á‡¶≤ ‡¶™‡ßç‡¶∞‡¶∏‡ßá‡¶∏ ‡¶ï‡¶∞‡ßá (‡¶®‡¶∞‡¶Æ‡¶æ‡¶≤ ‡¶¨‡¶æ ‡¶∂‡¶∞‡ßç‡¶ü‡¶∏) ‡¶™‡ßç‡¶Ø‡¶æ‡¶∞‡¶æ‡¶≤‡ßá‡¶≤ ‡¶•‡ßç‡¶∞‡ßá‡¶°‡ßá ‡¶ö‡¶æ‡¶≤‡¶æ‡¶Ø‡¶º‡•§"""
    audio_name = os.path.splitext(os.path.basename(audio_file))[0]
    
    audio_temp_folder = os.path.join(TEMP_FOLDER, audio_name)
    os.makedirs(audio_temp_folder, exist_ok=True)
    filtered_audio = os.path.join(audio_temp_folder, f"{audio_name}_filtered.wav")
    
    output_video = get_output_filename(audio_file, is_short, prefix, suffix)
    
    # ‡¶Ö‡¶°‡¶ø‡¶ì ‡¶™‡ßç‡¶∞‡¶∏‡ßá‡¶∏‡¶ø‡¶Ç
    remove_background_music(audio_file, filtered_audio, audio_temp_folder)
    
    # AI ‡¶≠‡¶Ø‡¶º‡ßá‡¶∏ ‡¶ú‡ßá‡¶®‡¶æ‡¶∞‡ßá‡¶ü ‡¶ï‡¶∞‡¶æ (‡¶Ø‡¶¶‡¶ø use_ai_voice=True ‡¶π‡¶Ø‡¶º)
    final_audio = filtered_audio
    transcript = ""
    
    if use_ai_voice:
        print("üéôÔ∏è Transcribing audio for AI voice generation...")
        transcript = transcribe_audio(filtered_audio)
        
        if transcript:
            # AI ‡¶≠‡¶Ø‡¶º‡ßá‡¶∏ ‡¶ú‡ßá‡¶®‡¶æ‡¶∞‡ßá‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®
            ai_voice_file = transcribe_and_generate_ai_voice(transcript, audio_name, audio_temp_folder)
            
            if ai_voice_file and os.path.exists(ai_voice_file):
                print(f"‚úÖ Using AI voice: {ai_voice_file}")
                final_audio = ai_voice_file
                
                # AI ‡¶≠‡¶Ø‡¶º‡ßá‡¶∏‡ßá‡¶∞ ‡¶Ö‡¶°‡¶ø‡¶ì ‡¶°‡¶ø‡¶â‡¶∞‡ßá‡¶∂‡¶® ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶®
                try:
                    ai_voice_duration = float(
                        subprocess.check_output(
                            f'ffprobe -i "{ai_voice_file}" -show_entries format=duration -v quiet -of csv="p=0"',
                            shell=True
                        ).decode().strip()
                    )
                    print(f"‚úÖ AI Voice Duration: {ai_voice_duration:.2f} seconds")
                except Exception as e:
                    print(f"‚ö†Ô∏è Could not check AI voice duration: {e}")
    
    # ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶æ
    create_video(STOCK_VIDEO, final_audio, output_video, is_short=is_short, use_karaoke=True, 
                temp_folder=audio_temp_folder, use_ai_voice=use_ai_voice, use_face_footage=use_face_footage)

    # Clear the specific audio and temp folder after processing
    clear_audio_and_temp_folders(audio_file, TEMP_FOLDER)
  
def get_audio_from_old_audio():
    """old_audio ‡¶´‡ßã‡¶≤‡ßç‡¶°‡¶æ‡¶∞ ‡¶•‡ßá‡¶ï‡ßá mp3, wav, ‡¶¨‡¶æ m4a ‡¶´‡¶æ‡¶á‡¶≤ ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßá ‡¶è‡¶¨‡¶Ç ‡¶∏‡ßá‡¶®‡¶ø‡¶ü‡¶æ‡¶á‡¶ú ‡¶ï‡¶∞‡ßá"""
    if not os.path.isdir(OLD_AUDIO_FOLDER):
        return []
        
    # ‡¶∏‡¶¨ ‡¶Ö‡¶°‡¶ø‡¶ì ‡¶´‡¶æ‡¶á‡¶≤ ‡¶∏‡¶Ç‡¶ó‡ßç‡¶∞‡¶π ‡¶ï‡¶∞‡ßÅ‡¶®
    audio_files = glob(os.path.join(OLD_AUDIO_FOLDER, "*.mp3")) + \
                 glob(os.path.join(OLD_AUDIO_FOLDER, "*.wav")) + \
                 glob(os.path.join(OLD_AUDIO_FOLDER, "*.m4a"))
                 
    sanitized_files = []
    
    # ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶´‡¶æ‡¶á‡¶≤‡ßá‡¶∞ ‡¶®‡¶æ‡¶Æ ‡¶∏‡ßá‡¶®‡¶ø‡¶ü‡¶æ‡¶á‡¶ú ‡¶ï‡¶∞‡ßÅ‡¶®
    for file_path in audio_files:
        file_dir = os.path.dirname(file_path)
        file_name = os.path.basename(file_path)
        
        # ‡¶´‡¶æ‡¶á‡¶≤ ‡¶®‡¶æ‡¶Æ ‡¶∏‡ßá‡¶®‡¶ø‡¶ü‡¶æ‡¶á‡¶ú ‡¶ï‡¶∞‡ßÅ‡¶®
        sanitized_name, original_name = sanitize_filename(file_name)
        sanitized_path = os.path.join(file_dir, sanitized_name)
        
        # ‡¶Ø‡¶¶‡¶ø ‡¶´‡¶æ‡¶á‡¶≤‡¶®‡¶æ‡¶Æ ‡¶™‡¶∞‡¶ø‡¶¨‡¶∞‡ßç‡¶§‡¶® ‡¶π‡¶Ø‡¶º‡ßá ‡¶•‡¶æ‡¶ï‡ßá, ‡¶§‡¶æ‡¶π‡¶≤‡ßá ‡¶∞‡¶ø‡¶®‡ßá‡¶Æ ‡¶ï‡¶∞‡ßÅ‡¶®
        if sanitized_name != file_name:
            try:
                # ‡¶´‡¶æ‡¶á‡¶≤ ‡¶∞‡¶ø‡¶®‡ßá‡¶Æ ‡¶ï‡¶∞‡ßÅ‡¶®
                os.rename(file_path, sanitized_path)
                print(f"‚úÖ Renamed: {file_name} -> {sanitized_name}")
                
                # ‡¶Æ‡ßç‡¶Ø‡¶æ‡¶™‡¶ø‡¶Ç ‡¶∏‡¶Ç‡¶∞‡¶ï‡ßç‡¶∑‡¶£ ‡¶ï‡¶∞‡ßÅ‡¶®
                map_filename(file_path, sanitized_path)
                sanitized_files.append(sanitized_path)
            except Exception as e:
                print(f"‚ùå Error renaming file {file_name}: {e}")
                sanitized_files.append(file_path)  # ‡¶Ö‡¶∞‡¶ø‡¶ú‡¶ø‡¶®‡¶æ‡¶≤ ‡¶´‡¶æ‡¶á‡¶≤ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®
        else:
            # ‡¶´‡¶æ‡¶á‡¶≤‡¶®‡¶æ‡¶Æ ‡¶™‡¶∞‡¶ø‡¶¨‡¶∞‡ßç‡¶§‡¶® ‡¶®‡¶æ ‡¶π‡¶≤‡ßá‡¶ì ‡¶Æ‡ßç‡¶Ø‡¶æ‡¶™‡¶ø‡¶Ç ‡¶∞‡¶æ‡¶ñ‡ßÅ‡¶®
            map_filename(file_path, file_path)
            sanitized_files.append(file_path)
                
    return sanitized_files

def batch_process():
    """Process batch of normal and shorts videos one by one with support for AI voice and face footage."""
    clear_temp_folder()
    old_audio_files = get_audio_from_old_audio()  # old_audio ‡¶´‡ßã‡¶≤‡ßç‡¶°‡¶æ‡¶∞ ‡¶•‡ßá‡¶ï‡ßá ‡¶´‡¶æ‡¶á‡¶≤‡¶ó‡ßÅ‡¶≤‡ßã ‡¶®‡¶ø‡¶Ø‡¶º‡ßá ‡¶Ü‡¶∏‡ßÅ‡¶®

    # URL ‡¶≤‡¶ø‡¶∏‡ßç‡¶ü ‡¶´‡¶æ‡¶á‡¶≤ ‡¶¨‡ßã‡¶ù‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶®
    has_ai_voice_shorts = os.path.isfile(YOUTUBE_AI_VOICE_SHORTS_URL_FILE) and os.path.getsize(YOUTUBE_AI_VOICE_SHORTS_URL_FILE) > 0
    has_ai_voice_long = os.path.isfile(YOUTUBE_AI_VOICE_LONG_VIDEO_URL_FILE) and os.path.getsize(YOUTUBE_AI_VOICE_LONG_VIDEO_URL_FILE) > 0
    has_regular_shorts = os.path.isfile(YOUTUBE_SHORTS_URL_FILE) and os.path.getsize(YOUTUBE_SHORTS_URL_FILE) > 0
    has_regular_videos = os.path.isfile(YOUTUBE_URL_FILE) and os.path.getsize(YOUTUBE_URL_FILE) > 0
    
    # ‡¶´‡ßá‡¶∏ ‡¶´‡ßÅ‡¶ü‡ßá‡¶ú URL ‡¶´‡¶æ‡¶á‡¶≤ ‡¶ö‡ßá‡¶ï
    has_face_shorts = os.path.isfile(YOUTUBE_SHORTS_WITH_FACE_URL_FILE) and os.path.getsize(YOUTUBE_SHORTS_WITH_FACE_URL_FILE) > 0
    has_face_long = os.path.isfile(YOUTUBE_LONG_WITH_FACE_URL_FILE) and os.path.getsize(YOUTUBE_LONG_WITH_FACE_URL_FILE) > 0
    has_face_ai_shorts = os.path.isfile(YOUTUBE_SHORTS_WITH_FACE_AI_URL_FILE) and os.path.getsize(YOUTUBE_SHORTS_WITH_FACE_AI_URL_FILE) > 0
    has_face_ai_long = os.path.isfile(YOUTUBE_LONG_WITH_FACE_AI_URL_FILE) and os.path.getsize(YOUTUBE_LONG_WITH_FACE_AI_URL_FILE) > 0

    # ‡¶Ø‡¶¶‡¶ø old_audio ‡¶´‡ßã‡¶≤‡ßç‡¶°‡¶æ‡¶∞‡ßá ‡¶ï‡ßã‡¶®‡ßã ‡¶´‡¶æ‡¶á‡¶≤ ‡¶®‡¶æ ‡¶•‡¶æ‡¶ï‡ßá, ‡¶§‡¶¨‡ßá YouTube ‡¶•‡ßá‡¶ï‡ßá ‡¶Ö‡¶°‡¶ø‡¶ì ‡¶°‡¶æ‡¶â‡¶®‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßÅ‡¶®
    if not old_audio_files:
        # ‡ß¶. ‡¶´‡ßá‡¶∏ ‡¶´‡ßÅ‡¶ü‡ßá‡¶ú ‡¶´‡¶æ‡¶á‡¶≤ ‡¶∏‡¶Ç‡¶ñ‡ßç‡¶Ø‡¶æ ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶®
        face_file_counts = face_handler.check_face_footage_files()
        
        # ‡ßß. ‡¶´‡ßá‡¶∏ ‡¶´‡ßÅ‡¶ü‡ßá‡¶ú ‡¶∏‡¶π ‡¶∂‡¶∞‡ßç‡¶ü‡¶∏ (‡¶∞‡ßá‡¶ó‡ßÅ‡¶≤‡¶æ‡¶∞ ‡¶Ö‡¶°‡¶ø‡¶ì)
        if has_face_shorts:
            print("\nüîπ Processing Face Footage Shorts from YouTube:")
            face_shorts = download_youtube_audio(YOUTUBE_SHORTS_WITH_FACE_URL_FILE)
            for audio_file in face_shorts:
                video_title = os.path.splitext(os.path.basename(audio_file))[0]
                print(f"\nProcessing face footage shorts: {video_title}")
                process_audio_in_parallel(audio_file, is_short=True, use_ai_voice=False, use_face_footage=True)
        
        # ‡ß®. ‡¶´‡ßá‡¶∏ ‡¶´‡ßÅ‡¶ü‡ßá‡¶ú ‡¶∏‡¶π ‡¶≤‡¶Ç ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì (‡¶∞‡ßá‡¶ó‡ßÅ‡¶≤‡¶æ‡¶∞ ‡¶Ö‡¶°‡¶ø‡¶ì)
        if has_face_long:
            print("\nüîπ Processing Face Footage Long Videos from YouTube:")
            face_long = download_youtube_audio(YOUTUBE_LONG_WITH_FACE_URL_FILE)
            for audio_file in face_long:
                video_title = os.path.splitext(os.path.basename(audio_file))[0]
                print(f"\nProcessing face footage long video: {video_title}")
                process_audio_in_parallel(audio_file, is_short=False, use_ai_voice=False, use_face_footage=True)
        
        # ‡ß©. ‡¶´‡ßá‡¶∏ ‡¶´‡ßÅ‡¶ü‡ßá‡¶ú ‡¶∏‡¶π ‡¶∂‡¶∞‡ßç‡¶ü‡¶∏ (AI ‡¶≠‡¶Ø‡¶º‡ßá‡¶∏)
        if has_face_ai_shorts:
            print("\nüîπ Processing Face Footage Shorts with AI Voice from YouTube:")
            face_ai_shorts = download_youtube_audio(YOUTUBE_SHORTS_WITH_FACE_AI_URL_FILE)
            for audio_file in face_ai_shorts:
                video_title = os.path.splitext(os.path.basename(audio_file))[0]
                print(f"\nProcessing face footage shorts with AI voice: {video_title}")
                process_audio_in_parallel(audio_file, is_short=True, use_ai_voice=True, use_face_footage=True)
        
        # ‡ß™. ‡¶´‡ßá‡¶∏ ‡¶´‡ßÅ‡¶ü‡ßá‡¶ú ‡¶∏‡¶π ‡¶≤‡¶Ç ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì (AI ‡¶≠‡¶Ø‡¶º‡ßá‡¶∏)
        if has_face_ai_long:
            print("\nüîπ Processing Face Footage Long Videos with AI Voice from YouTube:")
            face_ai_long = download_youtube_audio(YOUTUBE_LONG_WITH_FACE_AI_URL_FILE)
            for audio_file in face_ai_long:
                video_title = os.path.splitext(os.path.basename(audio_file))[0]
                print(f"\nProcessing face footage long video with AI voice: {video_title}")
                process_audio_in_parallel(audio_file, is_short=False, use_ai_voice=True, use_face_footage=True)
        
        # ‡ß´. AI ‡¶≠‡¶Ø‡¶º‡ßá‡¶∏ ‡¶≤‡¶Ç ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì (‡¶´‡ßá‡¶∏ ‡¶´‡ßÅ‡¶ü‡ßá‡¶ú ‡¶õ‡¶æ‡¶°‡¶º‡¶æ)
        if has_ai_voice_long:
            print("\nüîπ Processing AI Voice Long Videos from YouTube:")
            ai_voice_long_videos = download_youtube_audio(YOUTUBE_AI_VOICE_LONG_VIDEO_URL_FILE)
            for audio_file in ai_voice_long_videos:
                video_title = os.path.splitext(os.path.basename(audio_file))[0]
                print(f"\nProcessing AI voice long video: {video_title}")
                process_audio_in_parallel(audio_file, is_short=False, use_ai_voice=True, use_face_footage=False)
        
        # ‡ß¨. AI ‡¶≠‡¶Ø‡¶º‡ßá‡¶∏ ‡¶∂‡¶∞‡ßç‡¶ü‡¶∏ ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì (‡¶´‡ßá‡¶∏ ‡¶´‡ßÅ‡¶ü‡ßá‡¶ú ‡¶õ‡¶æ‡¶°‡¶º‡¶æ)
        if has_ai_voice_shorts:
            print("\nüîπ Processing AI Voice Shorts from YouTube:")
            ai_voice_shorts = download_youtube_audio(YOUTUBE_AI_VOICE_SHORTS_URL_FILE)
            for audio_file in ai_voice_shorts:
                video_title = os.path.splitext(os.path.basename(audio_file))[0]
                print(f"\nProcessing AI voice shorts: {video_title}")
                process_audio_in_parallel(audio_file, is_short=True, use_ai_voice=True, use_face_footage=False)
        
        # ‡ß≠. ‡¶∞‡ßá‡¶ó‡ßÅ‡¶≤‡¶æ‡¶∞ ‡¶≤‡¶Ç ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì (‡¶´‡ßá‡¶∏ ‡¶´‡ßÅ‡¶ü‡ßá‡¶ú ‡¶õ‡¶æ‡¶°‡¶º‡¶æ)
        if has_regular_videos:
            print("\nüîπ Processing Regular Videos from YouTube:")
            normal_audio_files = download_youtube_audio(YOUTUBE_URL_FILE)
            for audio_file in normal_audio_files:
                video_title = os.path.splitext(os.path.basename(audio_file))[0]
                print(f"\nProcessing regular video: {video_title}")
                process_audio_in_parallel(audio_file, is_short=False, use_ai_voice=False, use_face_footage=False)
        
        # ‡ßÆ. ‡¶∞‡ßá‡¶ó‡ßÅ‡¶≤‡¶æ‡¶∞ ‡¶∂‡¶∞‡ßç‡¶ü‡¶∏ ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì (‡¶´‡ßá‡¶∏ ‡¶´‡ßÅ‡¶ü‡ßá‡¶ú ‡¶õ‡¶æ‡¶°‡¶º‡¶æ)
        if has_regular_shorts:
            print("\nüîπ Processing Regular Shorts from YouTube:")
            shorts_audio_files = download_youtube_audio(YOUTUBE_SHORTS_URL_FILE)
            for audio_file in shorts_audio_files:
                video_title = os.path.splitext(os.path.basename(audio_file))[0]
                print(f"\nProcessing regular shorts: {video_title}")
                process_audio_in_parallel(audio_file, is_short=True, use_ai_voice=False, use_face_footage=False)
    else:
        # ‡¶Ø‡¶¶‡¶ø old_audio ‡¶´‡ßã‡¶≤‡ßç‡¶°‡¶æ‡¶∞‡ßá ‡¶´‡¶æ‡¶á‡¶≤ ‡¶•‡¶æ‡¶ï‡ßá, ‡¶§‡¶¨‡ßá ‡¶∏‡ßá‡¶ó‡ßÅ‡¶≤‡¶ø ‡¶™‡ßç‡¶∞‡¶∏‡ßá‡¶∏ ‡¶ï‡¶∞‡ßÅ‡¶® (‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶Ü‡¶Æ‡¶∞‡¶æ AI ‡¶≠‡¶Ø‡¶º‡ßá‡¶∏ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶õ‡¶ø ‡¶®‡¶æ)
        normal_audio_files = old_audio_files
        for audio_file in normal_audio_files:
            video_title = os.path.splitext(os.path.basename(audio_file))[0]
            print(f"\nProcessing from old_audio: {video_title}")
            process_audio_in_parallel(audio_file, is_short=False, use_ai_voice=False, use_face_footage=False)
        
    print("\nüéâ All videos are successfully created!")

if __name__ == "__main__":
    print("‚è≥ Loading Whisper model...")
    
    # ‡¶°‡¶ø‡¶≠‡¶æ‡¶á‡¶∏ ‡¶ö‡ßá‡¶ï‡¶ø‡¶Ç ‡¶è‡¶¨‡¶Ç ‡¶Æ‡¶°‡ßá‡¶≤‡¶ï‡ßá ‡¶°‡¶ø‡¶≠‡¶æ‡¶á‡¶∏‡ßá ‡¶™‡¶æ‡¶†‡¶æ‡¶®‡ßã
    if torch.cuda.is_available():
        device = torch.device("cuda")
    else:
        device = torch.device("cpu")
    
    # Whisper ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡¶æ
    model = whisper.load_model("small")
    
    # ‡¶Æ‡¶°‡ßá‡¶≤‡¶ï‡ßá GPU ‡¶¨‡¶æ CPU ‡¶§‡ßá ‡¶™‡¶æ‡¶†‡¶æ‡¶®‡ßã
    model.to(device)

    print("‚úÖ Whisper model loaded successfully!")
    batch_process()