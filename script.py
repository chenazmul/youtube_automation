import os
import shutil
import subprocess
import yt_dlp
import whisper
from glob import glob
import random
import string
import pysubs2
import torch
import requests
import json
import re
from concurrent.futures import as_completed
from openai import AzureOpenAI
from azure.identity import DefaultAzureCredential, get_bearer_token_provider 
from dotenv import load_dotenv
from subtitle_design import apply_design  # `subtitle_design.py` ржерзЗржХрзЗ ржбрж┐ржЬрж╛ржЗржи ржлрж╛ржВрж╢ржи ржЗржоржкрзЛрж░рзНржЯ ржХрж░рж╛ рж╣ржЪрзНржЫрзЗ
from azure_prompt import generate_output_from_azure  # Azure AI ржПрж░ ржлрж╛ржВрж╢ржиржЯрж┐ ржЗржоржкрзЛрж░рзНржЯ ржХрж░рж╛ рж╣ржЪрзНржЫрзЗ
from metadata_updater import set_file_properties
from metadata_updater import process_video_metadata
from ai_voice_generator import transcribe_and_generate_ai_voice  # AI ржнржпрж╝рзЗрж╕ ржлрж╛ржВрж╢ржи ржЗржоржкрзЛрж░рзНржЯ ржХрж░рж╛ рж╣ржЪрзНржЫрзЗ
import time
from face_footage_handler import FaceFootageHandler

load_dotenv()  # ржПржЯрж┐ ржЖржкржирж╛рж░ .env ржлрж╛ржЗрж▓ ржерзЗржХрзЗ ржкрж░рж┐ржмрзЗрж╢ ржнрзЗрж░рж┐ржпрж╝рзЗржмрж▓ржЧрзБрж▓рзЛ рж▓рзЛржб ржХрж░ржмрзЗ


# Azure OpenAI API ржХржиржлрж┐ржЧрж╛рж░рзЗрж╢ржи
endpoint = os.getenv("ENDPOINT_URL", "https://et1.openai.azure.com/")  
deployment = os.getenv("DEPLOYMENT_NAME", "gpt-4o")  

# Initialize Azure OpenAI Service client with Entra ID authentication
token_provider = get_bearer_token_provider(  
    DefaultAzureCredential(),  
    "https://cognitiveservices.azure.com/.default"  
)  

client = AzureOpenAI(  
    azure_endpoint=endpoint,  
    azure_ad_token_provider=token_provider,  
    api_version="2024-05-01-preview",  
)


# ржлрж╛ржЗрж▓ ржирж╛ржо рж╕рзЗржирж┐ржЯрж╛ржЗржЬ ржХрж░рж╛рж░ ржлрж╛ржВрж╢ржи
def sanitize_filename(filename):
    """
    ржлрж╛ржЗрж▓ ржирж╛ржо ржерзЗржХрзЗ ржмрж┐рж╢рзЗрж╖ ржЕржХрзНрж╖рж░ржЧрзБрж▓рзЛ рж░рж┐ржорзБржн ржХрж░рзЗ рж╢рзБржзрзБржорж╛рждрзНрж░ рж╕рзЗржл ржХрзНржпрж╛рж░рзЗржХрзНржЯрж╛рж░ рж░рж╛ржЦрзЗред
    
    Args:
        filename (str): ржЕрж░рж┐ржЬрж┐ржирж╛рж▓ ржлрж╛ржЗрж▓ржирж╛ржо
        
    Returns:
        tuple: (sanitized_name, original_name) - рж╕рзЗржирж┐ржЯрж╛ржЗржЬ ржХрж░рж╛ ржирж╛ржо ржПржмржВ ржЕрж░рж┐ржЬрж┐ржирж╛рж▓ ржирж╛ржо
    """
    # ржЕрж░рж┐ржЬрж┐ржирж╛рж▓ ржирж╛ржо рж╕ржВрж░ржХрзНрж╖ржг ржХрж░рзБржи
    original_name = filename
    
    # ржПржХрзНрж╕ржЯрзЗржирж╢ржи ржЖрж▓рж╛ржжрж╛ ржХрж░рзБржи
    base_name, extension = os.path.splitext(filename)
    
    # ржмрж┐рж╢рзЗрж╖ ржХрзНржпрж╛рж░рзЗржХрзНржЯрж╛рж░ рж░рж┐ржорзБржн ржХрж░рзБржи ржПржмржВ рж╕рзНржкрзЗрж╕ ржЖржирзНржбрж╛рж░рж╕рзНржХрзЛрж░ ржжрж┐ржпрж╝рзЗ ржкрзНрж░рждрж┐рж╕рзНржерж╛ржкржи ржХрж░рзБржи
    sanitized_base = re.sub(r'[^\w\s-]', '', base_name)
    sanitized_base = re.sub(r'[\s]+', '_', sanitized_base)
    
    # ржЦрзБржм рж▓ржорзНржмрж╛ ржирж╛ржо рж╣рж▓рзЗ рж╕рзЗржЯрж┐ рж╢рж░рзНржЯ ржХрж░рзБржи
    if len(sanitized_base) > 50:
        sanitized_base = sanitized_base[:50]
    
    # рж╕рзЗржирж┐ржЯрж╛ржЗржЬ ржХрж░рж╛ ржирж╛ржо ржлрж┐рж░рж┐ржпрж╝рзЗ ржжрж┐ржи
    sanitized_name = sanitized_base + extension
    
    return sanitized_name, original_name


# ржлрж╛ржЗрж▓ ржирж╛ржо ржорзНржпрж╛ржкрж┐ржВ ржПрж░ ржЬржирзНржп ржбрж┐ржХрж╢ржирж╛рж░рж┐
filename_mapping = {}

def map_filename(original_path, sanitized_path):
    """
    ржЕрж░рж┐ржЬрж┐ржирж╛рж▓ ржлрж╛ржЗрж▓ ржкрж╛рже ржПржмржВ рж╕рзЗржирж┐ржЯрж╛ржЗржЬ ржХрж░рж╛ ржлрж╛ржЗрж▓ ржкрж╛ржерзЗрж░ ржорзНржпрж╛ржкрж┐ржВ рж░рж╛ржЦрзЗред
    
    Args:
        original_path (str): ржЕрж░рж┐ржЬрж┐ржирж╛рж▓ ржлрж╛ржЗрж▓ ржкрж╛рже
        sanitized_path (str): рж╕рзЗржирж┐ржЯрж╛ржЗржЬ ржХрж░рж╛ ржлрж╛ржЗрж▓ ржкрж╛рже
    """
    filename_mapping[sanitized_path] = original_path
    
def get_original_filename(sanitized_path):
    """
    рж╕рзЗржирж┐ржЯрж╛ржЗржЬ ржХрж░рж╛ ржлрж╛ржЗрж▓ ржкрж╛рже ржерзЗржХрзЗ ржЕрж░рж┐ржЬрж┐ржирж╛рж▓ ржлрж╛ржЗрж▓ ржкрж╛рже ржкрж╛ржпрж╝ред
    
    Args:
        sanitized_path (str): рж╕рзЗржирж┐ржЯрж╛ржЗржЬ ржХрж░рж╛ ржлрж╛ржЗрж▓ ржкрж╛рже
        
    Returns:
        str: ржЕрж░рж┐ржЬрж┐ржирж╛рж▓ ржлрж╛ржЗрж▓ ржкрж╛рже, ржпржжрж┐ ржкрж╛ржУржпрж╝рж╛ ржпрж╛ржпрж╝; ржЕржирзНржпржерж╛ржпрж╝ рж╕рзЗржирж┐ржЯрж╛ржЗржЬ ржХрж░рж╛ ржкрж╛рже
    """
    return filename_mapping.get(sanitized_path, sanitized_path)

def get_original_basename(sanitized_path):
    """
    рж╕рзЗржирж┐ржЯрж╛ржЗржЬ ржХрж░рж╛ ржлрж╛ржЗрж▓ ржкрж╛рже ржерзЗржХрзЗ ржЕрж░рж┐ржЬрж┐ржирж╛рж▓ ржлрж╛ржЗрж▓ ржирж╛ржо (ржмрзЗрж╕ржирж╛ржо) ржкрж╛ржпрж╝ред
    
    Args:
        sanitized_path (str): рж╕рзЗржирж┐ржЯрж╛ржЗржЬ ржХрж░рж╛ ржлрж╛ржЗрж▓ ржкрж╛рже
        
    Returns:
        str: ржЕрж░рж┐ржЬрж┐ржирж╛рж▓ ржлрж╛ржЗрж▓рзЗрж░ ржмрзЗрж╕ржирж╛ржо, ржпржжрж┐ ржкрж╛ржУржпрж╝рж╛ ржпрж╛ржпрж╝; ржЕржирзНржпржерж╛ржпрж╝ рж╕рзЗржирж┐ржЯрж╛ржЗржЬ ржХрж░рж╛ ржмрзЗрж╕ржирж╛ржо
    """
    original_path = get_original_filename(sanitized_path)
    return os.path.splitext(os.path.basename(original_path))[0]


# ЁЯФ╣ ржХржиржлрж┐ржЧрж╛рж░рзЗрж╢ржи
BASE_PATH = "D:/video_project/"
OLD_AUDIO_FOLDER = "D:/video_project/old_audio"
YOUTUBE_URL_FILE = os.path.join(BASE_PATH, "youtube_urls.txt")
YOUTUBE_SHORTS_URL_FILE = os.path.join(BASE_PATH, "youtube_shorts_urls.txt")
# AI ржнржпрж╝рзЗрж╕ ржнрж┐ржбрж┐ржУ URL ржлрж╛ржЗрж▓
YOUTUBE_AI_VOICE_SHORTS_URL_FILE = os.path.join(BASE_PATH, "youtube_ai_voice_shorts_urls.txt")
YOUTUBE_AI_VOICE_LONG_VIDEO_URL_FILE = os.path.join(BASE_PATH, "youtube_ai_voice_long_video_urls.txt")

AUDIO_FOLDER = os.path.join(BASE_PATH, "audio_files")
STOCK_VIDEO = os.path.join(BASE_PATH, "stock_video.mp4")  # ржлрж▓ржмрзНржпрж╛ржХ рж╣рж┐рж╕рзЗржмрзЗ
OUTPUT_FOLDER = os.path.join(BASE_PATH, "output_videos")
SHORTS_FOLDER = os.path.join(OUTPUT_FOLDER, "shorts")
TEMP_FOLDER = os.path.join(BASE_PATH, "temp_output")
SHORTS_STOCK_VIDEOS_FOLDER = os.path.join(BASE_PATH, "shorts_stock_videos")
STOCK_VIDEOS_FOLDER = os.path.join(BASE_PATH, "stock_videos")
BACKGROUND_MUSIC_FOLDER = os.path.join(BASE_PATH, "background_music")
# ЁЯФ╣ ржлрзЗрж╕ ржлрзБржЯрзЗржЬ ржлрзЛрж▓рзНржбрж╛рж░ ржХржиржлрж┐ржЧрж╛рж░рзЗрж╢ржи
REAL_FOOTAGE_SHORTS_FOLDER = os.path.join(BASE_PATH, "real_footage_shorts")
REAL_FOOTAGE_LONG_FOLDER = os.path.join(BASE_PATH, "real_footage_long")
YOUTUBE_SHORTS_WITH_FACE_URL_FILE = os.path.join(BASE_PATH, "youtube_shorts_with_5_sec_with_face.txt")
YOUTUBE_LONG_WITH_FACE_URL_FILE = os.path.join(BASE_PATH, "youtube_long_with_5_sec_with_face.txt")
YOUTUBE_SHORTS_WITH_FACE_AI_URL_FILE = os.path.join(BASE_PATH, "youtube_shorts_with_5_sec_with_face_ai.txt")
YOUTUBE_LONG_WITH_FACE_AI_URL_FILE = os.path.join(BASE_PATH, "youtube_long_with_5_sec_with_face_ai.txt")

# ЁЯФ╣ Ensure output directories exist
os.makedirs(AUDIO_FOLDER, exist_ok=True)
os.makedirs(OUTPUT_FOLDER, exist_ok=True)
os.makedirs(SHORTS_FOLDER, exist_ok=True)
os.makedirs(TEMP_FOLDER, exist_ok=True)
os.makedirs(SHORTS_STOCK_VIDEOS_FOLDER, exist_ok=True)
# ржлрзЛрж▓рзНржбрж╛рж░ ржЧрзБрж▓рж┐ ржирж┐рж╢рзНржЪрж┐ржд ржХрж░рзБржи
os.makedirs(REAL_FOOTAGE_SHORTS_FOLDER, exist_ok=True)
os.makedirs(REAL_FOOTAGE_LONG_FOLDER, exist_ok=True)

# FaceFootageHandler ржЗржирж┐рж╢рж┐ржпрж╝рж╛рж▓рж╛ржЗржЬ ржХрж░рзБржи
face_handler = FaceFootageHandler(BASE_PATH)

def transcribe_audio(audio_file):
    """рж╕рзНржкрж┐ржЪ ржЯрзБ ржЯрзЗржХрзНрж╕ржЯ ржкрзНрж░рж╕рзЗрж╕ ржХрж░рж╛ Whisper ржжрж┐ржпрж╝рзЗ"""
    result = model.transcribe(audio_file, task='transcribe')
    if result and 'text' in result:
        return result['text']
    else:
        print(f"тЭМ Transcription failed for {audio_file}")
        return None


# Azure OpenAI API ржХрж▓
def generate_output_from_azure(transcribe, video_title, output_file_path):
    """Azure OpenAI API ржжрж┐ржпрж╝рзЗ рж╕рзНржкрж┐ржЪ ржЯрзЗржХрзНрж╕ржЯ ржкрзНрж░рж╕рзЗрж╕ ржХрж░рж╛ ржПржмржВ ржЖржЙржЯржкрзБржЯ рж╕рзЗржн ржХрж░рж╛"""
    
    # ржкрзНрж░ржорзНржкржЯ рждрзИрж░рж┐
    prompt = f"""
    Here is my transcribe: {transcribe}
    Topic: "{video_title}"
    
    Write 1 Youtube relevent Video Title, Must engaging. 
    Write 2 paragraphs based on transcribe and title.
    Write 10 hashtags.
    Write 10 normal tags with comma separation.

    And After this, write this also:

    ЁЯОд Speakers in this video: 
    Tony Robbins

    ЁЯФК Our speeches are created by, remixed or licensed to Tony Robbins Motivation.
    For licensing information, message geniusteam01@gmail.com

    ЁЯОе The video footage in this video:
    All video footage used is licensed through either CC-BY, from various stock footage websites, or filmed by us. All Creative Commons footage is listed at the video's end and licensed under CC-BY 3.0. Film and TV shows used in the video are interwoven with the video's narrative, related to the video's topic, and corresponding to FAIR USE.
    """
    
    # API Key ржПржмржВ Endpoint ржерзЗржХрзЗ API URL рж╕рзЗржЯ ржХрж░рзБржи
    api_key = os.getenv("API_KEY")  # ржЖржкржирж╛рж░ Azure OpenAI API Key 
    url = f'{endpoint}/openai/deployments/{deployment}/chat/completions?api-version=2024-02-15-preview'

    headers = {
        'Content-Type': 'application/json',
        'api-key': api_key  # API Key
    }

    payload = {
        "messages": [
            {"role": "system", "content": "You are an AI assistant that helps people find information."},
            {"role": "user", "content": prompt}  # ржПржЦрж╛ржирзЗ prompt ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗржЫрж┐
        ],
        "max_tokens": 1500,
        "temperature": 0.7
    }

    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload))

        if response.status_code == 200:
            data = response.json()
            result = data['choices'][0]['message']['content'].strip()  # рж╕ржарж┐ржХ ржЯрзЗржХрзНрж╕ржЯ ржпрж╛ржЪрж╛ржЗ
            print(f"тЬЕ Response received: {result[:200]}...")  # ржЖржВрж╢рж┐ржХ ржЖржЙржЯржкрзБржЯ
        else:
            print(f"тЭМ API Response Error: {response.status_code}, {response.text}")
            return

        # ржЖржЙржЯржкрзБржЯ ржлрж╛ржЗрж▓ рж╕рзЗржн ржХрж░рзБржи
        with open(output_file_path, "w", encoding="utf-8") as file:
            file.write(result)
            print(f"тЬЕ Output saved to: {output_file_path}")

    except Exception as e:
        print(f"тЭМ Error generating output from Azure OpenAI: {e}")
        print("тЪая╕П Skipping Azure process and continuing with the next steps...")


def process_audio_and_generate_text(audio_file, video_title, is_short=False):
    """рж╕рзНржкрж┐ржЪ ржЯрзБ ржЯрзЗржХрзНрж╕ржЯ ржкрзНрж░рж╕рзЗрж╕ ржПржмржВ Azure OpenAI ржПрж░ ржорж╛ржзрзНржпржорзЗ ржЖржЙржЯржкрзБржЯ рждрзИрж░рж┐ ржХрж░рж╛"""
    
    # Whisper ржПрж░ ржорж╛ржзрзНржпржорзЗ ржЕржбрж┐ржУ ржерзЗржХрзЗ ржЯрзНрж░рж╛ржирзНрж╕ржХрзНрж░рж┐ржкрзНржЯ ржХрж░рж╛
    transcribe = transcribe_audio(audio_file)

    if not transcribe:
        return
    
    # рж╕рзЗржирж┐ржЯрж╛ржЗржЬ ржХрж░рж╛ ржлрж╛ржЗрж▓ ржирж╛ржо ржерзЗржХрзЗ ржЕрж░рж┐ржЬрж┐ржирж╛рж▓ ржлрж╛ржЗрж▓ ржирж╛ржо ржЦрзБржБржЬрзБржи
    original_folder_name = get_original_basename(audio_file)
    sanitized_folder_name = os.path.splitext(os.path.basename(audio_file))[0]
    
    # ржпржжрж┐ ржЕрж░рж┐ржЬрж┐ржирж╛рж▓ ржлрзЛрж▓рзНржбрж╛рж░ ржирж╛ржо ржирж╛ ржкрж╛ржУржпрж╝рж╛ ржпрж╛ржпрж╝, рждрж╛рж╣рж▓рзЗ рж╕рзЗржирж┐ржЯрж╛ржЗржЬ ржХрж░рж╛ ржирж╛ржо ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи
    if not original_folder_name:
        original_folder_name = sanitized_folder_name
    
    # ржЕрж░рж┐ржЬрж┐ржирж╛рж▓ ржлрж╛ржЗрж▓ ржирж╛ржо ржЕржирзБржпрж╛ржпрж╝рзА ржлрзЛрж▓рзНржбрж╛рж░ рждрзИрж░рж┐ ржХрж░рзБржи
    if is_short:
        video_folder = os.path.join(OUTPUT_FOLDER, "shorts", original_folder_name)  # Shorts folder
    else:
        video_folder = os.path.join(OUTPUT_FOLDER, original_folder_name)  # Regular video folder

    os.makedirs(video_folder, exist_ok=True)

    # ржнрж┐ржбрж┐ржУ ржЯрж╛ржЗржЯрзЗрж▓ ржЕржирзБржпрж╛ржпрж╝рзА ржЖржЙржЯржкрзБржЯ ржлрж╛ржЗрж▓ ржирж╛ржо рждрзИрж░рж┐ ржХрж░рж╛ (рж╕рзЗржирж┐ржЯрж╛ржЗржЬ ржХрж░рж╛ ржирж╛ржо ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ)
    output_file_path = os.path.join(video_folder, f"{sanitized_folder_name}_output.txt")

    # Azure OpenAI API ржжрж┐ржпрж╝рзЗ ржЖржЙржЯржкрзБржЯ рждрзИрж░рж┐ ржХрж░рж╛
    generate_output_from_azure(transcribe, video_title, output_file_path)
    
    # Save video to the same folder (ржПржЯрж┐ create_video ржлрж╛ржВрж╢ржирзЗржЗ ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗ)
    print(f"тЬЕ Video and text saved to: {video_folder}")


def get_random_file(folder_path, extensions=(".mp4", ".mov", ".mp3", ".wav")):
    """ржлрзЛрж▓рзНржбрж╛рж░ ржерзЗржХрзЗ ржирж┐рж░рзНржжрж┐рж╖рзНржЯ ржПржХрзНрж╕ржЯрзЗржирж╢ржирзЗрж░ рж░рзНржпрж╛ржирзНржбржо ржлрж╛ржЗрж▓ ржкрзЗрждрзЗ рж╕рж╛рж╣рж╛ржпрзНржп ржХрж░рзЗред"""
    if not os.path.isdir(folder_path):
        return None
    file_list = [f for f in glob(os.path.join(folder_path, "*")) if f.lower().endswith(extensions)]
    if file_list:
        return random.choice(file_list)
    return None


# ржЖржЙржЯржкрзБржЯ ржнрж┐ржбрж┐ржУ ржлрж╛ржЗрж▓рзЗрж░ ржирж╛ржо рждрзИрж░рж┐ ржХрж░рждрзЗ ржлрж╛ржЗрж▓рзЗрж░ ржирж╛ржоржХрзЗ ржЕржбрж┐ржУ ржлрж╛ржЗрж▓рзЗрж░ ржирж╛ржо ржЕржирзБржпрж╛ржпрж╝рзА рж╕рзЗржЯ ржХрж░рзБржи
def get_output_filename(audio_file, is_short=False, prefix='', suffix=''):
    """
    ржЕржбрж┐ржУ ржлрж╛ржЗрж▓рзЗрж░ ржирж╛ржо ржЕржирзБржпрж╛ржпрж╝рзА ржЖржЙржЯржкрзБржЯ ржнрж┐ржбрж┐ржУ ржирж╛ржо рждрзИрж░рж┐ ржХрж░рзБржи, ржкрзНрж░рж┐ржлрж┐ржХрзНрж╕ ржУ рж╕рж╛ржлрж┐ржХрзНрж╕ рж╕рж╣ред
    ржПржЦржи ржПржЯрж┐ ржЕрж░рж┐ржЬрж┐ржирж╛рж▓ ржлрж╛ржЗрж▓ржирж╛ржо ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ ржлрзЛрж▓рзНржбрж╛рж░ рждрзИрж░рж┐ ржХрж░рзЗред
    """
    # рж╕рзЗржирж┐ржЯрж╛ржЗржЬ ржХрж░рж╛ ржлрж╛ржЗрж▓ ржкрж╛рже ржерзЗржХрзЗ ржЕрж░рж┐ржЬрж┐ржирж╛рж▓ ржлрж╛ржЗрж▓ржирж╛ржо ржЦрзБржБржЬрзБржи
    original_audio_filename = get_original_basename(audio_file)
    # ржпржжрж┐ ржЕрж░рж┐ржЬрж┐ржирж╛рж▓ ржирж╛ржо ржирж╛ ржкрж╛ржУржпрж╝рж╛ ржпрж╛ржпрж╝, рждрж╛рж╣рж▓рзЗ ржмрж░рзНрждржорж╛ржи ржлрж╛ржЗрж▓рзЗрж░ ржирж╛ржо ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи
    if not original_audio_filename:
        original_audio_filename = os.path.splitext(os.path.basename(audio_file))[0]
    
    sanitized_audio_filename = os.path.splitext(os.path.basename(audio_file))[0]
    
    if prefix:
        sanitized_audio_filename = prefix + sanitized_audio_filename
    if suffix:
        sanitized_audio_filename = sanitized_audio_filename + suffix

    # ржЕрж╕рзНржерж╛ржпрж╝рзА ржлрж╛ржЗрж▓ ржкрж╛рже рж╣рж┐рж╕рж╛ржмрзЗ TEMP_FOLDER ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи
    if is_short:
        output_filename = os.path.join(TEMP_FOLDER, f"{sanitized_audio_filename}_short.mp4")
    else:
        output_filename = os.path.join(TEMP_FOLDER, f"{sanitized_audio_filename}.mp4")
    
    return output_filename


def convert_srt_to_ass(srt_file, ass_file, is_short=False):
    """Convert SRT subtitles to ASS format with premium styling and random color patterns."""
    try:
        # ржлрж╛ржЗрж▓ржирж╛ржо ржПржХрзНрж╕ржЯрзНрж░рж╛ржХрзНржЯ ржХрж░рзБржи
        base_filename = os.path.basename(srt_file)
        
        print(f"\nЁЯОи Creating design for: {base_filename}")
        
        subs = pysubs2.load(srt_file, encoding="utf-8")
        
        # ржбрж┐ржЬрж╛ржЗржи ржЕрзНржпрж╛ржкрзНрж▓рж╛ржЗ ржХрж░рзБржи, ржлрж╛ржЗрж▓ржирж╛ржо ржкрж╛рж╕ ржХрж░рзБржи ржпрж╛рждрзЗ ржПржХржЗ ржлрж╛ржЗрж▓рзЗ рж╕ржмрж╕ржоржпрж╝ ржПржХржЗ ржбрж┐ржЬрж╛ржЗржи рж╣ржпрж╝
        subs = apply_design(subs, is_short, filename=base_filename)
        
        # ASS ржлрж╛ржЗрж▓ рж╣рж┐рж╕рзЗржмрзЗ рж╕ржВрж░ржХрзНрж╖ржг ржХрж░рзБржи
        subs.save(ass_file)
        print(f"тЬЕ Converted SRT to ASS with unique design: {ass_file}")
    except Exception as e:
        print(f"тЭМ Error converting subtitle to ASS: {e}")
        # ржлрж▓ржмрзНржпрж╛ржХ ржбрж┐ржЬрж╛ржЗржи
        try:
            subs = pysubs2.load(srt_file, encoding="utf-8")
            subs.styles["Default"].fontname = "Arial"
            subs.styles["Default"].fontsize = 24 if is_short else 30
            subs.styles["Default"].primarycolor = pysubs2.Color(255, 255, 255, 0)
            subs.styles["Default"].outlinecolor = pysubs2.Color(0, 0, 0, 0)
            subs.styles["Default"].backcolor = pysubs2.Color(0, 0, 0, 128)
            subs.styles["Default"].borderstyle = 3
            subs.styles["Default"].outline = 2
            subs.styles["Default"].shadow = 0
            subs.styles["Default"].alignment = 2
            subs.save(ass_file)
            print(f"тЬЕ Used fallback subtitle design: {ass_file}")
        except Exception as fallback_error:
            print(f"тЭМ Even fallback design failed: {fallback_error}")
            
def clear_temp_folder():
    """Clear temporary folder."""
    if os.path.exists(TEMP_FOLDER):
        shutil.rmtree(TEMP_FOLDER)
    os.makedirs(TEMP_FOLDER, exist_ok=True)

def shorten_filename(filename, length=10):
    """Shorten filenames to avoid issues with long paths."""
    base_name = os.path.splitext(os.path.basename(filename))[0]
    short_name = "_".join(base_name.split()[:length])
    return f"{short_name}_{''.join(random.choices(string.ascii_letters + string.digits, k=5))}"

def download_youtube_audio(url_file):
    """Download YouTube audio as MP3 and sanitize filenames."""
    if not os.path.isfile(url_file):
        return []
    with open(url_file, "r", encoding="utf-8") as file:
        urls = [line.strip() for line in file.readlines() if line.strip()]
    if not urls:
        return []

    ydl_opts = {
        'format': 'bestaudio/best',
        'postprocessors': [{
            'key': 'FFmpegExtractAudio',
            'preferredcodec': 'mp3',
            'preferredquality': '192',
        }],
        'outtmpl': os.path.join(AUDIO_FOLDER, '%(title)s.%(ext)s'),
        'noplaylist': True,
    }
    
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        ydl.download(urls)
    
    # ржбрж╛ржЙржирж▓рзЛржб ржХрж░рж╛ ржлрж╛ржЗрж▓ржЧрзБрж▓рзЛ рж╕ржВржЧрзНрж░рж╣ ржХрж░рзБржи
    downloaded_files = glob(os.path.join(AUDIO_FOLDER, "*.mp3"))
    sanitized_files = []
    
    # ржкрзНрж░рждрж┐ржЯрж┐ ржлрж╛ржЗрж▓рзЗрж░ ржирж╛ржо рж╕рзЗржирж┐ржЯрж╛ржЗржЬ ржХрж░рзБржи
    for file_path in downloaded_files:
        file_dir = os.path.dirname(file_path)
        file_name = os.path.basename(file_path)
        
        # ржлрж╛ржЗрж▓ ржирж╛ржо рж╕рзЗржирж┐ржЯрж╛ржЗржЬ ржХрж░рзБржи
        sanitized_name, original_name = sanitize_filename(file_name)
        sanitized_path = os.path.join(file_dir, sanitized_name)
        
        # ржпржжрж┐ ржлрж╛ржЗрж▓ржирж╛ржо ржкрж░рж┐ржмрж░рзНрждржи рж╣ржпрж╝рзЗ ржерж╛ржХрзЗ, рждрж╛рж╣рж▓рзЗ рж░рж┐ржирзЗржо ржХрж░рзБржи
        if sanitized_name != file_name:
            try:
                # ржлрж╛ржЗрж▓ рж░рж┐ржирзЗржо ржХрж░рзБржи
                os.rename(file_path, sanitized_path)
                print(f"тЬЕ Renamed: {file_name} -> {sanitized_name}")
                
                # ржорзНржпрж╛ржкрж┐ржВ рж╕ржВрж░ржХрзНрж╖ржг ржХрж░рзБржи
                map_filename(file_path, sanitized_path)
                sanitized_files.append(sanitized_path)
            except Exception as e:
                print(f"тЭМ Error renaming file {file_name}: {e}")
                sanitized_files.append(file_path)  # ржЕрж░рж┐ржЬрж┐ржирж╛рж▓ ржлрж╛ржЗрж▓ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи
        else:
            # ржлрж╛ржЗрж▓ржирж╛ржо ржкрж░рж┐ржмрж░рзНрждржи ржирж╛ рж╣рж▓рзЗржУ ржорзНржпрж╛ржкрж┐ржВ рж░рж╛ржЦрзБржи
            map_filename(file_path, file_path)
            sanitized_files.append(file_path)
    
    print(f"тЬЕ YouTube MP3 Download Complete from {url_file}!")
    return sanitized_files

# remove_background_music ржлрж╛ржВрж╢ржиржЯрж┐ ржкрж░рж┐ржмрж░рзНрждржи ржХрж░рзБржи
def remove_background_music(input_audio, output_audio, temp_folder):
    """
    Spleeter ржжрж┐ржпрж╝рзЗ ржмрзНржпрж╛ржХржЧрзНрж░рж╛ржЙржирзНржб ржорж┐ржЙржЬрж┐ржХ ржерзЗржХрзЗ ржнржпрж╝рзЗрж╕ ржЖрж▓рж╛ржжрж╛ ржХрж░рзЗред 
    ржпржжрж┐ Spleeter ржЗржирж╕рзНржЯрж▓ ржирж╛ ржерж╛ржХрзЗ ржмрж╛ ржмрзНржпрж░рзНрже рж╣ржпрж╝, рждрж╛рж╣рж▓рзЗ FFmpeg ржлрж┐рж▓рзНржЯрж╛рж░ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗред
    """
    try:
        print(f"ЁЯФК Processing audio file to separate voice from background: {input_audio}")
        
        # ржЕржбрж┐ржУрж░ ржжрзИрж░рзНржШрзНржп ржЪрзЗржХ ржХрж░рзБржи
        duration_cmd = f'ffprobe -i "{input_audio}" -show_entries format=duration -v quiet -of csv="p=0"'
        try:
            duration = float(subprocess.check_output(duration_cmd, shell=True).decode().strip())
            print(f"Audio duration: {duration} seconds ({duration/60:.2f} minutes)")
        except:
            print("Could not determine audio duration")

        # Spleeter ржЯрзЗржорзНржк ржбрж┐рж░рзЗржХрзНржЯрж░рж┐
        spleeter_output = os.path.join(temp_folder, "spleeter_output")
        os.makedirs(spleeter_output, exist_ok=True)
        
        # ржкрзНрж░ржержорзЗ Spleeter ржжрж┐ржпрж╝рзЗ ржЪрзЗрж╖рзНржЯрж╛ ржХрж░рзБржи
        try:
            # Spleeter ржХржорж╛ржирзНржб ржЪрж╛рж▓рж╛ржи
            spleeter_cmd = f'spleeter separate -o "{spleeter_output}" -p spleeter:2stems "{input_audio}"'
            print("Running Spleeter for voice separation...")
            subprocess.run(spleeter_cmd, shell=True, timeout=300)  # 5 ржорж┐ржирж┐ржЯ ржЯрж╛ржЗржоржЖржЙржЯ
            
            # Spleeter ржЖржЙржЯржкрзБржЯ ржкрж╛рже - ржЕржбрж┐ржУ ржирж╛ржо ржЕржирзБржпрж╛ржпрж╝рзА ржлрзЛрж▓рзНржбрж╛рж░ рждрзИрж░рж┐ ржХрж░рзЗ
            audio_name = os.path.splitext(os.path.basename(input_audio))[0]
            vocals_path = os.path.join(spleeter_output, audio_name, "vocals.wav")
            
            if os.path.exists(vocals_path):
                # ржнржпрж╝рзЗрж╕ ржХрзЛржпрж╝рж╛рж▓рж┐ржЯрж┐ ржЙржирзНржиржд ржХрж░рзБржи
                enhance_cmd = (
                    f'ffmpeg -i "{vocals_path}" -af "volume=1.8, ' 
                    f'compand=attacks=0.01:decays=0.1:points=-80/-80|-45/-45|-27/-25|-15/-10|-5/-2|0/0|20/8" '
                    f'-c:a pcm_s16le "{output_audio}" -y'
                )
                subprocess.run(enhance_cmd, shell=True)
                print(f"тЬЕ Successfully separated and enhanced vocals using Spleeter")
                return
            else:
                print(f"тЪая╕П Spleeter output file not found: {vocals_path}")
                raise FileNotFoundError(f"Spleeter output file not found: {vocals_path}")
                
        except Exception as spleeter_error:
            print(f"тЪая╕П Spleeter failed or not installed: {spleeter_error}")
            print("Falling back to FFmpeg filters for voice enhancement...")
        
        # ржпржжрж┐ Spleeter ржмрзНржпрж░рзНрже рж╣ржпрж╝, рждрж╛рж╣рж▓рзЗ FFmpeg ржлрж┐рж▓рзНржЯрж╛рж░ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи
        # ржЙржирзНржиржд FFmpeg ржЕржбрж┐ржУ ржлрж┐рж▓рзНржЯрж╛рж░
        audio_filter = (
            "highpass=f=80, " +           # ржирж┐ржЪрзБ ржЖржУржпрж╝рж╛ржЬ ржмрж╛ржж ржжрж┐ржи
            "lowpass=f=8000, " +          # ржЙржЪрзНржЪ ржЖржУржпрж╝рж╛ржЬ ржмрж╛ржж ржжрж┐ржи
            "volume=2.0, " +              # ржнрж▓рж┐ржЙржо ржмрж╛ржбрж╝рж╛ржи
            "compand=attacks=0.01:decays=0.1:" +  # ржбрж╛ржЗржирж╛ржорж┐ржХ ржХржорзНржкрзНрж░рзЗрж╢ржи
            "points=-80/-80|-45/-45|-27/-25|-15/-10|-5/-2|0/0|20/8"
        )
        
        ffmpeg_cmd = (
            f'ffmpeg -i "{input_audio}" -af "{audio_filter}" '
            f'-c:a pcm_s16le "{output_audio}" -y'
        )
        
        print(f"Running FFmpeg audio enhancement command...")
        subprocess.run(ffmpeg_cmd, shell=True)
        
        # ржЖржЙржЯржкрзБржЯ ржлрж╛ржЗрж▓ ржпрж╛ржЪрж╛ржЗ ржХрж░рзБржи
        if os.path.exists(output_audio):
            try:
                out_duration = float(subprocess.check_output(
                    f'ffprobe -i "{output_audio}" -show_entries format=duration -v quiet -of csv="p=0"',
                    shell=True
                ).decode().strip())
                print(f"тЬЕ Enhanced audio duration: {out_duration} seconds ({out_duration/60:.2f} minutes)")
            except:
                print("Could not determine output audio duration")
            
            print(f"тЬЕ Speech enhanced using FFmpeg filters: {output_audio}")
        else:
            print(f"тЭМ Output file not created: {output_audio}")
            # ржкрзНрж░рж╕рзЗрж╕рж┐ржВ ржмрзНржпрж░рзНрже рж╣рж▓рзЗ, рж╕рж╛ржзрж╛рж░ржг ржХржкрж┐ ржХрж░рзБржи
            shutil.copy2(input_audio, output_audio)
            print(f"тЬЕ Copied original file as fallback: {output_audio}")
            
    except Exception as e:
        print(f"тЭМ Error processing audio: {e}")
        # рж╕ржмржХрж┐ржЫрзБ ржмрзНржпрж░рзНрже рж╣рж▓рзЗ рж╕рж╛ржзрж╛рж░ржг ржХржкрж┐ ржХрж░рзБржи
        try:
            shutil.copy2(input_audio, output_audio)
            print(f"тЬЕ File copied as fallback: {output_audio}")
        except Exception as copy_error:
            print(f"тЭМ Even fallback copy failed: {copy_error}")
                       
def split_into_chunks(result, words_per_line=5):
    """
    Whisper result ржбрзЗржЯрж╛ ржерзЗржХрзЗ (word_timestamps=True) ржкрзНрж░рждрж┐ржЯрж┐ ржУржпрж╝рж╛рж░рзНржб ржирж┐ржпрж╝рзЗ 
    ржЫрзЛржЯ ржЫрзЛржЯ ржЪрж╛ржЩрзНржХ (рж╕рж╛ржмржЯрж╛ржЗржЯрзЗрж▓ рж▓рж╛ржЗржи) рждрзИрж░рж┐ ржХрж░рзЗ рж░рж┐ржЯрж╛рж░рзНржи ржХрж░ржмрзЗред
    """
    all_chunks = []
    current_words = []
    chunk_start_time = None
    chunk_end_time = None

    for seg in result["segments"]:
        for w in seg["words"]:
            if chunk_start_time is None:
                chunk_start_time = w["start"]
            chunk_end_time = w["end"]
            current_words.append(w["word"])

            if (len(current_words) >= words_per_line) or any(punct in w["word"] for punct in [".", "!", "?", ","]):
                text_line = " ".join(current_words).strip()
                all_chunks.append({
                    "start": chunk_start_time,
                    "end": chunk_end_time,
                    "text": text_line
                })
                current_words = []
                chunk_start_time = None
                chunk_end_time = None
    
    if current_words:
        text_line = " ".join(current_words).strip()
        all_chunks.append({
            "start": chunk_start_time,
            "end": chunk_end_time,
            "text": text_line
        })

    return all_chunks

def color_line_dynamically(line, color1="&H00FF00&", color2="&HFFFFFF&", ratio=0.7):
    """
    line: ржорзВрж▓ ржЯрзЗржХрзНрж╕ржЯ (ржПржХржЯрж┐ рж╕рж╛ржмржЯрж╛ржЗржЯрзЗрж▓ рж▓рж╛ржЗржи)
    color1: ржкрзНрж░ржержо ржЕржВрж╢рзЗрж░ рж░ржЩ (ASS BGR format, ржЙржжрж╛рж╣рж░ржг: &H00FF00& = рж╕ржмрзБржЬ)
    color2: ржкрж░рзЗрж░ ржЕржВрж╢рзЗрж░ рж░ржЩ (ASS BGR format, ржЙржжрж╛рж╣рж░ржг: &HFFFF00& = ржирзАрж▓рж╛ржн рж╣рж▓рзБржж ржиржпрж╝)
    ratio: ржХржд рж╢рждрж╛ржВрж╢ рж╢ржмрзНржж color1 ржП ржерж╛ржХржмрзЗ (ржбрж┐ржлрж▓рзНржЯ 0.7 = 70%)
    """
    words = line.split()
    total_words = len(words)
    if total_words == 0:
        return line

    split_index = int(total_words * ratio)
    if split_index <= 0:
        return f"{{\\c{color2}}}{line}{{\\r}}"
    if split_index >= total_words:
        return f"{{\\c{color1}}}{line}{{\\r}}"

    part1 = words[:split_index]
    part2 = words[split_index:]
    text1 = " ".join(part1)
    text2 = " ".join(part2)
    return f"{{\\c{color1}}}{text1} {{\\c{color2}}}{text2}{{\\r}}"

def generate_subtitles(audio_file, subtitle_file, subtitle_format='srt'):
    """Generate smaller-chunk subtitles from audio file using word timestamps, with dynamic coloring and fade animation."""
    global model
    result = model.transcribe(audio_file, word_timestamps=True, task='transcribe')
    if not result or "segments" not in result or not result["segments"]:
        print(f"тЭМ Transcription failed or empty segments for: {audio_file}")
        with open(subtitle_file, "w", encoding="utf-8") as f:
            f.write("")
        return

    chunks = split_into_chunks(result, words_per_line=5)
    def format_timestamp(seconds):
        hours, remainder = divmod(int(seconds), 3600)
        minutes, secs = divmod(remainder, 60)
        millisecs = int((seconds % 1) * 1000)
        return f"{hours:02}:{minutes:02}:{secs:02},{millisecs:03}"

    fade_tag = r"{\fad(300,300)}"
    with open(subtitle_file, "w", encoding="utf-8") as f:
        for i, chunk in enumerate(chunks, start=1):
            start_ts = format_timestamp(chunk["start"])
            end_ts = format_timestamp(chunk["end"])
            text_line = chunk["text"]
            colored_text = color_line_dynamically(line=text_line, color1="&H00FF00&", color2="&HFFFFFF&", ratio=0.7)
            animated_text = fade_tag + colored_text
            if subtitle_format == 'srt':
                f.write(f"{i}\n{start_ts} --> {end_ts}\n{animated_text}\n\n")
            else:
                f.write(f"{animated_text}\n")
    print(f"тЬЕ Subtitles generated (chunked): {subtitle_file}")

def create_karaoke_line(words, line_start, line_end):
    """
    words: [{'start': float, 'end': float, 'word': string}, ...]
    line_start, line_end: ржкрзБрж░рзЛ рж▓рж╛ржЗржирзЗрж░ рж╢рзБрж░рзБ ржУ рж╢рзЗрж╖ рж╕ржоржпрж╝ (рж╕рзЗржХрзЗржирзНржбрзЗ)
    рж░рж┐ржЯрж╛рж░рзНржи: \k ржЯрзНржпрж╛ржЧрж╕рж╣ ржПржХржЯрж┐ рж╕рзНржЯрзНрж░рж┐ржВ, ржпрж╛рждрзЗ рж╢ржмрзНржжржЧрзБрж▓рзЛрж░ ржЙржЪрзНржЪрж╛рж░ржгржХрж╛рж▓ ржЕржирзБржпрж╛ржпрж╝рзА рж╣рж╛ржЗрж▓рж╛ржЗржЯ рж╣ржпрж╝ред
    """
    karaoke_text = ""
    for w in words:
        w_start = w["start"] - line_start
        w_end = w["end"] - line_start
        duration_sec = max(0, w_end - w_start)
        duration_cs = int(duration_sec * 100)
        karaoke_text += f"{{\\k{duration_cs}}}{w['word']} "
    karaoke_text += "{\\k0}"
    return karaoke_text.strip()

def split_into_chunks_karaoke(result, words_per_line=5):
    """
    Whisper result ржерзЗржХрзЗ word-level рждржерзНржп ржирж┐ржпрж╝рзЗ ржкрзНрж░рждрж┐ржЯрж┐ ржЪрж╛ржЩрзНржХржХрзЗ (ржкрзНрж░рждрж┐ words_per_line ржЯрж┐ ржУржпрж╝рж╛рж░рзНржб ржмрж╛ ржпрждрж┐ ржЪрж┐рж╣рзНржирзЗ)
    ржПржХржЯрж┐ ржХрж░рзЗ "ржХрзНржпрж╛рж░рж╛ржУржХрзЗ рж▓рж╛ржЗржи" рж╣рж┐рж╕рзЗржмрзЗ рж░рж┐ржЯрж╛рж░рзНржи ржХрж░рзЗред
    """
    all_chunks = []
    current_words = []
    chunk_start_time = None
    chunk_end_time = None
    for seg in result["segments"]:
        for w in seg["words"]:
            if chunk_start_time is None:
                chunk_start_time = w["start"]
            chunk_end_time = w["end"]
            current_words.append(w)
            if (len(current_words) >= words_per_line) or any(punct in w["word"] for punct in [".", "!", "?", ","]):
                karaoke_line = create_karaoke_line(current_words, chunk_start_time, chunk_end_time)
                all_chunks.append({
                    "start": chunk_start_time,
                    "end": chunk_end_time,
                    "text": karaoke_line
                })
                current_words = []
                chunk_start_time = None
                chunk_end_time = None
    if current_words:
        karaoke_line = create_karaoke_line(current_words, chunk_start_time, chunk_end_time)
        all_chunks.append({
            "start": chunk_start_time,
            "end": chunk_end_time,
            "text": karaoke_line
        })
    return all_chunks

def generate_subtitles_karaoke_chunked(audio_file, subtitle_file, words_per_line=5):
    """
    Whisper ржерзЗржХрзЗ word-level timestamps ржирж┐ржпрж╝рзЗ, ржкрзНрж░рждрж┐ words_per_line ржУржпрж╝рж╛рж░рзНржбрзЗ ржЪрж╛ржЩрзНржХ ржХрж░рзЗ
    ржХрзНржпрж╛рж░рж╛ржУржХрзЗ ржПржлрзЗржХрзНржЯ рж╕рж╣ .ass ржлрж╛ржЗрж▓ рждрзИрж░рж┐ ржХрж░рзЗред
    """
    global model
    # ржЕржбрж┐ржУ ржлрж╛ржЗрж▓ рж▓рзЛржб ржХрж░рж╛
    audio_tensor = whisper.load_audio(audio_file)  # Ensure this is a numpy array first
    audio_tensor = torch.from_numpy(audio_tensor).float().to(device)  # Convert numpy array to tensor and move it to the device
    
    result = model.transcribe(audio_tensor, word_timestamps=True, task='transcribe')
    if not result or "segments" not in result or not result["segments"]:
        print(f"тЭМ Transcription failed or empty segments for: {audio_file}")
        with open(subtitle_file, "w", encoding="utf-8") as f:
            f.write("")
        return
    chunks = split_into_chunks_karaoke(result, words_per_line=words_per_line)
    subs = pysubs2.SSAFile()
    fade_tag = r"{\fad(300,300)}"
    for chunk in chunks:
        start_ms = chunk["start"] * 1000
        end_ms = chunk["end"] * 1000
        karaoke_line = chunk["text"]
        karaoke_line = fade_tag + karaoke_line
        karaoke_line = karaoke_line.upper()
        event = pysubs2.SSAEvent(
            start=start_ms,
            end=end_ms,
            text=karaoke_line
        )
        subs.append(event)
    subs.styles["Default"].fontname = "Montserrat"
    subs.styles["Default"].fontsize = 24
    subs.styles["Default"].bold = True
    subs.styles["Default"].alignment = 2
    subs.styles["Default"].outline = 4
    subs.styles["Default"].shadow = 3
    subs.styles["Default"].borderstyle = 1
    subs.styles["Default"].marginv = 60
    subs.styles["Default"].secondarycolor = pysubs2.Color(0, 255, 0, 0)
    subs.save(subtitle_file)
    print(f"тЬЕ Karaoke subtitles (chunked) generated: {subtitle_file}")

def generate_subtitles_karaoke(audio_file, subtitle_file):
    """
    Whisper ржерзЗржХрзЗ word-level timestamps ржирж┐ржпрж╝рзЗ ржкрзНрж░рждрж┐ржЯрж┐ рж╕рзЗржЧржорзЗржирзНржЯржХрзЗ ржХрзНржпрж╛рж░рж╛ржУржХрзЗ ржПржлрзЗржХрзНржЯ рж╕рж╣ .ass ржлрж╛ржЗрж▓ рждрзИрж░рж┐ ржХрж░рзЗред
    """
    global model
    # ржЕржбрж┐ржУ ржлрж╛ржЗрж▓ рж▓рзЛржб ржХрж░рж╛
    audio_tensor = whisper.load_audio(audio_file)  # Ensure this is a numpy array first
    audio_tensor = torch.from_numpy(audio_tensor).float().to(device)  # Convert numpy array to tensor and move it to the device
    
    result = model.transcribe(audio_tensor, word_timestamps=True, task='transcribe')
    if not result or "segments" not in result or not result["segments"]:
        print(f"тЭМ Transcription failed or empty segments for: {audio_file}")
        with open(subtitle_file, "w", encoding="utf-8") as f:
            f.write("")
        return
    subs = pysubs2.SSAFile()
    fade_tag = r"{\fad(300,300)}"
    for seg in result["segments"]:
        seg_start = seg["start"]
        seg_end = seg["end"]
        words = seg["words"]
        if not words:
            continue
        karaoke_line = create_karaoke_line(words, seg_start, seg_end)
        karaoke_line = fade_tag + karaoke_line
        karaoke_line = karaoke_line.upper()
        event = pysubs2.SSAEvent(
            start=seg_start * 1000,
            end=seg_end * 1000,
            text=karaoke_line
        )
        subs.append(event)
    subs.styles["Default"].fontname = "Montserrat"
    subs.styles["Default"].fontsize = 22
    subs.styles["Default"].bold = True
    subs.styles["Default"].alignment = 2
    subs.styles["Default"].outline = 4
    subs.styles["Default"].shadow = 3
    subs.styles["Default"].borderstyle = 1
    subs.styles["Default"].marginv = 60
    subs.styles["Default"].secondarycolor = pysubs2.Color(0, 255, 0, 0)
    karaoke_style = subs.styles["Default"].copy()
    karaoke_style.primarycolor = pysubs2.Color(255, 255, 255, 0)
    karaoke_style.secondarycolor = pysubs2.Color(255, 255, 0, 0)
    subs.styles["Karaoke"] = karaoke_style
    subs.save(subtitle_file)
    print(f"тЬЕ Karaoke subtitles generated: {subtitle_file}")

def clear_audio_and_temp_folders(audio_file, temp_folder):
    """Delete specific audio file and its related temp files."""
    # Delete the specific audio file
    if os.path.isfile(audio_file):
        os.remove(audio_file)
        print(f"тЬЕ Deleted audio file: {audio_file}")

    # Identify temp folder specific to the audio file
    temp_audio_folder = os.path.join(temp_folder, os.path.splitext(os.path.basename(audio_file))[0])

    # Delete the folder and its contents
    if os.path.isdir(temp_audio_folder):
        shutil.rmtree(temp_audio_folder)
        print(f"тЬЕ Deleted temporary folder: {temp_audio_folder}")

def create_video(stock_video, audio_file, output_video, is_short=False, use_karaoke=True, temp_folder=None, use_ai_voice=False, use_face_footage=False):
    """
    ржнрж┐ржбрж┐ржУ рждрзИрж░рж┐ ржХрж░рзЗ:
      1. рж╕рзНржЯржХ ржнрж┐ржбрж┐ржУ рж▓рзБржк ржХрж░рзЗ (рж╕рзНржХрзЗрж▓/ржкрзНржпрж╛ржб ржпржжрж┐ рж╢рж░рзНржЯрж╕ рж╣ржпрж╝)
      2. ржмрзНржпрж╛ржХржЧрзНрж░рж╛ржЙржирзНржб ржорж┐ржЙржЬрж┐ржХ ржорж┐ржХрзНрж╕ ржХрж░рж╛
      3. рж╕рж╛ржмржЯрж╛ржЗржЯрзЗрж▓ рждрзИрж░рж┐ (karaoke ржмрж╛ рж╕рж╛ржзрж╛рж░ржг, use_karaoke ржлрзНрж▓рзНржпрж╛ржЧ ржЕржирзБржпрж╛ржпрж╝рзА)
      4. ffmpeg ржжрж┐ржпрж╝рзЗ рж╕ржм ржорж╛рж░рзНржЬ ржХрж░рж╛
      
    ржпржжрж┐ use_ai_voice=True рж╣ржпрж╝, рждрж╛рж╣рж▓рзЗ Whisper ржжрж┐ржпрж╝рзЗ ржЯрзНрж░рж╛ржирзНрж╕ржХрзНрж░рж┐ржкрзНржЯ ржХрж░рзЗ AI ржнржпрж╝рзЗрж╕ ржЬрзЗржирж╛рж░рзЗржЯ ржХрж░ржмрзЗред
    ржпржжрж┐ use_face_footage=True рж╣ржпрж╝, рждрж╛рж╣рж▓рзЗ ржкрзНрж░ржержорзЗ ржлрзЗрж╕ ржлрзБржЯрзЗржЬ ржпрзЛржЧ ржХрж░ржмрзЗред
    """
    if not temp_folder:
        temp_folder = TEMP_FOLDER
    
    # рж╕рзЗржирж┐ржЯрж╛ржЗржЬ ржХрж░рж╛ ржЕржбрж┐ржУ ржлрж╛ржЗрж▓ ржерзЗржХрзЗ ржирж╛ржо ржирж┐ржи
    sanitized_folder_name = os.path.splitext(os.path.basename(audio_file))[0]
    # ржЕрж░рж┐ржЬрж┐ржирж╛рж▓ ржлрж╛ржЗрж▓ ржирж╛ржо ржЦрзБржБржЬрзБржи
    original_folder_name = get_original_basename(audio_file)
    
    # ржпржжрж┐ ржЕрж░рж┐ржЬрж┐ржирж╛рж▓ ржлрзЛрж▓рзНржбрж╛рж░ ржирж╛ржо ржирж╛ ржкрж╛ржУржпрж╝рж╛ ржпрж╛ржпрж╝, рждрж╛рж╣рж▓рзЗ рж╕рзЗржирж┐ржЯрж╛ржЗржЬ ржХрж░рж╛ ржирж╛ржо ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи
    if not original_folder_name:
        original_folder_name = sanitized_folder_name
    
    # ржлрзЛрж▓рзНржбрж╛рж░ рждрзИрж░рж┐ ржХрж░рзБржи ржЕрж░рж┐ржЬрж┐ржирж╛рж▓ ржирж╛ржо ржЕржирзБржпрж╛ржпрж╝рзА
    if is_short:
        video_folder = os.path.join(OUTPUT_FOLDER, "shorts", original_folder_name)  # Shorts folder
    else:
        video_folder = os.path.join(OUTPUT_FOLDER, original_folder_name)  # Regular video folder
    
    # ржнрж┐ржбрж┐ржУрж░ ржЬржирзНржп ржЗржЙржирж┐ржХ ржЯрзЗржорзНржк ржлрзЛрж▓рзНржбрж╛рж░
    video_specific_temp = os.path.join(temp_folder, f"{sanitized_folder_name}_{int(time.time())}")
    os.makedirs(video_specific_temp, exist_ok=True)
    
    # Make sure folder exists
    os.makedirs(video_folder, exist_ok=True)

    # Create video
    try:
        if is_short:
            random_stock = get_random_file(SHORTS_STOCK_VIDEOS_FOLDER, (".mp4", ".mov"))
            used_stock_video = random_stock if random_stock else stock_video
        else:
            random_stock = get_random_file(STOCK_VIDEOS_FOLDER, (".mp4", ".mov"))
            used_stock_video = random_stock if random_stock else stock_video

        print(f"ЁЯОм Creating video (is_short={is_short}, karaoke={use_karaoke}, ai_voice={use_ai_voice}, face_footage={use_face_footage}): {output_video} ...")
        
        # ржпржжрж┐ AI ржнржпрж╝рзЗрж╕ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рждрзЗ рж╣ржпрж╝
        if use_ai_voice:
            # Whisper ржжрж┐ржпрж╝рзЗ ржЯрзНрж░рж╛ржирзНрж╕ржХрзНрж░рж┐ржкрзНржЯ ржХрж░рзБржи
            print("ЁЯОЩя╕П Transcribing audio for AI voice generation...")
            transcript = transcribe_audio(audio_file)
            
            if transcript:
                # AI ржнржпрж╝рзЗрж╕ ржЬрзЗржирж╛рж░рзЗржЯ ржХрж░рзБржи
                ai_voice_file = transcribe_and_generate_ai_voice(transcript, sanitized_folder_name, video_specific_temp)
                
                if ai_voice_file and os.path.exists(ai_voice_file):
                    print(f"тЬЕ Using AI voice: {ai_voice_file}")
                    
                    # AI ржнржпрж╝рзЗрж╕рзЗрж░ рж╕рж╛ржерзЗ ржмрзНржпрж╛ржХржЧрзНрж░рж╛ржЙржирзНржб ржорж┐ржЙржЬрж┐ржХ ржорж┐ржХрзНрж╕ ржХрж░рзБржи
                    bgm_file = get_random_file(BACKGROUND_MUSIC_FOLDER, (".mp3", ".wav"))
                    if bgm_file:
                        mixed_audio = os.path.join(video_specific_temp, "mixed_audio.m4a")
                        
                        # ржЙржирзНржиржд ржорж┐ржХрзНрж╕рж┐ржВ ржлрж┐рж▓рзНржЯрж╛рж░:
                        # 1. ржмрзНржпрж╛ржХржЧрзНрж░рж╛ржЙржирзНржб ржорж┐ржЙржЬрж┐ржХрзЗрж░ ржнрж▓рж┐ржЙржо ржЖрж░рзЛ ржХржорж┐ржпрж╝рзЗ ржжрзЗржУржпрж╝рж╛ (0.1 ржерзЗржХрзЗ 0.05)
                        # 2. рж╕рзНржкрж┐ржЪ ржнрж▓рж┐ржЙржо ржмрж╛ржбрж╝рж╛ржирзЛ (1.5x)
                        # 3. ржорж┐ржХрзНрж╕рж┐ржВ ржПрж░ рж╕ржоржпрж╝ ржУржпрж╝рзЗржЯрзЗржЬ ржкрж░рж┐ржмрж░рзНрждржи (рж╕рзНржкрж┐ржЪржХрзЗ ржЕржЧрзНрж░рж╛ржзрж┐ржХрж╛рж░ ржжрзЗржУржпрж╝рж╛)
                        mix_cmd = (
                            f'ffmpeg -i "{ai_voice_file}" -i "{bgm_file}" -filter_complex '
                            f'"[0:a]volume=1.5[speech];'
                            f'[1:a]aloop=loop=-1:size=2*44100*60,volume=0.05[music];'
                            f'[speech][music]amix=inputs=2:duration=first:weights=10 1:dropout_transition=3" '
                            f'-c:a aac -b:a 192k "{mixed_audio}" -y'
                        )
                        
                        subprocess.run(mix_cmd, shell=True)
                        
                        # ржпрж╛ржЪрж╛ржЗ ржХрж░рзБржи ржпрзЗ ржорж┐ржХрзНрж╕ рж╕ржлрж▓ рж╣ржпрж╝рзЗржЫрзЗ
                        if os.path.exists(mixed_audio) and os.path.getsize(mixed_audio) > 0:
                            print(f"тЬЕ Mixed audio with enhanced speech volume and reduced background music")
                            final_audio = mixed_audio
                        else:
                            print(f"тЪая╕П Failed to mix audio, using original AI voice")
                            final_audio = ai_voice_file
                    else:
                        final_audio = ai_voice_file
                        print("тЪая╕П No background music found, using AI voice without music")
                else:
                    print("тЭМ AI voice generation failed, using original audio")
                    final_audio = audio_file
            else:
                print("тЭМ Transcription failed, using original audio")
                final_audio = audio_file
        else:
            # ржмрзНржпрж╛ржХржЧрзНрж░рж╛ржЙржирзНржб ржорж┐ржЙржЬрж┐ржХ ржорж┐ржХрзНрж╕ ржХрж░рзБржи (ржпржжрж┐ AI ржнржпрж╝рзЗрж╕ ржирж╛ рж╣ржпрж╝)
            # ржмрзНржпрж╛ржХржЧрзНрж░рж╛ржЙржирзНржб ржорж┐ржЙржЬрж┐ржХ ржорж┐ржХрзНрж╕рж┐ржВ ржЕржВрж╢ ржЖржкржбрзЗржЯ ржХрж░рзБржи (ржпржжрж┐ AI ржнржпрж╝рзЗрж╕ ржирж╛ рж╣ржпрж╝)
            bgm_file = get_random_file(BACKGROUND_MUSIC_FOLDER, (".mp3", ".wav"))
            if bgm_file:
                mixed_audio = os.path.join(video_specific_temp, "mixed_audio.m4a")
                
                # ржЙржирзНржиржд ржорж┐ржХрзНрж╕рж┐ржВ ржлрж┐рж▓рзНржЯрж╛рж░:
                # 1. ржмрзНржпрж╛ржХржЧрзНрж░рж╛ржЙржирзНржб ржорж┐ржЙржЬрж┐ржХрзЗрж░ ржнрж▓рж┐ржЙржо ржЖрж░рзЛ ржХржорж┐ржпрж╝рзЗ ржжрзЗржУржпрж╝рж╛ (0.1 ржерзЗржХрзЗ 0.05)
                # 2. рж╕рзНржкрж┐ржЪ ржнрж▓рж┐ржЙржо ржмрж╛ржбрж╝рж╛ржирзЛ (1.5x)
                # 3. ржорж┐ржХрзНрж╕рж┐ржВ ржПрж░ рж╕ржоржпрж╝ ржУржпрж╝рзЗржЯрзЗржЬ ржкрж░рж┐ржмрж░рзНрждржи (рж╕рзНржкрж┐ржЪржХрзЗ ржЕржЧрзНрж░рж╛ржзрж┐ржХрж╛рж░ ржжрзЗржУржпрж╝рж╛)
                mix_cmd = (
                    f'ffmpeg -i "{audio_file}" -i "{bgm_file}" -filter_complex '
                    f'"[0:a]volume=1.5[speech];'
                    f'[1:a]aloop=loop=-1:size=2*44100*60,volume=0.05[music];'
                    f'[speech][music]amix=inputs=2:duration=first:weights=10 1:dropout_transition=3" '
                    f'-c:a aac -b:a 192k "{mixed_audio}" -y'
                )
                
                subprocess.run(mix_cmd, shell=True)
                
                # ржпрж╛ржЪрж╛ржЗ ржХрж░рзБржи ржпрзЗ ржорж┐ржХрзНрж╕ рж╕ржлрж▓ рж╣ржпрж╝рзЗржЫрзЗ
                if os.path.exists(mixed_audio) and os.path.getsize(mixed_audio) > 0:
                    print(f"тЬЕ Mixed audio with enhanced speech volume and reduced background music")
                    final_audio = mixed_audio
                else:
                    print(f"тЪая╕П Failed to mix audio, using original enhanced audio")
                    final_audio = audio_file
            else:
                final_audio = audio_file

        # ржЕржбрж┐ржУ ржбрж┐ржЙрж░рзЗрж╢ржи ржЪрзЗржХ ржХрж░рзБржи
        audio_duration = float(
            subprocess.check_output(
                f'ffprobe -i "{final_audio}" -show_entries format=duration -v quiet -of csv="p=0"',
                shell=True
            ).decode().strip()
        )
        short_duration = min(audio_duration, 60) if is_short else audio_duration
        print(f"ЁЯУК Final audio duration: {short_duration:.2f}s")
        
        # ржлрзЗрж╕ ржлрзБржЯрзЗржЬ ржкрзНрж░рж╕рзЗрж╕рж┐ржВ
        # ржПржЗ ржЕржВрж╢ржЯрж┐ create_video ржлрж╛ржВрж╢ржирзЗрж░ ржнрж┐рждрж░рзЗ рж░рж╛ржЦрзБржи, ржпрзЗржЦрж╛ржирзЗ ржлрзЗрж╕ ржлрзБржЯрзЗржЬ ржкрзНрж░рж╕рзЗрж╕ ржХрж░рж╛ рж╣ржпрж╝

        if use_face_footage:
            print("ЁЯОн Processing face footage with guaranteed timing method...")
            # ржлрзЗрж╕ ржлрзБржЯрзЗржЬ ржирж┐ржи (рж╕рж░рзНржмрзЛржЪрзНржЪ 5 рж╕рзЗржХрзЗржирзНржбрзЗрж░)
            face_footage = face_handler.get_random_face_footage(is_short=is_short, max_duration=5.0)
            
            if not face_footage or not os.path.exists(face_footage):
                print("тЪая╕П No face footage available or file does not exist, using only stock footage")
                use_face_footage = False
            else:
                try:
                    # ржПржХржЯрж┐ рж╕ржорзНржкрзВрж░рзНржг ржирждрзБржи ржкржжрзНржзрждрж┐ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рж╛:
                    # 1. ржкрзНрж░ржержорзЗ ржПржоржи ржПржХржЯрж┐ ржнрж┐ржбрж┐ржУ рждрзИрж░рж┐ ржХрж░ржмрзЛ ржпрзЗржЯрж┐ рж╕рзНржЯржХ ржнрж┐ржбрж┐ржУрж░ рж▓рзБржкрж┐ржВ ржжрж┐ржпрж╝рзЗ ржкрзБрж░рзЛ ржЕржбрж┐ржУ ржжрзИрж░рзНржШрзНржп ржХржнрж╛рж░ ржХрж░рзЗ
                    # 2. рждрж╛рж░ржкрж░ ржнрж┐ржбрж┐ржУрж░ рж╢рзБрж░рзБрждрзЗ ржлрзЗрж╕ ржлрзБржЯрзЗржЬ ржмрж╕рж┐ржпрж╝рзЗ ржжрзЗржмрзЛ ржнрж┐ржбрж┐ржУ ржПржбрж┐ржЯрж┐ржВ ржкржжрзНржзрждрж┐рждрзЗ
                    # ржПрждрзЗ ржЯрж╛ржЗржорж┐ржВ рж╕ржорж╕рзНржпрж╛ ржПржбрж╝рж╛ржирзЛ ржпрж╛ржмрзЗ
                    
                    # рж╕рзНржЯрзЗржк 1: рж╕ржорзНржкрзВрж░рзНржг ржЕржбрж┐ржУ ржжрзИрж░рзНржШрзНржпрзЗрж░ ржЬржирзНржп рж╕рзНржЯржХ ржнрж┐ржбрж┐ржУ рждрзИрж░рж┐ ржХрж░рзБржи
                    full_stock_video = os.path.join(video_specific_temp, "full_stock.mp4")
                    
                    if is_short:
                        # рж╢рж░рзНржЯрж╕ ржнрж┐ржбрж┐ржУрж░ ржХрзНрж╖рзЗрждрзНрж░рзЗ рж╕рзНржХрзЗрж▓ ржХрж░рзБржи
                        scale_filter = "scale=1080:1920:force_original_aspect_ratio=decrease,pad=1080:1920:(ow-iw)/2:(oh-ih)/2"
                        stock_cmd = (
                            f'ffmpeg -stream_loop -1 -i "{used_stock_video}" -t {short_duration} '
                            f'-vf "{scale_filter}" -c:v libx264 -an -preset ultrafast -crf 23 '
                            f'"{full_stock_video}" -y'
                        )
                    else:
                        # рж░рзЗржЧрзБрж▓рж╛рж░ ржнрж┐ржбрж┐ржУрж░ ржХрзНрж╖рзЗрждрзНрж░рзЗ
                        stock_cmd = (
                            f'ffmpeg -stream_loop -1 -i "{used_stock_video}" -t {short_duration} '
                            f'-c:v libx264 -an -preset ultrafast -crf 23 "{full_stock_video}" -y'
                        )
                    
                    subprocess.run(stock_cmd, shell=True)
                    print(f"тЬЕ Created full-length stock video base")
                    
                    # рж╕рзНржЯрзЗржк 2: ржлрзЗрж╕ ржлрзБржЯрзЗржЬ ржкрзНрж░рж╕рзЗрж╕ ржХрж░рзБржи (рж╕рзНржХрзЗрж▓, ржЖржХрж╛рж░ ржЗрждрзНржпрж╛ржжрж┐)
                    face_processed = os.path.join(video_specific_temp, "face_processed.mp4")
                    
                    # ржлрзЗрж╕ ржлрзБржЯрзЗржЬрзЗрж░ ржжрзИрж░рзНржШрзНржп ржЪрзЗржХ ржХрж░рзБржи
                    face_duration = float(
                        subprocess.check_output(
                            f'ffprobe -i "{face_footage}" -show_entries format=duration -v quiet -of csv="p=0"',
                            shell=True
                        ).decode().strip()
                    )
                    print(f"тЬЕ Face footage duration: {face_duration:.2f}s")
                    
                    # ржлрзЗрж╕ ржлрзБржЯрзЗржЬрзЗрж░ ржжрзИрж░рзНржШрзНржп рж╕рзАржорж┐ржд ржХрж░рзБржи (5 рж╕рзЗржХрзЗржирзНржбрзЗрж░ ржмрзЗрж╢рж┐ ржиржпрж╝)
                    face_duration = min(face_duration, 5.0)
                    
                    if is_short:
                        face_cmd = (
                            f'ffmpeg -i "{face_footage}" -t {face_duration} '
                            f'-vf "{scale_filter}" -c:v libx264 -an -preset ultrafast -crf 23 '
                            f'"{face_processed}" -y'
                        )
                    else:
                        face_cmd = (
                            f'ffmpeg -i "{face_footage}" -t {face_duration} '
                            f'-c:v libx264 -an -preset ultrafast -crf 23 "{face_processed}" -y'
                        )
                    
                    subprocess.run(face_cmd, shell=True)
                    print(f"тЬЕ Processed face footage (limited to {face_duration:.2f}s)")
                    
                    # рж╕рзНржЯрзЗржк 3: ржПржХржЯрж╛ 1-ржкрзНржпрж╛рж╕ ржХржорж╛ржирзНржбрзЗ ржнрж┐ржбрж┐ржУ ржПржбрж┐ржЯрж┐ржВржпрж╝рзЗрж░ ржорж╛ржзрзНржпржорзЗ ржпрзЛржЧ ржХрж░рзБржи
                    # overlay + enable=, seekable=1 ржХржорж╛ржирзНржб ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ ржПржХржЯрж┐ ржлрзБрж▓ ржнрж┐ржбрж┐ржУ рждрзИрж░рж┐ ржХрж░ржмрзЛ
                    # ржПржЯрж╛ ржПржХржЗ FFmpeg ржкрзНрж░ржХрзНрж░рж┐ржпрж╝рж╛ржпрж╝ ржХрж░ржмрзЗ, ржпрж╛рждрзЗ рж╕рж┐ржЩрзНржХрж┐ржВ рж╕ржорж╕рзНржпрж╛ ржирж╛ рж╣ржпрж╝
                    
                    final_no_audio = os.path.join(video_specific_temp, "final_no_audio.mp4")
                    
                    # ржПржЦрж╛ржирзЗ overlay ржлрж┐рж▓рзНржЯрж╛рж░ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ, ржнрж┐ржбрж┐ржУрж░ рж╢рзБрж░рзБрждрзЗ ржлрзЗрж╕ ржлрзБржЯрзЗржЬ ржкрзНрж▓рзЗрж╕ ржХрж░рж╛ рж╣ржЪрзНржЫрзЗ
                    # ржПржмржВ 5 рж╕рзЗржХрзЗржирзНржб ржмрж╛ face_duration ржкрж░рзНржпржирзНржд ржжрзЗржЦрж╛ржирзЛ рж╣ржЪрзНржЫрзЗ рж╢рзБржзрзБ
                    concat_cmd = (
                        f'ffmpeg -i "{full_stock_video}" -i "{face_processed}" -filter_complex '
                        f'"[1:v]setpts=PTS-STARTPTS[face];'
                        f'[0:v][face]overlay=0:0:enable=\'between(t,0,{face_duration})\''
                        f'[outv]" -map "[outv]" -an -c:v libx264 -preset fast -crf 22 '
                        f'"{final_no_audio}" -y'
                    )
                    
                    subprocess.run(concat_cmd, shell=True)
                    
                    # ржпрж╛ржЪрж╛ржЗ ржХрж░рзБржи ржпрзЗ ржПржбрж┐ржЯрж┐ржВ рж╕ржлрж▓ рж╣ржпрж╝рзЗржЫрзЗ
                    if os.path.exists(final_no_audio) and os.path.getsize(final_no_audio) > 1000:  # ржЕржирзНрждржд 1KB
                        # ржнрж┐ржбрж┐ржУрж░ ржжрзИрж░рзНржШрзНржп ржЪрзЗржХ ржХрж░рзБржи
                        try:
                            video_duration = float(
                                subprocess.check_output(
                                    f'ffprobe -i "{final_no_audio}" -show_entries format=duration -v quiet -of csv="p=0"',
                                    shell=True
                                ).decode().strip()
                            )
                            print(f"тЬЕ Final video duration: {video_duration:.2f}s, Audio duration: {short_duration:.2f}s")
                            
                            # ржпржжрж┐ ржнрж┐ржбрж┐ржУ ржжрзИрж░рзНржШрзНржп ржЕржбрж┐ржУ ржжрзИрж░рзНржШрзНржпрзЗрж░ рж╕рж╛ржерзЗ ржорзЗрж▓рзЗ ржирж╛, рждрж╛рж╣рж▓рзЗ ржЯрзНрж░рж┐ржо ржХрж░рзБржи
                            if abs(video_duration - short_duration) > 0.5:  # ржпржжрж┐ 0.5 рж╕рзЗржХрзЗржирзНржбрзЗрж░ ржмрзЗрж╢рж┐ ржкрж╛рж░рзНржержХрзНржп рж╣ржпрж╝
                                print(f"тЪая╕П Video duration mismatch, trimming to match audio")
                                trimmed_video = os.path.join(video_specific_temp, "trimmed_video.mp4")
                                trim_cmd = (
                                    f'ffmpeg -i "{final_no_audio}" -t {short_duration} '
                                    f'-c:v copy "{trimmed_video}" -y'
                                )
                                subprocess.run(trim_cmd, shell=True)
                                final_no_audio = trimmed_video
                        except Exception as e:
                            print(f"тЪая╕П Could not check video duration: {e}")
                        
                        used_video = final_no_audio
                        print(f"тЬЕ Successfully created face+stock combined video")
                    else:
                        print(f"тЪая╕П Video editing failed, falling back to stock footage only")
                        use_face_footage = False
                
                except Exception as e:
                    print(f"тЭМ Error processing face footage: {e}")
                    use_face_footage = False
        
        # ржпржжрж┐ ржлрзЗрж╕ ржлрзБржЯрзЗржЬ ржмрзНржпржмрж╣рж╛рж░ ржирж╛ ржХрж░рж╛ рж╣ржпрж╝ ржмрж╛ рждрзНрж░рзБржЯрж┐ рж╣ржпрж╝, рждрж╛рж╣рж▓рзЗ рж╕рзНржЯрзНржпрж╛ржирзНржбрж╛рж░рзНржб ржнрж┐ржбрж┐ржУ ржкрзНрж░рж╕рзЗрж╕рж┐ржВ
        if not use_face_footage:
            print("ЁЯОм Using only stock footage...")
            # ржнрж┐ржбрж┐ржУ рж▓рзБржк ржХрж░рзЗ ржУ ржЕржирзНржпрж╛ржирзНржп ржкрзНрж░рж╕рзЗрж╕рж┐ржВ ржПржХрж╕рж╛ржерзЗ ржХрж░рзБржи
            stock_only_video = os.path.join(video_specific_temp, "stock_only.mp4")
            
            if is_short:
                scale_filter = (
                    "scale=1080:1920:force_original_aspect_ratio=decrease,"
                    "pad=1080:1920:(ow-iw)/2:(oh-ih)/2"
                )
                stock_cmd = (
                    f'ffmpeg -stream_loop -1 -i "{used_stock_video}" -t {short_duration} '
                    f'-vf "{scale_filter}" -c:v libx264 -an -preset ultrafast -crf 22 "{stock_only_video}" -y'
                )
            else:
                stock_cmd = (
                    f'ffmpeg -stream_loop -1 -i "{used_stock_video}" -t {short_duration} '
                    f'-c:v libx264 -an -preset ultrafast -crf 22 "{stock_only_video}" -y'
                )
            
            subprocess.run(stock_cmd, shell=True)
            used_video = stock_only_video
        
        # рж╕рж╛ржмржЯрж╛ржЗржЯрзЗрж▓ рждрзИрж░рж┐ ржХрж░рзБржи - ржкрзНрж░рждрж┐ржЯрж┐ ржнрж┐ржбрж┐ржУрж░ ржЬржирзНржп ржЖрж▓рж╛ржжрж╛ ржЗржЙржирж┐ржХ ржлрж╛ржЗрж▓ржирж╛ржо ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи
        unique_subtitle_id = f"{sanitized_folder_name}_{int(time.time())}"
        temp_subtitle_ass = os.path.join(video_specific_temp, f"subtitles_{unique_subtitle_id}.ass")
        
        if use_ai_voice:
            # AI ржнржпрж╝рзЗрж╕рзЗрж░ ржЬржирзНржп рж╕рж╛ржмржЯрж╛ржЗржЯрзЗрж▓ рждрзИрж░рж┐ ржХрж░рзБржи
            if use_karaoke:
                generate_subtitles_karaoke_chunked(final_audio, temp_subtitle_ass, words_per_line=5)
            else:
                # ржЗржЙржирж┐ржХ ржирж╛ржо ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи
                temp_subtitle_srt = os.path.join(video_specific_temp, f"subtitles_{unique_subtitle_id}.srt")
                generate_subtitles(final_audio, temp_subtitle_srt, subtitle_format='srt')
                convert_srt_to_ass(temp_subtitle_srt, temp_subtitle_ass, is_short=is_short)
        else:
            # ржирж░ржорж╛рж▓ ржЕржбрж┐ржУрж░ ржЬржирзНржп рж╕рж╛ржмржЯрж╛ржЗржЯрзЗрж▓ рждрзИрж░рж┐ ржХрж░рзБржи
            if use_karaoke:
                generate_subtitles_karaoke_chunked(final_audio, temp_subtitle_ass, words_per_line=5)
            else:
                # ржЗржЙржирж┐ржХ ржирж╛ржо ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи
                temp_subtitle_srt = os.path.join(video_specific_temp, f"subtitles_{unique_subtitle_id}.srt")
                generate_subtitles(final_audio, temp_subtitle_srt, subtitle_format='srt')
                convert_srt_to_ass(temp_subtitle_srt, temp_subtitle_ass, is_short=is_short)

        # ржнрж┐ржбрж┐ржУ, ржЕржбрж┐ржУ ржПржмржВ рж╕рж╛ржмржЯрж╛ржЗржЯрзЗрж▓ ржПржХрждрзНрж░рж┐ржд ржХрж░рзБржи
        subtitle_path = os.path.abspath(temp_subtitle_ass).replace("\\", "/").replace(":", "\\:")
        merge_cmd = (
            f'ffmpeg -i "{used_video}" -i "{final_audio}" '
            f'-map 0:v -map 1:a '
            f'-vf "drawbox=x=0:y=0:w=iw:h=ih:color=black@0.5:t=fill,ass=\'{subtitle_path}\'" '
            f'-c:v libx264 -c:a aac -preset fast -crf 18 -r 30 "{output_video}" -y'
        )
        subprocess.run(merge_cmd, shell=True)

        # ржлрж╛ржЗржирж╛рж▓ ржнрж┐ржбрж┐ржУ ржлрж╛ржЗрж▓ ржирж╛ржо рждрзИрж░рж┐ ржХрж░рзБржи
        final_video_path = os.path.join(video_folder, f"{sanitized_folder_name}.mp4")
        
        # ржЖржЙржЯржкрзБржЯ ржнрж┐ржбрж┐ржУ ржерзЗржХрзЗ ржлрж╛ржЗржирж╛рж▓ ржнрж┐ржбрж┐ржУ ржкрж╛ржерзЗ ржорзБржн ржХрж░рзБржи
        os.rename(output_video, final_video_path)
        print(f"тЬЕ Final Video Created: {final_video_path}")
        
        # ржЯрзЗржХрзНрж╕ржЯ ржЖржЙржЯржкрзБржЯ ржлрж╛ржЗрж▓ рждрзИрж░рж┐ ржХрж░рзБржи
        # Whisper ржПрж░ ржорж╛ржзрзНржпржорзЗ ржЕржбрж┐ржУ ржерзЗржХрзЗ ржЯрзНрж░рж╛ржирзНрж╕ржХрзНрж░рж┐ржкрзНржЯ ржХрж░рж╛
        transcribe = transcribe_audio(audio_file)
        if transcribe:
            # ржнрж┐ржбрж┐ржУ ржЯрж╛ржЗржЯрзЗрж▓ ржЕржирзБржпрж╛ржпрж╝рзА ржЖржЙржЯржкрзБржЯ ржлрж╛ржЗрж▓ ржирж╛ржо рждрзИрж░рж┐ ржХрж░рж╛
            output_text_path = os.path.join(video_folder, f"{sanitized_folder_name}_output.txt")
            # Azure OpenAI API ржжрж┐ржпрж╝рзЗ ржЖржЙржЯржкрзБржЯ рждрзИрж░рж┐ ржХрж░рж╛
            generate_output_from_azure(transcribe, original_folder_name, output_text_path)
        
        # ржнрж┐ржбрж┐ржУ рждрзИрж░рж┐ рж╢рзЗрж╖рзЗ ржорзЗржЯрж╛ржбрзЗржЯрж╛ ржЖржкржбрзЗржЯ ржХрж░рждрзЗ ржХрж▓ ржХрж░рзБржи
        if process_video_metadata(final_video_path):
            print("Metadata update was successful.")
        else:
            print("тЭМ Failed to update metadata.")
        
        print(f"тЬЕ Video and text saved to: {video_folder}")

        # AI ржнржпрж╝рзЗрж╕ ржлрж╛ржЗрж▓ ржбрж┐рж▓рж┐ржЯ ржХрж░рзБржи (ржРржЪрзНржЫрж┐ржХ)
        if use_ai_voice and final_audio != audio_file and os.path.exists(final_audio):
            os.remove(final_audio)
            print(f"ЁЯЧСя╕П Deleted AI voice file: {final_audio}")
            
        # рж╕ржмрж╢рзЗрж╖рзЗ ржнрж┐ржбрж┐ржУ-рж╕рзНржкрзЗрж╕рж┐ржлрж┐ржХ ржЯрзЗржорзНржк ржлрзЛрж▓рзНржбрж╛рж░ ржбрж┐рж▓рж┐ржЯ ржХрж░рзБржи
        try:
            shutil.rmtree(video_specific_temp)
            print(f"ЁЯЧСя╕П Cleaned up temporary folder: {video_specific_temp}")
        except Exception as e:
            print(f"тЪая╕П Could not clean up temp folder: {e}")

        return True  # Return True if video creation is successful

    except Exception as e:
        print(f"тЭМ Error creating video for {audio_file}: {e}")
        print(f"тЪая╕П Full error message: {e}")  # рждрзНрж░рзБржЯрж┐рж░ ржмрж┐рж╕рзНрждрж╛рж░рж┐ржд ржмрж╛рж░рзНрждрж╛ ржжрзЗржЦрж╛ржУ
        print("тЪая╕П Skipping this audio and moving to the next one...")
        return False

def process_audio_in_parallel(audio_file, is_short=False, prefix='', suffix='', use_ai_voice=False, use_face_footage=False):
    """ржПржХржЯрж┐ ржЕржбрж┐ржУ ржлрж╛ржЗрж▓ ржкрзНрж░рж╕рзЗрж╕ ржХрж░рзЗ (ржирж░ржорж╛рж▓ ржмрж╛ рж╢рж░рзНржЯрж╕) ржкрзНржпрж╛рж░рж╛рж▓рзЗрж▓ ржерзНрж░рзЗржбрзЗ ржЪрж╛рж▓рж╛ржпрж╝ред"""
    audio_name = os.path.splitext(os.path.basename(audio_file))[0]
    
    audio_temp_folder = os.path.join(TEMP_FOLDER, audio_name)
    os.makedirs(audio_temp_folder, exist_ok=True)
    filtered_audio = os.path.join(audio_temp_folder, f"{audio_name}_filtered.wav")
    
    output_video = get_output_filename(audio_file, is_short, prefix, suffix)
    
    # ржЕржбрж┐ржУ ржкрзНрж░рж╕рзЗрж╕рж┐ржВ
    remove_background_music(audio_file, filtered_audio, audio_temp_folder)
    
    # AI ржнржпрж╝рзЗрж╕ ржЬрзЗржирж╛рж░рзЗржЯ ржХрж░рж╛ (ржпржжрж┐ use_ai_voice=True рж╣ржпрж╝)
    final_audio = filtered_audio
    transcript = ""
    
    if use_ai_voice:
        print("ЁЯОЩя╕П Transcribing audio for AI voice generation...")
        transcript = transcribe_audio(filtered_audio)
        
        if transcript:
            # AI ржнржпрж╝рзЗрж╕ ржЬрзЗржирж╛рж░рзЗржЯ ржХрж░рзБржи
            ai_voice_file = transcribe_and_generate_ai_voice(transcript, audio_name, audio_temp_folder)
            
            if ai_voice_file and os.path.exists(ai_voice_file):
                print(f"тЬЕ Using AI voice: {ai_voice_file}")
                final_audio = ai_voice_file
                
                # AI ржнржпрж╝рзЗрж╕рзЗрж░ ржЕржбрж┐ржУ ржбрж┐ржЙрж░рзЗрж╢ржи ржЪрзЗржХ ржХрж░рзБржи
                try:
                    ai_voice_duration = float(
                        subprocess.check_output(
                            f'ffprobe -i "{ai_voice_file}" -show_entries format=duration -v quiet -of csv="p=0"',
                            shell=True
                        ).decode().strip()
                    )
                    print(f"тЬЕ AI Voice Duration: {ai_voice_duration:.2f} seconds")
                except Exception as e:
                    print(f"тЪая╕П Could not check AI voice duration: {e}")
    
    # ржнрж┐ржбрж┐ржУ рждрзИрж░рж┐ ржХрж░рж╛
    create_video(STOCK_VIDEO, final_audio, output_video, is_short=is_short, use_karaoke=True, 
                temp_folder=audio_temp_folder, use_ai_voice=use_ai_voice, use_face_footage=use_face_footage)

    # Clear the specific audio and temp folder after processing
    clear_audio_and_temp_folders(audio_file, TEMP_FOLDER)
  
def get_audio_from_old_audio():
    """old_audio ржлрзЛрж▓рзНржбрж╛рж░ ржерзЗржХрзЗ mp3, wav, ржмрж╛ m4a ржлрж╛ржЗрж▓ рж▓рзЛржб ржХрж░рзЗ ржПржмржВ рж╕рзЗржирж┐ржЯрж╛ржЗржЬ ржХрж░рзЗ"""
    if not os.path.isdir(OLD_AUDIO_FOLDER):
        return []
        
    # рж╕ржм ржЕржбрж┐ржУ ржлрж╛ржЗрж▓ рж╕ржВржЧрзНрж░рж╣ ржХрж░рзБржи
    audio_files = glob(os.path.join(OLD_AUDIO_FOLDER, "*.mp3")) + \
                 glob(os.path.join(OLD_AUDIO_FOLDER, "*.wav")) + \
                 glob(os.path.join(OLD_AUDIO_FOLDER, "*.m4a"))
                 
    sanitized_files = []
    
    # ржкрзНрж░рждрж┐ржЯрж┐ ржлрж╛ржЗрж▓рзЗрж░ ржирж╛ржо рж╕рзЗржирж┐ржЯрж╛ржЗржЬ ржХрж░рзБржи
    for file_path in audio_files:
        file_dir = os.path.dirname(file_path)
        file_name = os.path.basename(file_path)
        
        # ржлрж╛ржЗрж▓ ржирж╛ржо рж╕рзЗржирж┐ржЯрж╛ржЗржЬ ржХрж░рзБржи
        sanitized_name, original_name = sanitize_filename(file_name)
        sanitized_path = os.path.join(file_dir, sanitized_name)
        
        # ржпржжрж┐ ржлрж╛ржЗрж▓ржирж╛ржо ржкрж░рж┐ржмрж░рзНрждржи рж╣ржпрж╝рзЗ ржерж╛ржХрзЗ, рждрж╛рж╣рж▓рзЗ рж░рж┐ржирзЗржо ржХрж░рзБржи
        if sanitized_name != file_name:
            try:
                # ржлрж╛ржЗрж▓ рж░рж┐ржирзЗржо ржХрж░рзБржи
                os.rename(file_path, sanitized_path)
                print(f"тЬЕ Renamed: {file_name} -> {sanitized_name}")
                
                # ржорзНржпрж╛ржкрж┐ржВ рж╕ржВрж░ржХрзНрж╖ржг ржХрж░рзБржи
                map_filename(file_path, sanitized_path)
                sanitized_files.append(sanitized_path)
            except Exception as e:
                print(f"тЭМ Error renaming file {file_name}: {e}")
                sanitized_files.append(file_path)  # ржЕрж░рж┐ржЬрж┐ржирж╛рж▓ ржлрж╛ржЗрж▓ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи
        else:
            # ржлрж╛ржЗрж▓ржирж╛ржо ржкрж░рж┐ржмрж░рзНрждржи ржирж╛ рж╣рж▓рзЗржУ ржорзНржпрж╛ржкрж┐ржВ рж░рж╛ржЦрзБржи
            map_filename(file_path, file_path)
            sanitized_files.append(file_path)
                
    return sanitized_files

def batch_process():
    """Process batch of normal and shorts videos one by one with support for AI voice and face footage."""
    clear_temp_folder()
    old_audio_files = get_audio_from_old_audio()  # old_audio ржлрзЛрж▓рзНржбрж╛рж░ ржерзЗржХрзЗ ржлрж╛ржЗрж▓ржЧрзБрж▓рзЛ ржирж┐ржпрж╝рзЗ ржЖрж╕рзБржи

    # URL рж▓рж┐рж╕рзНржЯ ржлрж╛ржЗрж▓ ржмрзЛржЭрж╛рж░ ржЬржирзНржп ржЪрзЗржХ ржХрж░рзБржи
    has_ai_voice_shorts = os.path.isfile(YOUTUBE_AI_VOICE_SHORTS_URL_FILE) and os.path.getsize(YOUTUBE_AI_VOICE_SHORTS_URL_FILE) > 0
    has_ai_voice_long = os.path.isfile(YOUTUBE_AI_VOICE_LONG_VIDEO_URL_FILE) and os.path.getsize(YOUTUBE_AI_VOICE_LONG_VIDEO_URL_FILE) > 0
    has_regular_shorts = os.path.isfile(YOUTUBE_SHORTS_URL_FILE) and os.path.getsize(YOUTUBE_SHORTS_URL_FILE) > 0
    has_regular_videos = os.path.isfile(YOUTUBE_URL_FILE) and os.path.getsize(YOUTUBE_URL_FILE) > 0
    
    # ржлрзЗрж╕ ржлрзБржЯрзЗржЬ URL ржлрж╛ржЗрж▓ ржЪрзЗржХ
    has_face_shorts = os.path.isfile(YOUTUBE_SHORTS_WITH_FACE_URL_FILE) and os.path.getsize(YOUTUBE_SHORTS_WITH_FACE_URL_FILE) > 0
    has_face_long = os.path.isfile(YOUTUBE_LONG_WITH_FACE_URL_FILE) and os.path.getsize(YOUTUBE_LONG_WITH_FACE_URL_FILE) > 0
    has_face_ai_shorts = os.path.isfile(YOUTUBE_SHORTS_WITH_FACE_AI_URL_FILE) and os.path.getsize(YOUTUBE_SHORTS_WITH_FACE_AI_URL_FILE) > 0
    has_face_ai_long = os.path.isfile(YOUTUBE_LONG_WITH_FACE_AI_URL_FILE) and os.path.getsize(YOUTUBE_LONG_WITH_FACE_AI_URL_FILE) > 0

    # ржпржжрж┐ old_audio ржлрзЛрж▓рзНржбрж╛рж░рзЗ ржХрзЛржирзЛ ржлрж╛ржЗрж▓ ржирж╛ ржерж╛ржХрзЗ, рждржмрзЗ YouTube ржерзЗржХрзЗ ржЕржбрж┐ржУ ржбрж╛ржЙржирж▓рзЛржб ржХрж░рзБржи
    if not old_audio_files:
        # рзж. ржлрзЗрж╕ ржлрзБржЯрзЗржЬ ржлрж╛ржЗрж▓ рж╕ржВржЦрзНржпрж╛ ржЪрзЗржХ ржХрж░рзБржи
        face_file_counts = face_handler.check_face_footage_files()
        
        # рзз. ржлрзЗрж╕ ржлрзБржЯрзЗржЬ рж╕рж╣ рж╢рж░рзНржЯрж╕ (рж░рзЗржЧрзБрж▓рж╛рж░ ржЕржбрж┐ржУ)
        if has_face_shorts:
            print("\nЁЯФ╣ Processing Face Footage Shorts from YouTube:")
            face_shorts = download_youtube_audio(YOUTUBE_SHORTS_WITH_FACE_URL_FILE)
            for audio_file in face_shorts:
                video_title = os.path.splitext(os.path.basename(audio_file))[0]
                print(f"\nProcessing face footage shorts: {video_title}")
                process_audio_in_parallel(audio_file, is_short=True, use_ai_voice=False, use_face_footage=True)
        
        # рзи. ржлрзЗрж╕ ржлрзБржЯрзЗржЬ рж╕рж╣ рж▓ржВ ржнрж┐ржбрж┐ржУ (рж░рзЗржЧрзБрж▓рж╛рж░ ржЕржбрж┐ржУ)
        if has_face_long:
            print("\nЁЯФ╣ Processing Face Footage Long Videos from YouTube:")
            face_long = download_youtube_audio(YOUTUBE_LONG_WITH_FACE_URL_FILE)
            for audio_file in face_long:
                video_title = os.path.splitext(os.path.basename(audio_file))[0]
                print(f"\nProcessing face footage long video: {video_title}")
                process_audio_in_parallel(audio_file, is_short=False, use_ai_voice=False, use_face_footage=True)
        
        # рзй. ржлрзЗрж╕ ржлрзБржЯрзЗржЬ рж╕рж╣ рж╢рж░рзНржЯрж╕ (AI ржнржпрж╝рзЗрж╕)
        if has_face_ai_shorts:
            print("\nЁЯФ╣ Processing Face Footage Shorts with AI Voice from YouTube:")
            face_ai_shorts = download_youtube_audio(YOUTUBE_SHORTS_WITH_FACE_AI_URL_FILE)
            for audio_file in face_ai_shorts:
                video_title = os.path.splitext(os.path.basename(audio_file))[0]
                print(f"\nProcessing face footage shorts with AI voice: {video_title}")
                process_audio_in_parallel(audio_file, is_short=True, use_ai_voice=True, use_face_footage=True)
        
        # рзк. ржлрзЗрж╕ ржлрзБржЯрзЗржЬ рж╕рж╣ рж▓ржВ ржнрж┐ржбрж┐ржУ (AI ржнржпрж╝рзЗрж╕)
        if has_face_ai_long:
            print("\nЁЯФ╣ Processing Face Footage Long Videos with AI Voice from YouTube:")
            face_ai_long = download_youtube_audio(YOUTUBE_LONG_WITH_FACE_AI_URL_FILE)
            for audio_file in face_ai_long:
                video_title = os.path.splitext(os.path.basename(audio_file))[0]
                print(f"\nProcessing face footage long video with AI voice: {video_title}")
                process_audio_in_parallel(audio_file, is_short=False, use_ai_voice=True, use_face_footage=True)
        
        # рзл. AI ржнржпрж╝рзЗрж╕ рж▓ржВ ржнрж┐ржбрж┐ржУ (ржлрзЗрж╕ ржлрзБржЯрзЗржЬ ржЫрж╛ржбрж╝рж╛)
        if has_ai_voice_long:
            print("\nЁЯФ╣ Processing AI Voice Long Videos from YouTube:")
            ai_voice_long_videos = download_youtube_audio(YOUTUBE_AI_VOICE_LONG_VIDEO_URL_FILE)
            for audio_file in ai_voice_long_videos:
                video_title = os.path.splitext(os.path.basename(audio_file))[0]
                print(f"\nProcessing AI voice long video: {video_title}")
                process_audio_in_parallel(audio_file, is_short=False, use_ai_voice=True, use_face_footage=False)
        
        # рзм. AI ржнржпрж╝рзЗрж╕ рж╢рж░рзНржЯрж╕ ржнрж┐ржбрж┐ржУ (ржлрзЗрж╕ ржлрзБржЯрзЗржЬ ржЫрж╛ржбрж╝рж╛)
        if has_ai_voice_shorts:
            print("\nЁЯФ╣ Processing AI Voice Shorts from YouTube:")
            ai_voice_shorts = download_youtube_audio(YOUTUBE_AI_VOICE_SHORTS_URL_FILE)
            for audio_file in ai_voice_shorts:
                video_title = os.path.splitext(os.path.basename(audio_file))[0]
                print(f"\nProcessing AI voice shorts: {video_title}")
                process_audio_in_parallel(audio_file, is_short=True, use_ai_voice=True, use_face_footage=False)
        
        # рзн. рж░рзЗржЧрзБрж▓рж╛рж░ рж▓ржВ ржнрж┐ржбрж┐ржУ (ржлрзЗрж╕ ржлрзБржЯрзЗржЬ ржЫрж╛ржбрж╝рж╛)
        if has_regular_videos:
            print("\nЁЯФ╣ Processing Regular Videos from YouTube:")
            normal_audio_files = download_youtube_audio(YOUTUBE_URL_FILE)
            for audio_file in normal_audio_files:
                video_title = os.path.splitext(os.path.basename(audio_file))[0]
                print(f"\nProcessing regular video: {video_title}")
                process_audio_in_parallel(audio_file, is_short=False, use_ai_voice=False, use_face_footage=False)
        
        # рзо. рж░рзЗржЧрзБрж▓рж╛рж░ рж╢рж░рзНржЯрж╕ ржнрж┐ржбрж┐ржУ (ржлрзЗрж╕ ржлрзБржЯрзЗржЬ ржЫрж╛ржбрж╝рж╛)
        if has_regular_shorts:
            print("\nЁЯФ╣ Processing Regular Shorts from YouTube:")
            shorts_audio_files = download_youtube_audio(YOUTUBE_SHORTS_URL_FILE)
            for audio_file in shorts_audio_files:
                video_title = os.path.splitext(os.path.basename(audio_file))[0]
                print(f"\nProcessing regular shorts: {video_title}")
                process_audio_in_parallel(audio_file, is_short=True, use_ai_voice=False, use_face_footage=False)
    else:
        # ржпржжрж┐ old_audio ржлрзЛрж▓рзНржбрж╛рж░рзЗ ржлрж╛ржЗрж▓ ржерж╛ржХрзЗ, рждржмрзЗ рж╕рзЗржЧрзБрж▓рж┐ ржкрзНрж░рж╕рзЗрж╕ ржХрж░рзБржи (ржПржЦрж╛ржирзЗ ржЖржорж░рж╛ AI ржнржпрж╝рзЗрж╕ ржмрзНржпржмрж╣рж╛рж░ ржХрж░ржЫрж┐ ржирж╛)
        normal_audio_files = old_audio_files
        for audio_file in normal_audio_files:
            video_title = os.path.splitext(os.path.basename(audio_file))[0]
            print(f"\nProcessing from old_audio: {video_title}")
            process_audio_in_parallel(audio_file, is_short=False, use_ai_voice=False, use_face_footage=False)
        
    print("\nЁЯОЙ All videos are successfully created!")

if __name__ == "__main__":
    print("тП│ Loading Whisper model...")
    
    # ржбрж┐ржнрж╛ржЗрж╕ ржЪрзЗржХрж┐ржВ ржПржмржВ ржоржбрзЗрж▓ржХрзЗ ржбрж┐ржнрж╛ржЗрж╕рзЗ ржкрж╛ржарж╛ржирзЛ
    if torch.cuda.is_available():
        device = torch.device("cuda")
    else:
        device = torch.device("cpu")
    
    # Whisper ржоржбрзЗрж▓ рж▓рзЛржб ржХрж░рж╛
    model = whisper.load_model("small")
    
    # ржоржбрзЗрж▓ржХрзЗ GPU ржмрж╛ CPU рждрзЗ ржкрж╛ржарж╛ржирзЛ
    model.to(device)

    print("тЬЕ Whisper model loaded successfully!")
    batch_process()